{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvFPBiP6apT"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7c5H_GU4eOws"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers torch\n",
        "!pip install -q openai==0.28\n",
        "!pip install -q peft accelerate\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q optuna"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4OUsLJ_bJ_k"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForPreTraining\n",
        "from transformers import Trainer, TrainingArguments, AutoConfig, BertForSequenceClassification\n",
        "from transformers import EarlyStoppingCallback, BitsAndBytesConfig\n",
        "\n",
        "import openai\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch import nn\n",
        "\n",
        "from peft import LoraConfig, get_peft_model,TaskType\n",
        "from peft import prepare_model_for_kbit_training\n",
        "import optuna\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import pandas as pd\n",
        "import math\n",
        "import random\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J16xcl_HO_B_"
      },
      "source": [
        "# Get Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFsAFMfknAoX"
      },
      "source": [
        "## GetModel class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGVQgUe5mguu"
      },
      "outputs": [],
      "source": [
        "class GetModel:\n",
        "    def __init__(self, model_checkpoint):\n",
        "        self.model_checkpoint = model_checkpoint\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "    def get_model_with_lora(self, quantized = False, lora_rank = 8, scaling_factor = 16, dropout = 0.1, chosen_layers = [6]):\n",
        "\n",
        "        bnb_config = BitsAndBytesConfig(\n",
        "            load_in_4bit= True,\n",
        "            bnb_4bit_quant_type= 'nf4',\n",
        "            bnb_4bit_compute_dtype= torch.bfloat16,\n",
        "            bnb_4bit_use_double_quant = True,\n",
        "        )\n",
        "\n",
        "        if quantized:\n",
        "            model = BertForSequenceClassification.from_pretrained(\n",
        "                self.model_checkpoint,\n",
        "                num_labels=2,\n",
        "                torch_dtype=torch.bfloat16,\n",
        "                quantization_config = bnb_config\n",
        "            )\n",
        "        else:\n",
        "            model = BertForSequenceClassification.from_pretrained(\n",
        "                self.model_checkpoint,\n",
        "                num_labels=2,\n",
        "                torch_dtype=torch.bfloat16 # ovo sam mozda zajebao probaj float32 ili bfloat32\n",
        "            )\n",
        "\n",
        "            device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "            model.to(device)\n",
        "\n",
        "        peft_config = LoraConfig(\n",
        "            r = lora_rank,\n",
        "            lora_alpha = scaling_factor,\n",
        "            lora_dropout = dropout,\n",
        "            task_type=\"SEQ_CLS\",\n",
        "            target_modules = [\"attention.self.query\", \"attention.self.value\"],\n",
        "            layers_to_transform = chosen_layers\n",
        "        )\n",
        "\n",
        "        model_with_lora = get_peft_model(model, peft_config)\n",
        "        trainable_parameters = GetModel.get_trainable_parameters(model_with_lora)\n",
        "        return model_with_lora, GetModel.get_hyperparameters_and_trainable_parameters(trainable_parameters, quantized, lora_rank, scaling_factor, dropout, chosen_layers)\n",
        "\n",
        "    @classmethod\n",
        "    def get_hyperparameters_and_trainable_parameters(cls, trainable_parameters, quantized, lora_rank, scaling_factor, dropout, chosen_layers):\n",
        "        info = \"model is quantized \\n\" if quantized else \"model is not quantized \\n\"\n",
        "        info += f\"lora_rank: {lora_rank}, scaling_factor: {scaling_factor}, dropout: {dropout}, chosen_layers: {chosen_layers}\\n\"\n",
        "        info += f\"trainable_parameters: {trainable_parameters}\\n\"\n",
        "        return info\n",
        "\n",
        "    @classmethod\n",
        "    def get_trainable_parameters(cls, model):\n",
        "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "        return trainable_params\n",
        "\n",
        "    def get_tokenizer(self):\n",
        "        return self.tokenizer\n",
        "\n",
        "    @classmethod\n",
        "    def print_model(cls, model):\n",
        "        for name, module in model.named_modules():\n",
        "            print(name)\n",
        "\n",
        "# model_class = GetModel(model_checkpoint = \"classla/bcms-bertic\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aELWKwgO1h3y"
      },
      "source": [
        "## Trainer class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EuWZKlGB1lGC"
      },
      "outputs": [],
      "source": [
        "class GetTrainer:\n",
        "    def __init__(self, num_epochs = 10, lr = 2e-4, weight_decay=0.01):\n",
        "        self.training_args = TrainingArguments(\n",
        "            output_dir='./results',\n",
        "            num_train_epochs=num_epochs,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=16,\n",
        "            learning_rate = lr,\n",
        "            warmup_steps=100,\n",
        "            weight_decay=weight_decay,\n",
        "            logging_dir='./logs',\n",
        "            logging_steps=1,\n",
        "            eval_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            remove_unused_columns=False,\n",
        "            load_best_model_at_end = True,\n",
        "            metric_for_best_model= \"eval_f1_score\", #evaluation metrics are: ['eval_loss', 'eval_accuracy', 'eval_precision', 'eval_recall', 'eval_f1_score']\n",
        "            greater_is_better = True\n",
        "        )\n",
        "        self.training_hyperparameters = f\"num_epochs: {num_epochs}, learning_rate: {lr}, weight_decay: {weight_decay}\"\n",
        "\n",
        "    def compute_metrics(self, pred):\n",
        "        labels = pred.label_ids\n",
        "        preds = pred.predictions.argmax(-1)\n",
        "\n",
        "        accuracy = accuracy_score(labels, preds)\n",
        "        precision = precision_score(labels, preds, average='weighted')\n",
        "        recall = recall_score(labels, preds, average='weighted')\n",
        "        f1 = f1_score(labels, preds, average='weighted')\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'precision': precision,\n",
        "            'recall': recall,\n",
        "            'f1_score': f1\n",
        "        }\n",
        "\n",
        "    def get_trainer(self, model, train_data, val_data):\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=self.training_args,\n",
        "            train_dataset=train_data,\n",
        "            eval_dataset=val_data,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "            compute_metrics=self.compute_metrics\n",
        "        )\n",
        "\n",
        "        return trainer, self.training_hyperparameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNHzVmsv3Tab"
      },
      "source": [
        "## Dataset Classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "io__a7gw1FL1"
      },
      "source": [
        "**Loader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Uc5p7_y3c8J"
      },
      "outputs": [],
      "source": [
        "class DatasetLoader:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def add_all_sheets_from_all_files(self, path_file_names, list_of_sheet_names):\n",
        "        output_dataset = []\n",
        "        for index, path_file_name in enumerate(path_file_names):\n",
        "            for sheet_name in list_of_sheet_names[index]:\n",
        "                output_dataset.extend(pd.read_excel(path_file_name, sheet_name=sheet_name).to_dict(orient='records'))\n",
        "        self.check_if_classes_are_balanced(output_dataset)\n",
        "        return output_dataset\n",
        "\n",
        "    def map_name_to_path(self, dataset_name):\n",
        "        path = \"/content/\" + dataset_name + \".xlsx\"\n",
        "        return path\n",
        "\n",
        "    def check_if_classes_are_balanced(self, dataset):\n",
        "        examples_labels = {}\n",
        "        for item in dataset:\n",
        "            label = item[\"label\"]\n",
        "            examples_labels[label] = examples_labels.get(label, 0) + 1\n",
        "\n",
        "        print(\"0: \", examples_labels[0], \"1: \", examples_labels[1])\n",
        "        if examples_labels[0] == examples_labels[1]:\n",
        "            print(\"dataset is balanced\")\n",
        "            return True\n",
        "        else:\n",
        "            print(\"!!!!!!!!!! not balanced\")\n",
        "            return False\n",
        "\n",
        "    @classmethod\n",
        "    def closest_power_of_2(cls, number):\n",
        "       logarithm = math.ceil(math.log2(number))\n",
        "       return 2 ** logarithm\n",
        "\n",
        "    def get_max_tokens(self, dataset):\n",
        "        max_tokens = 0\n",
        "        for item in dataset:\n",
        "            tokenized_text = self.tokenizer.encode(item['text'], truncation = True)\n",
        "            num_tokens = len(tokenized_text)\n",
        "            max_tokens = max(max_tokens, num_tokens)\n",
        "        return max_tokens\n",
        "\n",
        "    def filter_duplicates(self, original_dataset_path, new_file_name):\n",
        "        df = pd.read_excel(original_dataset_path, sheet_name = \"All\")\n",
        "        df_cleaned = df.drop_duplicates(subset=['text'])\n",
        "        df_cleaned.to_excel(new_file_name + \".xlsx\", sheet_name = \"All\", index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uyVMPYzR1OyN"
      },
      "source": [
        "**Augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3XBJQocA3juq"
      },
      "outputs": [],
      "source": [
        "keyboard_neighborhood = {\n",
        "    '1': ['`', '2', 'q'],\n",
        "    '2': ['1', '3', 'q', 'w'],\n",
        "    '3': ['2', '4', 'w', 'e'],\n",
        "    '4': ['3', '5', 'e', 'r'],\n",
        "    '5': ['4', '6', 'r', 't'],\n",
        "    '6': ['5', '7', 't', 'y'],\n",
        "    '7': ['6', '8', 'y', 'u'],\n",
        "    '8': ['7', '9', 'u', 'i'],\n",
        "    '9': ['8', '0', 'i', 'o'],\n",
        "    '0': ['9', '-', 'o', 'p'],\n",
        "    '-': ['0', '=', 'p', '[', '\\''],\n",
        "    '=': ['-', '[', ']', '+'],\n",
        "    'q': ['w', 'a', '1', '2'],\n",
        "    'w': ['q', 'e', 'a', 's', '2', '3'],\n",
        "    'e': ['w', 'r', 's', 'd', '3', '4'],\n",
        "    'r': ['e', 't', 'd', 'f', '4', '5'],\n",
        "    't': ['r', 'y', 'f', 'g', '5', '6'],\n",
        "    'y': ['t', 'u', 'g', 'h', '6', '7', 'z'],\n",
        "    'u': ['y', 'i', 'h', 'j', '7', '8'],\n",
        "    'i': ['u', 'o', 'j', 'k', '8', '9'],\n",
        "    'o': ['i', 'p', 'k', 'l', '9', '0'],\n",
        "    'p': ['o', 'l', '[', ';', '0', '-'],\n",
        "    '[': ['p', ']', ';', '\\'','-', '=' 'š'],\n",
        "    ']': ['[', 'đ', '\\'', '\\\\', 'đ'],\n",
        "    'a': ['q', 'w', 's', 'z'],\n",
        "    's': ['a', 'w', 'e', 'd', 'z', 'x'],\n",
        "    'd': ['s', 'e', 'r', 'f', 'x', 'c'],\n",
        "    'f': ['d', 'r', 't', 'g', 'c', 'v'],\n",
        "    'g': ['f', 't', 'y', 'h', 'v', 'b'],\n",
        "    'h': ['g', 'y', 'u', 'j', 'b', 'n'],\n",
        "    'j': ['h', 'u', 'i', 'k', 'n', 'm'],\n",
        "    'k': ['j', 'i', 'o', 'l', 'm', ','],\n",
        "    'l': ['k', 'o', 'p', ';', ',', '.'],\n",
        "    ';': ['p', '[', 'l', '\\'', '.', '/', 'č'],\n",
        "    '\\'': ['[', ']', ';', 'ć'],\n",
        "    '\\\\': ['ž', ']'],\n",
        "    'z': ['a', 's', 'x', 'y'],\n",
        "    'x': ['z', 's', 'd', 'c'],\n",
        "    'c': ['x', 'd', 'f', 'v', ' '],\n",
        "    'v': ['c', 'f', 'g', 'b', ' '],\n",
        "    'b': ['v', 'g', 'h', 'n', ' '],\n",
        "    'n': ['b', 'h', 'j', 'm', ' '],\n",
        "    'm': ['n', 'j', 'k', ' ', ','],\n",
        "    ',': ['m', 'k', 'l', '.'],\n",
        "    '.': [',', 'l', ';', '/'],\n",
        "    '/': ['.', ';', '\\''],\n",
        "    ' ': ['c', 'v', 'b', 'n', 'm'],\n",
        "    '!': ['1'],\n",
        "    '?': ['/'],\n",
        "    'ž': ['z', '\\\\'],\n",
        "    'š': ['s', '\\''],\n",
        "    'đ': [']', 'd'],\n",
        "    'ć': ['c', '\\''],\n",
        "    'č': [';', 'c']\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZMA-u1a1RGu"
      },
      "outputs": [],
      "source": [
        "class DatasetAugmentation:\n",
        "    def __init__(self, keyboard_neighborhood = keyboard_neighborhood, engine = \"gpt-4o\"):\n",
        "        self.engine = engine\n",
        "        self.keyboard_neighborhood = keyboard_neighborhood\n",
        "        self.prompt_setup()\n",
        "\n",
        "    def generate_response(self, prompt, temperature = 0.9, n_of_responses = 2):\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=self.engine,\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            max_tokens=256,\n",
        "            n=n_of_responses,\n",
        "            temperature=temperature,\n",
        "            top_p = 1\n",
        "        )\n",
        "\n",
        "        responses = [choice['message']['content'].strip() for choice in response['choices']]\n",
        "        return responses\n",
        "\n",
        "    def prompt_setup(self):\n",
        "        self.promt_intro = \"Parafraziraj sledeću rečenicu tako da može zadržati ili promeniti značenje, ali je važno da priroda rečenice \"\n",
        "\n",
        "        conditional_part_contex_normal = \"(rečenica ne predstavlja pretnju fizičkim nasiljem niti nagovaranje na isto) ostane ista. \"\n",
        "        conditional_part_contex_violence = \"(rečenica predstavlja pretnju fizičkim nasiljem ili nagovaranje na isto) ostane ista. \"\n",
        "        self.conditional_part_contex = [conditional_part_contex_normal, conditional_part_contex_violence]\n",
        "\n",
        "        self.prompt_middle = \"Molim te da koristiš sinonime, promeniš imena, brojeve, redosled reči, i preformulišeš delove rečenice.\\n\"\n",
        "\n",
        "        conditional_part_example_normal =  \"Na primer ako ti dam rečenicu: Idemo na piknik sutra u 6 Stefane. Tvoj odgovor može biti: Nikola, planiramo izlet za sutra uveče u 8!.\"\n",
        "        conditional_part_example_violence =  \"Na primer ako ti dam rečenicu: Prebiću te večeras Marija. Tvoj odgovor može biti: Jovane razbuću ti nos kasnije.\"\n",
        "        self.conditional_part_example = [conditional_part_example_normal, conditional_part_example_violence]\n",
        "\n",
        "    def create_prompt(self, old_text, old_label):\n",
        "        new_prompt = self.promt_intro + self.conditional_part_contex[old_label] + self.prompt_middle + self.conditional_part_example[old_label] + f\"\\nRečenica: {old_text}\"\n",
        "        return new_prompt\n",
        "\n",
        "    def new_dataset_by_paraphrazing(self, original_dataset, new_dataset_name):\n",
        "        texts, labels = [], []\n",
        "        n_responses_per_request = 2\n",
        "        list_of_temperatures = [0.75, 0.85, 0.95]\n",
        "        n_of_temperatures = len(list_of_temperatures)\n",
        "        augmentation = n_responses_per_request*n_of_temperatures\n",
        "\n",
        "        for item in original_dataset:\n",
        "            old_text, old_label = item[\"text\"], item[\"label\"]\n",
        "            texts.append(old_text)\n",
        "            labels.append(old_label)\n",
        "            for temperature in list_of_temperatures:\n",
        "                prompt = self.create_prompt(old_text, old_label)\n",
        "                new_texts = self.generate_response(prompt, temperature, n_responses_per_request)\n",
        "                texts.extend(new_texts)\n",
        "            labels.extend([old_label]*augmentation)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "          'text': texts,\n",
        "          'label': labels\n",
        "        })\n",
        "\n",
        "        df.to_excel(new_dataset_name + \".xlsx\", sheet_name=\"All\", index=False)\n",
        "\n",
        "    def add_typo(self, original_text, typo_prob = 0.03):\n",
        "        typos_count = 0\n",
        "        new_text = []\n",
        "        for char in original_text:\n",
        "            if random.random() < typo_prob:\n",
        "                is_alphabet, is_uppercase = char.isalpha(), char.isupper()\n",
        "                if is_alphabet and is_uppercase:\n",
        "                    lower_char = char.lower()\n",
        "                    if lower_char in self.keyboard_neighborhood:\n",
        "                        new_char = random.choice(self.keyboard_neighborhood[lower_char])\n",
        "                        typos_count += 1\n",
        "                        if new_char.isalpha():\n",
        "                            new_char = new_char.upper()\n",
        "                    else:\n",
        "                        new_char = char\n",
        "                else:\n",
        "                    if char in self.keyboard_neighborhood:\n",
        "                        new_char = random.choice(self.keyboard_neighborhood[char])\n",
        "                        typos_count += 1\n",
        "                    else:\n",
        "                        new_char = char\n",
        "            else:\n",
        "               new_char = char\n",
        "\n",
        "            new_text.append(new_char)\n",
        "\n",
        "        return ''.join(new_text), typos_count\n",
        "\n",
        "    def new_dataset_by_adding_noise(self, original_dataset, new_file_name):\n",
        "        add_noise_prob = 0.1\n",
        "        texts, labels = [], []\n",
        "        for item in original_dataset:\n",
        "            old_text, old_label = item['text'], item['label']\n",
        "            texts.append(old_text)\n",
        "            labels.append(old_label)\n",
        "            if random.random() < add_noise_prob:\n",
        "                new_text, typos_count = self.add_typo(original_text = old_text)\n",
        "                if typos_count > 0:\n",
        "                    texts.append(new_text)\n",
        "                    labels.append(old_label)\n",
        "\n",
        "        df = pd.DataFrame({\n",
        "          'text': texts,\n",
        "          'label': labels\n",
        "        })\n",
        "\n",
        "        df.to_excel(new_file_name + \".xlsx\", sheet_name=\"All\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN5ij7ud1IVV"
      },
      "source": [
        "**torch Dataset object**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueTtxwbl3_Ny"
      },
      "outputs": [],
      "source": [
        "class SentimentDataset(Dataset):\n",
        "    def __init__(self, dataset, tokenizer, max_length):\n",
        "        self.texts = [item['text'] for item in dataset]\n",
        "        self.labels = [item['label'] for item in dataset]\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        label = self.labels[idx]\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        input_ids = encoding['input_ids'].squeeze()\n",
        "        attention_mask = encoding['attention_mask'].squeeze()\n",
        "        return {\n",
        "            'input_ids': input_ids,\n",
        "            'attention_mask': attention_mask,\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY-aQq1B4da7"
      },
      "source": [
        "## Evaluation Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iJNx3SOu4f0S"
      },
      "outputs": [],
      "source": [
        "class EvaluationClass:\n",
        "    def __init__(self, model, device, class_names, tokenizer):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.class_names = class_names\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def classify_input(self, input_ids, attention_mask):\n",
        "        inputs = {\n",
        "            'input_ids': input_ids.unsqueeze(0).to(self.device),\n",
        "            'attention_mask': attention_mask.unsqueeze(0).to(self.device)\n",
        "        }\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        predicted_class_id = logits.argmax().item()\n",
        "        return predicted_class_id\n",
        "\n",
        "    def evaluate_model(self, dataset):\n",
        "        true_labels = [item['labels'].item() for item in dataset]\n",
        "        predicted_labels = []\n",
        "        for item in dataset:\n",
        "            new_prediction = self.classify_input(item['input_ids'], item['attention_mask'])\n",
        "            predicted_labels.append(new_prediction)\n",
        "\n",
        "        return true_labels, predicted_labels\n",
        "\n",
        "    def get_metrics(self, dataset):\n",
        "        true_labels, predicted_labels = self.evaluate_model(dataset)\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "        recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "        f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "        return {\"accuracy\": accuracy, \"precision\": precision, \"recall\":recall, \"f1_score\": f1}\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(self, dataset):\n",
        "        true_labels, predicted_labels = self.evaluate_model(dataset)\n",
        "        accuracy = accuracy_score(true_labels, predicted_labels)\n",
        "        precision = precision_score(true_labels, predicted_labels, average='weighted')\n",
        "        recall = recall_score(true_labels, predicted_labels, average='weighted')\n",
        "        f1 = f1_score(true_labels, predicted_labels)\n",
        "\n",
        "        print(f\"\\nInfo: {self.info}\")\n",
        "        print(f'Accuracy: {accuracy}')\n",
        "        print(f'Precision: {precision}')\n",
        "        print(f'Recall: {recall}')\n",
        "        print(f'F1 score: {f1}')\n",
        "\n",
        "        cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])\n",
        "\n",
        "        plt.figure(figsize=(6,3))\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "        plt.xlabel(\"Predicted\")\n",
        "        plt.ylabel(\"True\")\n",
        "        plt.title(\"Confusion Matrix\")\n",
        "        plt.show()\n",
        "\n",
        "    def plot_all_matrixes(self, train, val, test):\n",
        "        labels = [\"Train Set\", \"Val Set\", \"Test Set\"]\n",
        "        sets = [train, val, test]\n",
        "        plt.figure(figsize=(16,4))\n",
        "        for i, (dataset, label) in enumerate(zip(sets, labels)):\n",
        "            true_labels, predicted_labels = self.evaluate_model(dataset)\n",
        "            cm = confusion_matrix(true_labels, predicted_labels, labels=[0, 1])\n",
        "            plt.subplot(1, 3, i+1)\n",
        "            sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=self.class_names, yticklabels=self.class_names)\n",
        "            plt.xlabel(\"Predicted\")\n",
        "            plt.ylabel(\"True\")\n",
        "            plt.title(f\"Confusion Matrix {label}\")\n",
        "            print(f\"{label}: {self.get_metrics(dataset)}\")\n",
        "        plt.show()\n",
        "\n",
        "    def classify_text(self, text, max_length = 32): #ne moze ovako mora max_length da se podesi\n",
        "        inputs = self.tokenizer(text, padding=\"max_length\", truncation=True, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(**inputs)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        predicted_class_id = logits.argmax().item()\n",
        "        return self.class_names[predicted_class_id]\n",
        "\n",
        "    # def set_info(self, lora_hyperparameters, training_hyperparameters):\n",
        "    #     self.info = f\"{lora_hyperparameters}\"\n",
        "    #     self.info += f\"training_hyperparameters: {training_hyperparameters}\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "346lhviHZESv"
      },
      "source": [
        "# Initializaton"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#key:\n",
        "openai.api_key = \"",
        "\n",
        "#device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "#model\n",
        "model_checkpoint = \"classla/bcms-bertic\"\n",
        "model_class = GetModel(model_checkpoint)\n",
        "tokenizer = model_class.get_tokenizer()\n",
        "class_names = ['normal', 'violence']"
      ],
      "metadata": {
        "id": "I1zjotQ36zmj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating dataset**"
      ],
      "metadata": {
        "id": "wYBv380ZT5Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init\n",
        "loader_class = DatasetLoader(tokenizer)\n",
        "augmentation_class = DatasetAugmentation()\n",
        "\n",
        "#manual_dataset\n",
        "path_acceptable = \"/content/DatasetsAcceptableText.xlsx\"\n",
        "path_unacceptable = \"/content/DatasetsUnacceptableText.xlsx\"\n",
        "sheets_acceptable = [\"Normal\", \"SuicideThreads\", \"AntiSuicideViolence\", \"TrickyNormal\"]\n",
        "sheets_unacceptable = [\"PhysicalThreats\", \"SuicidePersuasion\", \"MurderViolencePersuasion\", \"TrickyViolent\"]\n",
        "path_test = \"/content/DatasetsTestCustom.xlsx\"\n",
        "sheets_test = [\"TestCustomCool\"]\n",
        "\n",
        "#initial dataset\n",
        "#initial_manual_dataset = loader_class.add_all_sheets_from_all_files([path_acceptable, path_unacceptable, path_test], [sheets_acceptable, sheets_unacceptable, sheets_test])"
      ],
      "metadata": {
        "id": "k4n4bcHP_6XE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#auto generated dataset from manual\n",
        "augmented_name = \"Augmented\"\n",
        "filtered_name = \"Filtered\"\n",
        "added_noise_name = \"AddedNoise\"\n",
        "sheet_name_default = \"All\"\n",
        "\n",
        "#augmentation_class.new_dataset_by_paraphrazing(initial_manual_dataset, augmented_name)\n",
        "\n",
        "#loader_class.filter_duplicates(loader_class.map_name_to_path(augmented_name), filtered_name)\n",
        "#filtered_dataset = loader_class.add_all_sheets_from_all_files([loader_class.map_name_to_path(filtered_name)], [[sheet_name_default]])\n",
        "\n",
        "#augmentation_class.new_dataset_by_adding_noise(filtered_dataset, added_noise_name)\n",
        "\n",
        "#I need to clean it manually now"
      ],
      "metadata": {
        "id": "6BHbyDdo_sbd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Cleaned Dataset**"
      ],
      "metadata": {
        "id": "0-rZr9nUTwKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#manually cleaned dataset\n",
        "cleaned_name = \"ManuallyCleaned\"\n",
        "final_dataset = loader_class.add_all_sheets_from_all_files([loader_class.map_name_to_path(cleaned_name)], [[sheet_name_default]])\n",
        "max_tokens = loader_class.get_max_tokens(final_dataset)\n",
        "max_length = DatasetLoader.closest_power_of_2(max_tokens)\n",
        "print(\"max_tokens: \", max_tokens, \"max_length: \", max_length)"
      ],
      "metadata": {
        "id": "XJbetXn4BEnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0790e846-e7a3-46a9-e567-8aa1dcc12905"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  2301 1:  2301\n",
            "dataset is balanced\n",
            "max_tokens:  37 max_length:  64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Split**"
      ],
      "metadata": {
        "id": "Hd96d0UkT0GM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#I will choose 40 tokens for max_length for PyTorch Dataset Class (dataset max is 37)\n",
        "max_length = 40\n",
        "\n",
        "#split - forcing balance across all sets\n",
        "class_0 = [item for item in final_dataset if item['label'] == 0]\n",
        "class_1 = [item for item in final_dataset if item['label'] == 1]\n",
        "\n",
        "train_0, temp_0 = train_test_split(class_0, test_size=0.1, random_state=20024)\n",
        "val_0, test_0 = train_test_split(temp_0, test_size=0.5, random_state=2024)\n",
        "\n",
        "train_1, temp_1 = train_test_split(class_1, test_size=0.1, random_state=2024)\n",
        "val_1, test_1 = train_test_split(temp_1, test_size=0.5, random_state=2024)\n",
        "\n",
        "train_data = train_0 + train_1\n",
        "val_data = val_0 + val_1\n",
        "test_data = test_0 + test_1\n",
        "\n",
        "random.seed(2024)\n",
        "random.shuffle(train_data)\n",
        "random.shuffle(val_data)\n",
        "random.shuffle(test_data)\n",
        "\n",
        "#check\n",
        "loader_class.check_if_classes_are_balanced(train_data)\n",
        "loader_class.check_if_classes_are_balanced(val_data)\n",
        "loader_class.check_if_classes_are_balanced(test_data)\n",
        "\n",
        "#get PyTorch Dataset\n",
        "pytorch_train = SentimentDataset(train_data, tokenizer, max_length)\n",
        "pytorch_val = SentimentDataset(val_data, tokenizer, max_length)\n",
        "pytorch_test = SentimentDataset(test_data, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "4yRESJKTBEtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb741f8d-705a-4294-da0e-529bba200558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:  2070 1:  2070\n",
            "dataset is balanced\n",
            "0:  115 1:  115\n",
            "dataset is balanced\n",
            "0:  116 1:  116\n",
            "dataset is balanced\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uItb3lq1PJdN"
      },
      "source": [
        "# Experiments"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 1:** Quantization as regularization method\n"
      ],
      "metadata": {
        "id": "QpqLkO0H4hZG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparameters_list = [{\"quantized\": False, \"weight_decay\": 0, \"dropout\": 0}, {\"quantized\": False, \"weight_decay\": 0.01, \"dropout\": 0},\n",
        "                        {\"quantized\": False, \"weight_decay\": 0, \"dropout\": 0.1}, {\"quantized\": True, \"weight_decay\": 0, \"dropout\": 0},\n",
        "                        {\"quantized\": True, \"weight_decay\": 0.01, \"dropout\": 0.1}]\n",
        "choosen_layers_list = [[6], [11], [6, 11], [5, 6], [9, 10, 11], [5, 6, 11]]\n",
        "for hyperparameters in hyperparameters_list:\n",
        "    quantized, weight_decay, dropout = hyperparameters[\"quantized\"], hyperparameters[\"weight_decay\"], hyperparameters[\"dropout\"]\n",
        "    print(hyperparameters)\n",
        "    #model\n",
        "    model_with_lora, model_info = model_class.get_model_with_lora(quantized = quantized, lora_rank = 8, scaling_factor = 32, dropout = dropout, chosen_layers = [6, 11])\n",
        "\n",
        "    #trainer\n",
        "    trainer_class = GetTrainer(num_epochs = 10, lr = 1e-4, weight_decay=weight_decay)\n",
        "    trainer, training_hyperparameters_info = trainer_class.get_trainer(model_with_lora, pytorch_train, pytorch_val)\n",
        "    trainer.train()\n",
        "\n",
        "    evaluation_class = EvaluationClass(model_with_lora, device, class_names, tokenizer)\n",
        "    evaluation_class.set_info(model_info, training_hyperparameters_info)\n",
        "    evaluation_class.plot_all_matrixes(pytorch_train, pytorch_val, pytorch_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r3kN-Xt14_RF",
        "outputId": "bb22528d-1df2-4300-f77e-6bda262f0698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'quantized': False, 'weight_decay': 0, 'dropout': 0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 01:11, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.614198</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.710833</td>\n",
              "      <td>0.691304</td>\n",
              "      <td>0.683986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.341800</td>\n",
              "      <td>0.520024</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756522</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.589800</td>\n",
              "      <td>0.517935</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.761047</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.671900</td>\n",
              "      <td>0.552955</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.784318</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.771825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.589800</td>\n",
              "      <td>0.521637</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.770076</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.243200</td>\n",
              "      <td>0.507914</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786978</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>0.509188</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.786860</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.781800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.503668</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.797474</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.502683</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.640600</td>\n",
              "      <td>0.505333</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791392</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791289</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.8318840579710145, 'precision': 0.832823909380266, 'recall': 0.8318840579710145, 'f1_score': 0.8272952853598015}\n",
            "Val Set: {'accuracy': 0.7956521739130434, 'precision': 0.7974741326841144, 'recall': 0.7956521739130434, 'f1_score': 0.7873303167420814}\n",
            "Test Set: {'accuracy': 0.7931034482758621, 'precision': 0.7974358974358974, 'recall': 0.7931034482758621, 'f1_score': 0.7798165137614679}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'quantized': False, 'weight_decay': 0.01, 'dropout': 0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 01:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.642527</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.685033</td>\n",
              "      <td>0.678261</td>\n",
              "      <td>0.675290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.326200</td>\n",
              "      <td>0.511812</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.753112</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.751944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.517875</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.754502</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.751606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.746100</td>\n",
              "      <td>0.550577</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.776088</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.757528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.722700</td>\n",
              "      <td>0.512653</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.761047</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.326200</td>\n",
              "      <td>0.519811</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.763278</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.511090</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.776928</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.296900</td>\n",
              "      <td>0.510360</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.780830</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.482400</td>\n",
              "      <td>0.509205</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.770076</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.449200</td>\n",
              "      <td>0.509035</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765539</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765146</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.8251207729468599, 'precision': 0.8253941559806601, 'recall': 0.8251207729468599, 'f1_score': 0.8225490196078431}\n",
            "Val Set: {'accuracy': 0.7782608695652173, 'precision': 0.7808302808302807, 'recall': 0.7782608695652173, 'f1_score': 0.7671232876712328}\n",
            "Test Set: {'accuracy': 0.771551724137931, 'precision': 0.7740157480314961, 'recall': 0.771551724137931, 'f1_score': 0.7601809954751131}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABQsAAAGJCAYAAAAt9GUDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACL/UlEQVR4nOzde3yP9f/H8edn7GRsQ2wWZjkfc4w5hmVJIispZQ7RwSGUat+ck0XOckhJKkqlVCpnEebc5JRTSmFDbMthw3b9/pDPz6eNbbZ9Dtce927X7eZzXe/P53pfH2tP1+t6X+/LYhiGIQAAAAAAAAD5npujOwAAAAAAAADAOVAsBAAAAAAAACCJYiEAAAAAAACAf1EsBAAAAAAAACCJYiEAAAAAAACAf1EsBAAAAAAAACCJYiEAAAAAAACAf1EsBAAAAAAAACCJYiEAAAAAAACAf1EszGcOHTqkNm3ayM/PTxaLRUuWLMnVz//9999lsVj0wQcf5OrnurJ7771X9957r6O7kWU//vijLBaLfvzxR0d3BQByhMyzP2fPPGfvHwDciByzP3ICuIZioQMcOXJEzzzzjO666y55eXnJ19dXTZo00dSpU3Xp0qU83XdkZKR2796tN954Qx999JHq16+fp/uzp+7du8tiscjX1zfD7/HQoUOyWCyyWCyaMGFCtj//xIkTGjlypGJjY3Oht9l3/fgyW7p37+6Q/t3K5cuXNXXqVNWpU0e+vr7y9/dX9erV1adPH/3666/Z/jxH/10AyDoyL2+YPfO+/PJLWSwWvffeezdts3LlSlksFk2bNi3X909uAbiOHMsbZs8xe5+7LVy4UFOmTMlye3IOmSno6A7kN999950effRReXp6qlu3bqpRo4YuX76sDRs2aMiQIdq7d6/mzJmTJ/u+dOmSYmJi9Nprr6lfv355so/g4GBdunRJ7u7uefL5mSlYsKAuXryob7/9Vp07d7bZtmDBAnl5eSk5Ofm2PvvEiRMaNWqUypUrp9q1a2f5fStWrLit/f3XM888o7CwMOvro0ePavjw4erTp4+aNWtmXV++fPkc7ad58+a6dOmSPDw8cvQ5N4qIiNAPP/ygxx9/XL1799aVK1f066+/aunSpWrcuLGqVKmSrc+73b8LAPZF5uUtM2deu3bt5Ofnp4ULF+rpp5/OsM3ChQtVoEABdenSJVf2eSNyC4BEjuU1M+eYvc7drlu4cKH27NmjgQMHZqk9OYfMUCy0o6NHj6pLly4KDg7WmjVrVKpUKeu2vn376vDhw/ruu+/ybP+nT5+WJPn7++fZPiwWi7y8vPLs8zPj6empJk2a6JNPPkkXOAsXLlS7du20ePFiu/Tl4sWLKlSoUK4V3UJDQxUaGmp9vX37dg0fPlyhoaF68sknb/q+CxcuyMfHJ8v7cXNzy9W/w23btmnp0qV644039L///c9m29tvv62EhIRc2xcA50Hm5T0zZ56np6ceeeQRzZs3TydOnFBQUJDN9uTkZH311Ve67777VLJkyVzZ53XkFgCJHLMHM+fY7Z672QM5hywxYDfPPvusIcnYuHFjltpfuXLFGD16tHHXXXcZHh4eRnBwsBEVFWUkJyfbtAsODjbatWtn/PTTT0aDBg0MT09PIyQkxJg/f761zYgRIwxJNktwcLBhGIYRGRlp/fONrr/nRitWrDCaNGli+Pn5GT4+PkalSpWMqKgo6/ajR48akox58+bZvG/16tVG06ZNjUKFChl+fn7GQw89ZOzbty/D/R06dMiIjIw0/Pz8DF9fX6N79+7GhQsXMv2+IiMjDR8fH+ODDz4wPD09jXPnzlm3bd261ZBkLF682JBkvPXWW9Ztf//9t/Hiiy8aNWrUMHx8fIwiRYoY999/vxEbG2tts3bt2nTf343H2aJFC6N69erG9u3bjWbNmhne3t7GCy+8YN3WokUL62d169bN8PT0THf8bdq0Mfz9/Y3jx49neqyGYRjbtm1L913PmzfPkGT8+OOPxnPPPWeUKFHC8Pf3NwzDMH7//XfjueeeMypVqmR4eXkZxYoVMx555BHj6NGjNp97/VjXrl1rXXf9+Pbu3Wvce++9hre3txEUFGSMGzcu035+8skn1j5lxV9//WX06NHDKFmypOHh4WFUq1bNmDt3brr+3ezvAoBzIPPIPMPIWeZd78fEiRPTbfviiy8MScZHH31kGIZhvP/++0bLli2NEiVKGB4eHkbVqlWNmTNnpnvff/uXEXILgGGQY+TYNXl57mYYhrF582YjPDzc8PX1Nby9vY3mzZsbGzZssGmTlJRkvPDCC0ZwcLDh4eFhlChRwggLCzN27Nhh7fPNfl4yQs4hK5iz0I6+/fZb3XXXXWrcuHGW2j/99NMaPny46tatq8mTJ6tFixaKjo7O8Habw4cP65FHHtF9992niRMnqmjRourevbv27t0rSerUqZMmT54sSXr88cf10UcfZWtOA0nau3evHnzwQaWkpGj06NGaOHGiHnroIW3cuPGW71u1apXCw8N16tQpjRw5UoMHD9amTZvUpEkT/f777+nad+7cWf/884+io6PVuXNnffDBBxo1alSW+9mpUydZLBZ9+eWX1nULFy5UlSpVVLdu3XTtf/vtNy1ZskQPPvigJk2apCFDhmj37t1q0aKFTpw4IUmqWrWqRo8eLUnq06ePPvroI3300Udq3ry59XP+/vtvtW3bVrVr19aUKVPUsmXLDPs3depUlShRQpGRkUpNTZUkvfPOO1qxYoWmT5+ebvTE7Xj++ee1b98+DR8+XK+++qqka1eQNm3apC5dumjatGl69tlntXr1at177726ePFipp957tw53X///br77rs1ceJEValSRa+88op++OGHW74vODhY0rVbCa5evXrLtvHx8WrUqJFWrVqlfv36aerUqapQoYJ69epl/XnNyt8FAMcj88g8KWeZ17x5c5UuXVoLFy5Mt23hwoUqVKiQOnbsKEmaNWuWgoOD9b///U8TJ05UmTJl9Pzzz2vGjBmZfIPpkVsAJHKMHLsmL8/d1qxZo+bNmyspKUkjRozQ2LFjlZCQoFatWmnr1q3Wds8++6xmzZqliIgIzZw5Uy+99JK8vb21f/9+SdJrr72m2rVr64477rAe661+Xsg5ZImjq5X5RWJioiHJ6NChQ5bax8bGGpKMp59+2mb9Sy+9ZEgy1qxZY10XHBxsSDLWr19vXXfq1CnD09PTePHFF63rrl85uvHKjGFk/erU5MmTDUnG6dOnb9rvjK5O1a5d2yhZsqTx999/W9ft2rXLcHNzM7p165Zufz179rT5zIcfftgoXrz4Tfd543H4+PgYhmEYjzzyiNG6dWvDMAwjNTXVCAwMNEaNGpXhd5CcnGykpqamOw5PT09j9OjR1nU3uxpkGP9/NWf27NkZbvvvKIbly5cbkowxY8YYv/32m1G4cGGjY8eOmR7jjW41srBp06bG1atXbdpfvHgx3WfExMQYkowPP/zQuu5mIwv/2y4lJcUIDAw0IiIibtnPtLQ06/sDAgKMxx9/3JgxY4bxxx9/pGvbq1cvo1SpUsaZM2ds1nfp0sXw8/OzHsOt/i4AOB6ZR+bdKCeZN2TIEEOSceDAAeu6xMREw8vLy3j88cet6zLKuPDwcOOuu+7KtH//RW4BIMfIsRvlxblbWlqaUbFiRSM8PNxIS0uztrt48aIREhJi3HfffdZ1fn5+Rt++fW/5+e3atbvlaMIbkXPICkYW2klSUpIkqUiRIllq//3330uSBg8ebLP+xRdflKR082NUq1bNZqLUEiVKqHLlyvrtt99uu8//dX2+jK+//lppaWlZes/JkycVGxur7t27q1ixYtb1tWrV0n333Wc9zhs9++yzNq+bNWumv//+2/odZsUTTzyhH3/8UXFxcVqzZo3i4uL0xBNPZNjW09NTbm7X/ldITU3V33//rcKFC6ty5crauXNnlvfp6empHj16ZKltmzZt9Mwzz2j06NHq1KmTvLy89M4772R5X5np3bu3ChQoYLPO29vb+ucrV67o77//VoUKFeTv75+l4yxcuLDN/BoeHh665557Mv0Zs1gsWr58ucaMGaOiRYvqk08+Ud++fRUcHKzHHnvMOieGYRhavHix2rdvL8MwdObMGesSHh6uxMTEbP19AHAcMo/Mu1FOMu967tw4unDx4sVKTk5W165dretuzLjExESdOXNGLVq00G+//abExMQs7es6cgsAOUaO3Sgvzt1iY2N16NAhPfHEE/r777+t+XHhwgW1bt1a69evt/69+fv7a8uWLdaRkzlFziErKBbaia+vryTpn3/+yVL7P/74Q25ubqpQoYLN+sDAQPn7++uPP/6wWV+2bNl0n1G0aFGdO3fuNnuc3mOPPaYmTZro6aefVkBAgLp06aLPPvvsluFzvZ+VK1dOt61q1arWX4g3+u+xFC1aVJKydSwPPPCAihQpokWLFmnBggVq0KBBuu/yurS0NE2ePFkVK1aUp6en7rjjDpUoUUK//PJLtk4w7rzzzmxNiDthwgQVK1ZMsbGxmjZtWq5O0B4SEpJu3aVLlzR8+HCVKVPG5jgTEhKydJylS5eWxWKxWZfVnzFPT0+99tpr2r9/v06cOKFPPvlEjRo10meffWZ9utvp06eVkJCgOXPmqESJEjbL9SA/depUVg4fgIOReWTef91u5tWqVUs1atTQJ598Yl23cOFC3XHHHQoPD7eu27hxo8LCwuTj4yN/f3+VKFHCOml7douFErkF5HfkGDn2X7l97nbo0CFJUmRkZLoMee+995SSkmI9nvHjx2vPnj0qU6aM7rnnHo0cOTLHhWVyDpnhach24uvrq6CgIO3Zsydb7/tvceZm/juK7DrDMG57H9fnZLjO29tb69ev19q1a/Xdd99p2bJlWrRokVq1aqUVK1bctA/ZlZNjuc7T01OdOnXS/Pnz9dtvv2nkyJE3bTt27FgNGzZMPXv21Ouvv65ixYrJzc1NAwcOzPJVOMl2VENW/Pzzz9Zfrrt379bjjz+erfdnty/9+/fXvHnzNHDgQIWGhsrPz08Wi0VdunTJ0nHmxt+LJJUqVUpdunRRRESEqlevrs8++0wffPCBtQ9PPvmkIiMjM3xvrVq1srUvAI5B5mUdmZe5J598Uq+++qq2b9+u0qVLa+3atXrmmWdUsOC1f8YeOXJErVu3VpUqVTRp0iSVKVNGHh4e+v777zV58uRsHVdGyC0g/yHHso4cuz3X+/rWW2+pdu3aGbYpXLiwpGvzQjZr1kxfffWVVqxYobfeekvjxo3Tl19+qbZt2+aoHxI5h4xRLLSjBx98UHPmzFFMTIzNY9QzEhwcrLS0NB06dEhVq1a1ro+Pj1dCQoJ1UtLcULRo0Qwfj/7fK2CS5ObmptatW6t169aaNGmSxo4dq9dee01r165VWFhYhschSQcOHEi37ddff9Udd9whHx+fnB9EBp544gm9//77cnNzy3Bi4eu++OILtWzZUnPnzrVZn5CQoDvuuMP6OqvhnxUXLlxQjx49VK1aNTVu3Fjjx4/Xww8/rAYNGuTaPv7riy++UGRkpCZOnGhdl5ycnOHfvT24u7urVq1aOnTokM6cOaMSJUqoSJEiSk1NzfBn6Ua5+XcBIG+QebbIvNvPvMcff1xRUVFauHChgoODlZqaanML8rfffquUlBR98803NiNc1q5dm2vHIJFbQH5Djtkix3L33K18+fKSrhWmM8sQ6VpB7/nnn9fzzz+vU6dOqW7dunrjjTesxcLcOF5yDjfiNmQ7evnll+Xj46Onn35a8fHx6bYfOXJEU6dOlXRtKLakdE8xmjRpkiSpXbt2udav8uXLKzExUb/88ot13cmTJ/XVV1/ZtDt79my6916/CpKSkpLhZ5cqVUq1a9fW/PnzbUJtz549WrFihfU480LLli31+uuv6+2331ZgYOBN2xUoUCDdla/PP/9cx48ft1l3PRhzo7j2yiuv6NixY5o/f74mTZqkcuXKKTIy8qbfY27I6DinT5+e7ipkbjt06JCOHTuWbn1CQoJiYmJUtGhRlShRQgUKFFBERIQWL16c4VXc06dPW/+cm38XAPIGmZdgXU/m5SzzypYtq2bNmmnRokX6+OOPFRISYvN00uujWm48rsTERM2bN++2+ktuAZDIMXLs/+XFuVu9evVUvnx5TZgwQefPn0+3/XqGpKampru9umTJkgoKCrLZv4+PT5ZvwybnkBWMLLSj8uXLa+HChXrsscdUtWpVdevWTTVq1NDly5e1adMmff755+revbsk6e6771ZkZKTmzJmjhIQEtWjRQlu3btX8+fPVsWPHmz7a/XZ06dJFr7zyih5++GENGDBAFy9e1KxZs1SpUiWbCUtHjx6t9evXq127dgoODtapU6c0c+ZMlS5dWk2bNr3p57/11ltq27atQkND1atXL126dEnTp0+Xn5/fLYeY55Sbm5uGDh2aabsHH3xQo0ePVo8ePdS4cWPt3r1bCxYs0F133WXTrnz58vL399fs2bNVpEgR+fj4qGHDhhnOD3gra9as0cyZMzVixAjVrVtXkjRv3jzde++9GjZsmMaPH5+tz8uqBx98UB999JH8/PxUrVo1xcTEaNWqVSpevHie7O+6Xbt26YknnlDbtm3VrFkzFStWTMePH9f8+fN14sQJTZkyxXqi9+abb2rt2rVq2LChevfurWrVquns2bPauXOnVq1aZf1HT279XQDIO2QemSflXuY9+eST6tOnj06cOKHXXnvNZlubNm3k4eGh9u3b65lnntH58+f17rvvqmTJkjp58mS2+iuRWwCuIcfIMSnvzt3c3Nz03nvvqW3btqpevbp69OihO++8U8ePH9fatWvl6+urb7/9Vv/8849Kly6tRx55RHfffbcKFy6sVatWadu2bTZ3jNWrV0+LFi3S4MGD1aBBAxUuXFjt27fPcN/kHLLE3o9fhmEcPHjQ6N27t1GuXDnDw8PDKFKkiNGkSRNj+vTpRnJysrXdlStXjFGjRhkhISGGu7u7UaZMGSMqKsqmjWEYRnBwsNGuXbt0+/nvY98zevT8dStWrDBq1KhheHh4GJUrVzY+/vhjY8SIEcaNPyKrV682OnToYAQFBRkeHh5GUFCQ8fjjjxsHDx5Mt4//PjJ91apVRpMmTQxvb2/D19fXaN++vbFv3z6bNtf3d/r0aZv18+bNMyQZR48evel3ahiGERkZafj4+NyyTUbfQXJysvHiiy8apUqVMry9vY0mTZoYMTEx6b4/wzCMr7/+2qhWrZpRsGBBm+Ns0aKFUb169Qz3eePnJCUlGcHBwUbdunWNK1eu2LQbNGiQ4ebmZsTExNzyGK7L6PH017+rbdu2pWt/7tw5o0ePHsYdd9xhFC5c2AgPDzd+/fVXIzg42IiMjLS2W7t2rSHJWLt2rc0xZHR8kZGRRnBw8C37GR8fb7z55ptGixYtjFKlShkFCxY0ihYtarRq1cr44osvMmzft29fo0yZMoa7u7sRGBhotG7d2pgzZ45Nu5v9XQBwLmQemZcbmXf27FnD09PTkJTuuzQMw/jmm2+MWrVqGV5eXka5cuWMcePGGe+//3667zKj4/wvcgvAjcgxciyvzt0MwzB+/vlno1OnTkbx4sUNT09PIzg42OjcubOxevVqwzAMIyUlxRgyZIhx9913G0WKFDF8fHyMu+++25g5c6bN55w/f9544oknDH9/f0PSLc/RyDlkhcUwsvl0AgAAAAAAAACmxJyFAAAAAAAAACRRLAQAAAAAAADwL4qFAAAAAAAAACRRLAQAAAAAAADwL4qFAAAAAAAAACRRLAQAAAAAAADwL4qFAAAAAAAAACRJBR3dgbzgXaefo7sAEzi37W1HdwEm4JVLv2Vz+nvt0s/8PLsycg25gVxDbnCGXCPTXB+5hpwi05AbcivTJPPlmimLhQBgOhYGggMATIRcAwCYiclyjWIhALgCi8XRPQAAIPeQawAAMzFZrlEsBABXYLIrVQCAfI5cAwCYiclyzVxHAwAAAAAAAOC2MbIQAFyByYa1AwDyOXINAGAmJss1ioUA4ApMNqwdAJDPkWsAADMxWa5RLAQAV2CyK1UAgHyOXAMAmInJco1iIQC4ApNdqQIA5HPkGgDATEyWaxQLAcAVmOxKFQAgnyPXAABmYrJcM1fpEwAAAAAAAMBtY2QhALgCkw1rBwDkc+QaAMBMTJZrFAsBwBWYbFg7ACCfI9cAAGZislyjWAgArsBkV6oAAPkcuQYAMBOT5RrFQgBwBSa7UgUAyOfINQCAmZgs1ygWAoArMNmVKgBAPkeuAQDMxGS5Zq6jAQAAAIAb/PPPPxo4cKCCg4Pl7e2txo0ba9u2bdbthmFo+PDhKlWqlLy9vRUWFqZDhw45sMcAADgWxUIAcAUWt5wtAAA4Eztm2tNPP62VK1fqo48+0u7du9WmTRuFhYXp+PHjkqTx48dr2rRpmj17trZs2SIfHx+Fh4crOTk5t48aAGBWdsw1e1wE4wwSAFyBmyVnCwAAzsROmXbp0iUtXrxY48ePV/PmzVWhQgWNHDlSFSpU0KxZs2QYhqZMmaKhQ4eqQ4cOqlWrlj788EOdOHFCS5YsyZtjBwCYjx3P1exxEYxiIQC4AkYWAgDMJAeZlpKSoqSkJJslJSUlw91cvXpVqamp8vLyslnv7e2tDRs26OjRo4qLi1NYWJh1m5+fnxo2bKiYmJg8/QoAACZip3M1e10E4wwSAFyBxZKzBQAAZ5KDTIuOjpafn5/NEh0dneFuihQpotDQUL3++us6ceKEUlNT9fHHHysmJkYnT55UXFycJCkgIMDmfQEBAdZtAABkKge55owXwSgWAoArYGQhAMBMcpBpUVFRSkxMtFmioqJuuquPPvpIhmHozjvvlKenp6ZNm6bHH39cbm7kIwAgl+Qg15zxIhgJCQAAAMBleHp6ytfX12bx9PS8afvy5ctr3bp1On/+vP78809t3bpVV65c0V133aXAwEBJUnx8vM174uPjrdsAAMhLzngRjGIhALgCbkMGAJiJAzLNx8dHpUqV0rlz57R8+XJ16NBBISEhCgwM1OrVq63tkpKStGXLFoWGhubGkQIA8oMc5JozXgSjWAgAroDbkAEAZmLHTFu+fLmWLVumo0ePauXKlWrZsqWqVKmiHj16yGKxaODAgRozZoy++eYb7d69W926dVNQUJA6duyY+8cNADAnB5yr5eVFsIK33SsAgP0wOhAAYCZ2zLXrt3P99ddfKlasmCIiIvTGG2/I3d1dkvTyyy/rwoUL6tOnjxISEtS0aVMtW7Ys3eTxAADclB1zbfny5TIMQ5UrV9bhw4c1ZMiQDC+CVaxYUSEhIRo2bFi2L4Ix3AQAXIEdRxauX79e7du3V1BQkCwWi5YsWZKuzf79+/XQQw/Jz89PPj4+atCggY4dO2bdnpycrL59+6p48eIqXLiwIiIi0g2FP3bsmNq1a6dChQqpZMmSGjJkiK5evXpbXw8AwMXYcQRG586ddeTIEaWkpOjkyZN6++235efn9/9dsVg0evRoxcXFKTk5WatWrVKlSpVy82gBAGZnx1xLTExU3759VaVKFXXr1k1NmzbV8uXLbS6C9e/fX3369FGDBg10/vz5bF8EY2QhALgCO16punDhgu6++2717NlTnTp1Srf9yJEjatq0qXr16qVRo0bJ19dXe/futQmfQYMG6bvvvtPnn38uPz8/9evXT506ddLGjRslSampqWrXrp0CAwO1adMmnTx5Ut26dZO7u7vGjh1rt2MFADgII+YBAGZix1zr3LmzOnfufIuuXLsINnr06NveB8VCAICNtm3bqm3btjfd/tprr+mBBx7Q+PHjrevKly9v/XNiYqLmzp2rhQsXqlWrVpKkefPmqWrVqtq8ebMaNWqkFStWaN++fVq1apUCAgJUu3Ztvf7663rllVc0cuRIeXh45N0BAgAAAABuituQAcAV5PA25JSUFCUlJdksKSkp2e5GWlqavvvuO1WqVEnh4eEqWbKkGjZsaHOr8o4dO3TlyhWFhYVZ11WpUkVly5ZVTEyMJCkmJkY1a9ZUQECAtU14eLiSkpK0d+/e2/+eAACugYd2AQDMxGS55py9AgDYslhytERHR8vPz89miY6OznY3Tp06pfPnz+vNN9/U/fffrxUrVujhhx9Wp06dtG7dOklSXFycPDw85O/vb/PegIAAxcXFWdvcWCi8vv36NgCAyeUk1wAAcDYmyzVuQwYAV5DDK05RUVEaPHiwzTpPT89sf05aWpokqUOHDho0aJAkqXbt2tq0aZNmz56tFi1a5KifAIB8wklHUgAAcFtMlmsUCwHAFeQwfDw9PW+rOPhfd9xxhwoWLKhq1arZrK9atao2bNggSQoMDNTly5eVkJBgM7owPj5egYGB1jZbt261+YzrT0u+3gYAYGImO6kCAORzJss1cx0NAJhVDm9Dzi0eHh5q0KCBDhw4YLP+4MGDCg4OliTVq1dP7u7uWr16tXX7gQMHdOzYMYWGhkqSQkNDtXv3bp06dcraZuXKlfL19U1XiAQAmJATZBoAALnGZLnGyEIAgI3z58/r8OHD1tdHjx5VbGysihUrprJly2rIkCF67LHH1Lx5c7Vs2VLLli3Tt99+qx9//FGS5Ofnp169emnw4MEqVqyYfH191b9/f4WGhqpRo0aSpDZt2qhatWp66qmnNH78eMXFxWno0KHq27dvroyABAAAAADcHoqFAOAK7Disffv27WrZsqX19fW5DiMjI/XBBx/o4Ycf1uzZsxUdHa0BAwaocuXKWrx4sZo2bWp9z+TJk+Xm5qaIiAilpKQoPDxcM2fOtG4vUKCAli5dqueee06hoaHy8fFRZGSkRo8ebbfjBAA4kMlu1wIA5HMmyzWKhQDgCuw4PP3ee++VYRi3bNOzZ0/17Nnzptu9vLw0Y8YMzZgx46ZtgoOD9f333992PwEALsxJb7sCAOC2mCzXKBYCgCsw2ZUqAEA+R64BAMzEZLlGsRAAXIHJrlQBAPI5cg0AYCYmyzWKhQDgAiwmCx8AQP5GrgEAzMRsuWaucZIAAAAAAAAAbhsjCwHABZjtShUAIH8j1wAAZmK2XKNYCACuwFzZAwDI78g1AICZmCzXKBYCgAsw25UqAED+Rq4BAMzEbLlGsRAAXIDZwgcAkL+RawAAMzFbrlEsBAAXYLbwAQDkb+QaAMBMzJZrPA0ZAAAAAAAAgCRGFgKASzDblSoAQP5GrgEAzMRsuUaxEABcgbmyBwCQ35FrAAAzMVmuUSwEABdgtitVAID8jVwDAJiJ2XKNYiEAuACzhQ8AIH8j1wAAZmK2XKNYCAAuwGzhAwDI38g1AICZmC3XeBoyAAAAAAAAAEmMLAQAl2C2K1UAgPyNXAMAmInZco1iIQC4AnNlDwAgvyPXAABmYrJco1gIAC7AbFeqAAD5G7kGADATs+UaxUIAcAFmCx8AQP5GrgEAzMRsueawYuG0adOy3HbAgAF52BMAcH5mCx+zIdMAIHvslWupqakaOXKkPv74Y8XFxSkoKEjdu3fX0KFDrX0wDEMjRozQu+++q4SEBDVp0kSzZs1SxYoV7dJHZ0SuAUD2mO18zWHFwsmTJ2epncViIYAAAE6NTAMA5zRu3DjNmjVL8+fPV/Xq1bV9+3b16NFDfn5+1t/H48eP17Rp0zR//nyFhIRo2LBhCg8P1759++Tl5eXgI3AMcg0AnJO9LoI5rFh49OhRR+0aAFyPuS5UmQ6ZBgDZZKdc27Rpkzp06KB27dpJksqVK6dPPvlEW7dulXTthGrKlCkaOnSoOnToIEn68MMPFRAQoCVLlqhLly726aiTIdcAIJvslGv2ugjmlpcHAQDIHRaLJUcLAADOJCeZlpKSoqSkJJslJSUlw/00btxYq1ev1sGDByVJu3bt0oYNG9S2bVtJ14picXFxCgsLs77Hz89PDRs2VExMTN5/EQAAU7DXudqNF8HKlSunRx55RG3atLnpRbBatWrpww8/1IkTJ7RkyZIs78dpHnDy119/6ZtvvtGxY8d0+fJlm22TJk1yUK8AwDlQ8HMtZBoA3FpOci06OlqjRo2yWTdixAiNHDkyXdtXX31VSUlJqlKligoUKKDU1FS98cYb6tq1qyQpLi5OkhQQEGDzvoCAAOs2kGsAkJmc5FpKSkq6i16enp7y9PRM17Zx48aaM2eODh48qEqVKlkvgl3/XZzZRbCsjph3imLh6tWr9dBDD+muu+7Sr7/+qho1auj333+XYRiqW7euo7sHAA5HsdB1kGkAkLmc5FpUVJQGDx5ssy6jEypJ+uyzz7RgwQItXLhQ1atXV2xsrAYOHKigoCBFRkbedh/yE3INADJntotgTnEbclRUlF566SXt3r1bXl5eWrx4sf7880+1aNFCjz76qKO7BwAOx23IroNMA4DM5STTPD095evra7PcrFg4ZMgQvfrqq+rSpYtq1qypp556SoMGDVJ0dLQkKTAwUJIUHx9v8774+HjrtvyOXAOAzOUk16KiopSYmGizREVFZbifGy+C7dy5U/Pnz9eECRM0f/78XD0epygW7t+/X926dZMkFSxYUJcuXVLhwoU1evRojRs3zsG9AwAg68g0AHAeFy9elJub7SlPgQIFlJaWJkkKCQlRYGCgVq9ebd2elJSkLVu2KDQ01K59dVbkGgDkLWe8COYUxUIfHx/r3BelSpXSkSNHrNvOnDnjqG4BgPOw5HCB3ZBpAJAFdsq09u3b64033tB3332n33//XV999ZUmTZqkhx9++Fo3LBYNHDhQY8aM0TfffKPdu3erW7duCgoKUseOHXPjSF0euQYAWWCnXLPXRTCnmLOwUaNG2rBhg6pWraoHHnhAL774onbv3q0vv/xSjRo1cnT3AMDhuJXYdZBpAJA5e+Xa9OnTNWzYMD3//PM6deqUgoKC9Mwzz2j48OHWNi+//LIuXLigPn36KCEhQU2bNtWyZcvk5eVllz46O3INADJnr1y7fhGsbNmyql69un7++WdNmjRJPXv2tPbj+kWwihUrKiQkRMOGDcv2RTCnKBZOmjRJ58+flySNGjVK58+f16JFi1SxYkWergUAoljoSsg0AMicvXKtSJEimjJliqZMmXLLvowePVqjR4+2S59cDbkGAJkz20Uwi2EYRl4cgCN51+nn6C7ABM5te9vRXYAJeOXSJZkyfb/O0fv/nNEhdzoChyDXkBvINeQGZ8g1Ms31kWvIKTINuSG3Mk0yX645xcjCG50/f956r/V1vr6+DuoNAAC3j0wDAJgJuQYA+YNTPODk6NGjateunXx8fOTn56eiRYuqaNGi8vf3V9GiRR3dPQBwPDs+4GT9+vVq3769goKCZLFYtGTJkpu2ffbZZ2WxWNLd3nX27Fl17dpVvr6+8vf3V69evay3MF33yy+/qFmzZvLy8lKZMmU0fvz47HXUSZFpAJAFPLTLZZBrAJAFJss1pxhZ+OSTT8owDL3//vsKCAhgbq4saFK3vAZ1C1PdamVVqoSfOg+ao29//MW6/dLPGQ/L/t/krzT5w2tPxfl8yjO6u9KdKlGsiM4lXdTaLQc0dNrXOnk60do+LLSqhj37gKqWL6Xky1e0cecRvTLxSx07eTZvDxAO8dmnC/XZok904vhxSVL5ChX1zHPPq2mzFpKk0SOHa8vmTTp96pQKFSqku2vX0cDBLynkrvKSpAO//qr335ujn3/eoYRz5xR05516tHMXdX0q0mHHZBb2/L144cIF3X333erZs6c6dep003ZfffWVNm/erKCgoHTbunbtqpMnT2rlypW6cuWKevTooT59+mjhwoWSrj2Rq02bNgoLC9Ps2bO1e/du9ezZU/7+/urTp0+eHZs9kGl5p3AhT414/kE91OpulShaWLsO/KWXxn+hHfuOSZLmjHpSTz1kO9n+io371KHfTEd0F05o7rvvaPXKFTp69Dd5enmp9r85Vi7kLmublJQUTRz/ppb98L0uX76sxk2a6rVhI1T8jjsc2HPz4Xej6yDX8g65hpzKSq598dki/fD9Uu3ft1cXLlzQTzHbGBGcB8z2u9EpioW7du3Sjh07VLlyZUd3xWX4eHtq98Hj+vDrGC2alP7EulxYlM3rNk2qa/aIJ/TV6ljruvXbDuqtucsVdyZRQSX9FT3oYS18q5dadr82UXFwUHF9PrmPpn28Rt1fmy+/wl4a/1KEPp3YW42fGJenxwfHKBkQqBcGvaSywcEyDEPffr1EL/Trq0WLv1KFChVVrVp1tXuwvQJLlVJSYqJmzZiuZ3v30vcrVqtAgQLat2+PihUvprFvvqXAwFKKjd2p10cOl5tbAT3e9UlHH55Ls2f4tG3bVm3btr1lm+PHj6t///5avny52rVrZ7Nt//79WrZsmbZt26b69etLujYR7wMPPKAJEyYoKChICxYs0OXLl/X+++/Lw8ND1atXV2xsrCZNmuTyxUIyLe/MGv6EqlUIUs+h83XydKIef+AefTe7v+pGjNGJfy90Ld+4V8+M+Nj6npTLVx3VXTih7du26rHHu6p6zZpKvZqq6VMn6dnevfTlN9+pUKFCkqS3xo3VT+vW6a1JU1SkSBFFv/G6Br/QT/MXfOrg3puL2U6qzIxcyzvkGnIqK7mWnHxJjZs0U+MmzTRtykQH99i8zJZrTlEsbNCggf78808CKBtWbNynFRv33XR7/N//2Lxuf29Nrdt2SL8f/9u6bvqCtdY/Hzt5ThPmrdRnk3qrYEE3Xb2aprrVyqiAm5tGzliq68/BmfLhan0+uY+1Dczl3patbF73f2GQPvv0E/2yK1YVKlTUI50fs267887S6jdgoB7t1EEnjh9XmbJl9XCnR2zeX7pMGf0SG6vVq1ZQLMyhnIZPSkqKUlJSbNZ5enrK09Mz25+Vlpamp556SkOGDFH16tXTbY+JiZG/v7+1UChJYWFhcnNz05YtW/Twww8rJiZGzZs3l4eHh7VNeHi4xo0bp3Pnzrn0bU1kWt7w8nRXx9a19eigOdq484gk6Y13vtcDzWuo96PNNGrmUknS5ctX02UgcN2sOXNtXo9+4021bBaq/fv2ql79Bvrnn3/01eLFenP8BDVsFHqtzZix6tj+Af2yK1a17q7tgF6bk9lOqsyMXMsb5BpyQ2a5JklPdusuSdq2dYu9u5evmC3XnKJY+N577+nZZ5/V8ePHVaNGDbm7u9tsr1WrloN6Zg4lixXR/U1rqPfwj27apqhvIXVpW1+bdx21FgF37vtTaUaaunVopI++2azChTz1RLt7tGbLAQqF+UBqaqpWLF+mS5cu6u6766TbfvHiRX391Ze6s3RpBQYG3vRz/jn/j/z8/POwp/lDTsMnOjpao0aNslk3YsQIjRw5MtufNW7cOBUsWFADBgzIcHtcXJxKlixps65gwYIqVqyY4uLirG1CQkJs2gQEBFi3uXKxkEzLGwULuKlgwQJKvnzFZn1yyhU1rlPe+rpZ/Yr6Y3W0EpIu6sdtBzVqxlKdTbxg7+7CRZz/59oJuK+fnyRp3949unr1ihqGNra2CbmrvEqVCtKuWIqFuclsJ1VmRq7lDXINeeG/uQb7MVuuOUWx8PTp0zpy5Ih69OhhXWexWGQYhiwWi1JTUx3YO9f3ZPuG+udispasiU23bcyADnq2S3P5eHtqyy9H1WnAbOu2P078rQefn6GPx/XU2691UcGCBbR512/q2G+WHXsPezt08ICeeqKLLl9OUaFChTR52gyVr1DBun3RJws0eeIEXbp0UeVCQvTOu/PkfsPosBvF/rxTK5b9oOkz37FX93ETUVFRGjx4sM262xlVuGPHDk2dOlU7d+40XSDmFjItb5y/mKLNu35TVO+2OnA0XvF/J6nz/fXVsFaIjvx5WpK0ctN+fb1ml34//rfuKn2HRvVvr6/ffk4tIicqLc1w8BHA2aSlpWn8uLGqXaeuKlasJEn6+8wZubu7p5vLqVjx4jpz5rQjugk4HLmWN8g15LaMcg24XU5RLOzZs6fq1KmjTz75JNuT5mZ0a52RliqLW4Hc7qbL6tahkRb9sD3D+S0mf7hKHyyJUdlSxfTaM2313utPWQuGAcWLaOawJ7Tg2y36bNkOFfbx1PDnHtTCCb3U7tmMH6AC11euXIg+W7xE58//o5UrlmvY/17R3A8+thYMH3jwITVq3ERnTp/W/HlzNeTFgZr/8SfpCk+HDh3UwP7P65nn+qpxk6aOOBRzyWFd7nZvOf6vn376SadOnVLZsmWt61JTU/Xiiy9qypQp+v333xUYGKhTp07ZvO/q1as6e/asdRRqYGCg4uPjbdpcf32rkaquICeZJpFrt9Jz6Id6Z2RX/bbiDV29mqrYX//UZ8u2q07Vaz+Pny/fYW279/AJ7T50XPuXjlLz+hX149aDjuo2nNTYMaN05NAhffDRQkd3JX/iepPLINfyDrmG3ESuOZjJcs0pioV//PGHvvnmG1W4YfRSVmV0a12BgAZyL3VPbnXPpTWpU16VQwL11KvzMtz+d8IF/Z1wQYePndKBo3E6vHyMGtYK0ZZfjuqZx5or6fwlvTb1a2v7nq/N1+HlY3RPzXLauvt3Ox0F7Mndw0Nlg4MlSdWq19DePbu14OMPNXzkaElSkSJFVKRIEQUHl1OtWneraeN7tGbVSrVt96D1M44cPqw+vbor4tHH1OfZ5x1yHGbjLKP4nnrqKYWFhdmsCw8P11NPPWUdcRAaGqqEhATt2LFD9erVkyStWbNGaWlpatiwobXNa6+9pitXrlhvZ1q5cqUqV67s0rcgSznLNIlcu5Wjf51Rm6enqpCXh3wLeynuTJI+erOHjh4/k2H734//rdPn/lH5MiU4qYKNsWNGa/26H/X+/I8VcMMFiuJ33KErV64oKSnJZnTh2b//1h13lHBEV03LWXINmSPX8g65htxys1yD/Zgt19wc3QFJatWqlXbt2nVb742KilJiYqLNUjCgXi730HVFdgzVjn3HtPvg8Uzburld++H2cL9WQy7k5ZFueHtqWppNW5hfWlqarly+nOE2Q5IMQ5dv2H748CE93bObHnqoo/q/MMg+ncwHLBZLjpbsOH/+vGJjYxUbGytJOnr0qGJjY3Xs2DEVL15cNWrUsFnc3d0VGBhonfi8atWquv/++9W7d29t3bpVGzduVL9+/dSlSxcFBQVJkp544gl5eHioV69e2rt3rxYtWqSpU6emu1XaFeUk0yRyLSsuJl9W3Jkk+RfxVljjqlr64+4M291Z0l/F/XwUdybJzj2EszIMQ2PHjNaa1Sv17vvzVbp0GZvt1arXUMGC7tq6Oca67vejv+nkyRO6u3ZtO/fW3OyVacg5ci3vkWu4XZnlGuzHbLnmFCML27dvr0GDBmn37t2qWbNmuklzH3rooZu+N6Nb6/LDkHYfbw+VL/P/V7jL3VlctSrdqXNJF/Vn3DlJUhEfL3W6r45enfRVuvc3qBGsetWDtennI0r456JCSpfQiOfb6cix09ryy1FJ0g8/7VX/ri0V1ed+fbZsh4oU8tSofg/pjxN/K/bXv+xzoLCrqZMnqmmz5gosVUoXL1zQ998t1fZtWzVrzlz99eefWr7se4U2bqKiRYspPj5O7783R56eXmravIWka7ce9+4ZqcZNmuqpyB46c/rafCtuBQqoWLFijjw0l2fPDNm+fbtatmxpfX29gBcZGakPPvggS5+xYMEC9evXT61bt5abm5siIiI0bdo063Y/Pz+tWLFCffv2Vb169XTHHXdo+PDh6tOnT64eiyPkJNOk/JtrWREWWlUWi3Tw91MqX6aExg7qqINH4/XhNzHy8fbQa888oCWrYxV3Jkl3lblDb7zQUUf+PKOVm/Y7uutwEmNfH6Ufvl+qKdNnyqeQjzWnChcpIi8vLxUpUkQPR0Rowvg35evnp8KFC+vNsWN0d+06PNwklznpuREyQK7lHXINOZVZrknSmdOndebMGf157Jgk6fChgypUyEelSpWSn7+/o7puOmbLNYthGA6fGdXN7eYDHG9n0lzvOv1y2iWn16xeRa1474V06z/6ZrP6jPhYktSzUxO99VKEQtr8T0nnk23aVa8QpAlDIlSzUmn5eHso7kyiVmzar3HvLtOJ04nWdo+G19OgyDBVDC6pi8mXteWXoxo69Wsd/N12rjEzOrct/83LOGLY/7R182adPn1KhYsUUaVKldWjV2+FNm6iU6fiNWr4UO3bt1dJiUkqfkdx1atXX88811flQu6SJM2aMV2zZ6b/3oKC7tQPK9fY+3CcglcuXZKpOGRZjt5/6K37c6cjyFRuZ5qUP3ItKyLuq6PR/R/SnQH+Opt4UV+vjtWIGd8q6XyyvDzd9dmkPrq7Smn5F/HWydOJWhXzq0bPXKpTZ/9xdNedQn7Mtf+6u3rlDNePHhOtDg93knRtfrWJ49/UD99/p8tXLqtxk6Z6begI3VGC25Al58g1Ms2+yLW8Q67dPjLtmqzk2s3O0W5sk1/lVqZJ5ss1pygW5jbCB7mBAEJucIaTKsk5AwhZR64hN5BryA3OkGtkmusj15BTZBpyA8XCm3P4nIVXrlxRwYIFtWfPHkd3BQCclsWSswX2QaYBQNaQaa6BXAOArDFbrjl8zkJ3d3eVLVv2toavA0B+4awT38IWmQYAWUOuuQZyDQCyxmy55vCRhZL02muv6X//+5/Onj3r6K4AgFNiZKHrINMAIHNkmusg1wAgc2bLNYePLJSkt99+W4cPH1ZQUJCCg4Pl4+Njs33nzp0O6hkAOAc3NydNEaRDpgFA5sg110GuAUDmzJZrTlEs7Nixo6O7AABOzVmvOCE9Mg0AMkeuuQ5yDQAyZ7Zcc4pi4YgRIxzdBQAAcgWZBgAwE3INAPIfpygWXrdjxw7t379fklS9enXVqVPHwT0CAOdgtglz8wMyDQBujlxzPeQaANyc2XLNKYqFp06dUpcuXfTjjz/K399fkpSQkKCWLVvq008/VYkSJRzbQQBwMJNlj6mRaQCQOXLNdZBrAJA5s+WaUzwNuX///vrnn3+0d+9enT17VmfPntWePXuUlJSkAQMGOLp7AOBwFoslRwvsh0wDgMyRaa6DXAOAzJkt15xiZOGyZcu0atUqVa1a1bquWrVqmjFjhtq0aePAngGAc3DWEEF6ZBoAZI5ccx3kGgBkzmy55hTFwrS0NLm7u6db7+7urrS0NAf0CACci8myx9TINADIHLnmOsg1AMic2XLNKW5DbtWqlV544QWdOHHCuu748eMaNGiQWrdu7cCeAQCQPWQaAMBMyDUAyH+colj49ttvKykpSeXKlVP58uVVvnx5lStXTklJSZo+fbqjuwcADsecha6DTAOAzJFproNcA4DMmS3XnOI25DJlymjnzp1avXq19u/fL0mqWrWqwsLCHNwzAHAOTpohyACZBgCZI9dcB7kGAJkzW645RbFQktasWaM1a9bo1KlTSktL088//6yFCxdKkt5//30H9w4AHMtZrzghY2QaANwaueZayDUAuDWz5ZpTFAtHjRql0aNHq379+ipVqpTpvmQAyCl+LboOMg0AMsevRtdBrgFA5sz2q9EpioWzZ8/WBx98oKeeesrRXQEAp8Q/zF0HmQYAmbNXrpUrV05//PFHuvXPP/+8ZsyYoeTkZL344ov69NNPlZKSovDwcM2cOVMBAQF26Z8rINcAIHNmO19zigecXL58WY0bN3Z0NwAAyDEyDQCcx7Zt23Ty5EnrsnLlSknSo48+KkkaNGiQvv32W33++edat26dTpw4oU6dOjmyy06HXAOA/McpioVPP/20dc4LAEB6FkvOFtgPmQYAmbNXppUoUUKBgYHWZenSpSpfvrxatGihxMREzZ07V5MmTVKrVq1Ur149zZs3T5s2bdLmzZvz5sBdELkGAJmzV66VK1cuwycq9+3bV5KUnJysvn37qnjx4ipcuLAiIiIUHx+f7eNxituQk5OTNWfOHK1atUq1atWSu7u7zfZJkyY5qGcA4BzMNqzdzMg0AMhcTnItJSVFKSkpNus8PT3l6el5y/ddvnxZH3/8sQYPHiyLxaIdO3boypUrNk/1rVKlisqWLauYmBg1atTotvtoJuQaAGTOXudr27ZtU2pqqvX1nj17dN9999mMmP/uu+/0+eefy8/PT/369VOnTp20cePGbO3HKYqFv/zyi2rXri3p2oHeiBNkAGB0oCsh0wAgczn5dRgdHa1Ro0bZrBsxYoRGjhx5y/ctWbJECQkJ6t69uyQpLi5OHh4e8vf3t2kXEBCguLi42++gyZBrAJA5e/06LFGihM3rN998M92I+YULF6pVq1aSpHnz5qlq1aravHlzti6COUWxcO3atY7uAgA4Nf4x7jrINADIXE5yLSoqSoMHD7ZZl9moQkmaO3eu2rZtq6CgoNved35ErgFA5sw2Yt4p5iwEANwacxYCAMwkJ5nm6ekpX19fmyWzE6o//vhDq1at0tNPP21dFxgYqMuXLyshIcGmbXx8vAIDA/PisAEAJpWTXIuOjpafn5/NEh0dnek+83LEPMVCAAAAAKY2b948lSxZUu3atbOuq1evntzd3bV69WrrugMHDujYsWMKDQ11RDcBAPlQVFSUEhMTbZaoqKhM35eXI+ad4jZkAMCtcRsyAMBM7JlraWlpmjdvniIjI1Ww4P+f/vj5+alXr14aPHiwihUrJl9fX/Xv31+hoaE83AQAkC05ybWs3HL8X9dHzH/55ZfWdTeOmL9xdOHtjJinWAgALoBaIQDATOyZa6tWrdKxY8fUs2fPdNsmT54sNzc3RUREKCUlReHh4Zo5c6b9OgcAMAV7n69lNmI+IiJC0u2PmKdYCAAugJGFAAAzsWeutWnTRoZhZLjNy8tLM2bM0IwZM+zWHwCA+ZhtxDzFQgBwARQLAQBmQq4BAMzEnrlmjxHzFAsBwAVwTgUAMBNyDQBgJvbMNXuMmOdpyAAAAAAAAAAkMbIQAFwCt2sBAMyEXAMAmInZco1iIQC4AJNlDwAgnyPXAABmYrZc4zZkAHABFoslR0t2rF+/Xu3bt1dQUJAsFouWLFli3XblyhW98sorqlmzpnx8fBQUFKRu3brpxIkTNp9x9uxZde3aVb6+vvL391evXr10/vx5mza//PKLmjVrJi8vL5UpU0bjx4+/7e8HAOBa7JVpAADYg9lyjWIhALgAiyVnS3ZcuHBBd999d4aT4l68eFE7d+7UsGHDtHPnTn355Zc6cOCAHnroIZt2Xbt21d69e7Vy5UotXbpU69evV58+fazbk5KS1KZNGwUHB2vHjh166623NHLkSM2ZM+e2vh8AgGuxV6YBAGAPZss1bkMGABfgZscUadu2rdq2bZvhNj8/P61cudJm3dtvv6177rlHx44dU9myZbV//34tW7ZM27ZtU/369SVJ06dP1wMPPKAJEyYoKChICxYs0OXLl/X+++/Lw8ND1atXV2xsrCZNmmRTVAQAmJM9cw0AgLxmtlxjZCEA5AMpKSlKSkqyWVJSUnLlsxMTE2WxWOTv7y9JiomJkb+/v7VQKElhYWFyc3PTli1brG2aN28uDw8Pa5vw8HAdOHBA586dy5V+AQAAAACyj2IhALiAnN6GHB0dLT8/P5slOjo6x/1KTk7WK6+8oscff1y+vr6SpLi4OJUsWdKmXcGCBVWsWDHFxcVZ2wQEBNi0uf76ehsAgHmZ7XYtAED+ZrZc4zZkAHABOZ34NioqSoMHD7ZZ5+npmaPPvHLlijp37izDMDRr1qwcfRYAIH9x1gndAQC4HWbLNYqFAOAC3HKYPZ6enjkuDt7oeqHwjz/+0Jo1a6yjCiUpMDBQp06dsml/9epVnT17VoGBgdY28fHxNm2uv77eBgBgXjnNNQAAnInZco3bkAHABVgslhwtuel6ofDQoUNatWqVihcvbrM9NDRUCQkJ2rFjh3XdmjVrlJaWpoYNG1rbrF+/XleuXLG2WblypSpXrqyiRYvman8BAM7HWTINAIDcYLZco1gIAC4gp3MWZsf58+cVGxur2NhYSdLRo0cVGxurY8eO6cqVK3rkkUe0fft2LViwQKmpqYqLi1NcXJwuX74sSapataruv/9+9e7dW1u3btXGjRvVr18/denSRUFBQZKkJ554Qh4eHurVq5f27t2rRYsWaerUqelulQYAmJPZ5nYCAORvZss1bkMGANjYvn27WrZsaX19vYAXGRmpkSNH6ptvvpEk1a5d2+Z9a9eu1b333itJWrBggfr166fWrVvLzc1NERERmjZtmrWtn5+fVqxYob59+6pevXq64447NHz4cPXp0ydvDw4AAAAAcEsUCwHABVhkv0tO9957rwzDuOn2W227rlixYlq4cOEt29SqVUs//fRTtvsHAHB99sw1AADymtlyjWIhALgAs02YCwDI38g1AICZmC3XKBYCgAtw1olvAQC4HeQaAMBMzJZrFAsBwAWYLHsAAPkcuQYAMBOz5RrFQgBwAW5mSx8AQL5GrgEAzMRsuebm6A4AAAAAAAAAcA6MLAQAF2CyC1UAgHyOXAMAmInZco1iIQC4ALNNmAsAyN/INQCAmZgt1ygWAoALMFn2AADyOXINAGAmZss1ioUA4ALMNmEuACB/I9cAAGZitlyjWAgALsBc0QMAyO/INQCAmZgt13gaMgAAAAAAAABJjCwEAJdgtglzAQD5G7kGADATs+UaxUIAcAFu5soeAEA+R64BAMzEbLlGsRAAXIDZrlQBAPI3cg0AYCZmyzWKhQDgAkyWPQCAfI5cAwCYidlyjQecAIALsFgsOVoAAHAm9sy048eP68knn1Tx4sXl7e2tmjVravv27dbthmFo+PDhKlWqlLy9vRUWFqZDhw7l5uECAEzObOdqt1Us/Omnn/Tkk08qNDRUx48flyR99NFH2rBhQ652DgAAeyDXAMCczp07pyZNmsjd3V0//PCD9u3bp4kTJ6po0aLWNuPHj9e0adM0e/ZsbdmyRT4+PgoPD1dycrIDe377yDQAQE5lu1i4ePFihYeHy9vbWz///LNSUlIkSYmJiRo7dmyudxAAcG3C3JwsuDlyDQDsLyeZlpKSoqSkJJvl+u/u/xo3bpzKlCmjefPm6Z577lFISIjatGmj8uXLS7o2qnDKlCkaOnSoOnTooFq1aunDDz/UiRMntGTJEjt+I7mDTAMAx7DnuZo9Rsxnu1g4ZswYzZ49W++++67c3d2t65s0aaKdO3dm9+MAAFnAbch5h1wDAPvLSaZFR0fLz8/PZomOjs5wP998843q16+vRx99VCVLllSdOnX07rvvWrcfPXpUcXFxCgsLs67z8/NTw4YNFRMTk+ffQ24j0wDAMex1rmavEfPZfsDJgQMH1Lx583Tr/fz8lJCQkN2PAwBkAeW+vEOuAYD95STXoqKiNHjwYJt1np6eGbb97bffNGvWLA0ePFj/+9//tG3bNg0YMEAeHh6KjIxUXFycJCkgIMDmfQEBAdZtroRMAwDHyEmupaSkpBsh7+npmWG23Thi/rqQkBDrn/87Yl6SPvzwQwUEBGjJkiXq0qVLlvqU7ZGFgYGBOnz4cLr1GzZs0F133ZXdjwMAZIGbxZKjBTdHrgGA/eUk0zw9PeXr62uz3KxYmJaWprp162rs2LGqU6eO+vTpo969e2v27Nl2PmL7INMAwDFykmvOOGI+28XC3r1764UXXtCWLVtksVh04sQJLViwQC+99JKee+657H4cAAAORa4BgHmVKlVK1apVs1lXtWpVHTt2TNK14pokxcfH27SJj4+3bnMlZBoAuJ6oqCglJibaLFFRURm2vT5ivmLFilq+fLmee+45DRgwQPPnz5ekXBsxn+3bkF999VWlpaWpdevWunjxopo3by5PT0+99NJL6t+/f3Y/DgCQBQwOzDvkGgDYn71yrUmTJjpw4IDNuoMHDyo4OFjStVu3AgMDtXr1atWuXVuSlJSUpC1btrhkcY1MAwDHyEmu3eyW44ykpaWpfv361odW1alTR3v27NHs2bMVGRl5+534j2wXCy0Wi1577TUNGTJEhw8f1vnz51WtWjUVLlw41zoFALDFQ0ryDrkGAPZnr1wbNGiQGjdurLFjx6pz587aunWr5syZozlz5lj7MXDgQI0ZM0YVK1ZUSEiIhg0bpqCgIHXs2NEufcxNZBoAOIa9cu1mI+YXL14syXbEfKlSpaxt4uPjrRfFsiLbxcLrPDw80nUQAJA3qBXmPXINAOzHXrnWoEEDffXVV4qKitLo0aMVEhKiKVOmqGvXrtY2L7/8si5cuKA+ffooISFBTZs21bJly+Tl5WWfTuYBMg0A7MtsI+azXSxs2bLlLSuma9asye5HAgAywUNK8g65BgD2Z89ce/DBB/Xggw/edLvFYtHo0aM1evRou/Upr5BpAOAY9so1e42Yz3ax8L/DFq9cuaLY2Fjt2bMnV++PBgD8P2qFeYdcAwD7I9fyBpkGAI5hthHz2S4WTp48OcP1I0eO1Pnz57P7cQAAOBS5BgAwCzINAMzPHiPm3W77nf/x5JNP6v3338+tjwMA3MBiseRoQfaRawCQd8g0+yLTACBvmS3XbvsBJ/8VExPjNJMAn9w01dFdgAkUbfGao7sAE7i08Y1c+Zxcu7KDLHOmXPtl2VuO7gJMoETX+Y7uAkzgn0W5cysruWZfzpRpkrRr2XhHdwEuruSTHzq6CzCBpE+75dpnmS3Xsl0s7NSpk81rwzB08uRJbd++XcOGDcu1jgEA/p+zXnEyA3INAOyPXMsbZBoAOIbZci3bxUI/Pz+b125ubqpcubJGjx6tNm3a5FrHAAD/z81c2eNUyDUAsD9yLW+QaQDgGGbLtWwVC1NTU9WjRw/VrFlTRYsWzas+AQD+w2zh4yzINQBwDHIt95FpAOA4Zsu1bN1WXaBAAbVp00YJCQl51B0AgKOtX79e7du3V1BQkCwWi5YsWWKz3TAMDR8+XKVKlZK3t7fCwsJ06NAhmzZnz55V165d5evrK39/f/Xq1SvdUxh/+eUXNWvWTF5eXipTpozGj7f//EXkGgDALMg0AEBuyfYcjDVq1NBvv/2WF30BANyEPZ+GfOHCBd19992aMWNGhtvHjx+vadOmafbs2dqyZYt8fHwUHh6u5ORka5uuXbtq7969WrlypZYuXar169erT58+1u1JSUlq06aNgoODtWPHDr311lsaOXKk5syZc3tfUA6QawBgf2Z7aqSzINMAwDHMlmvZnrNwzJgxeumll/T666+rXr168vHxsdnu6+uba50DAFyT02HtKSkpSklJsVnn6ekpT0/PdG3btm2rtm3bZvg5hmFoypQpGjp0qDp06CBJ+vDDDxUQEKAlS5aoS5cu2r9/v5YtW6Zt27apfv36kqTp06frgQce0IQJExQUFKQFCxbo8uXLev/99+Xh4aHq1asrNjZWkyZNsikq2gO5BgD2Z7bbtZwFmQYAjmG2XMvyyMLRo0frwoULeuCBB7Rr1y499NBDKl26tIoWLaqiRYvK39+fuTEAII9YLDlboqOj5efnZ7NER0dnux9Hjx5VXFycwsLCrOv8/PzUsGFDxcTESJJiYmLk7+9vLRRKUlhYmNzc3LRlyxZrm+bNm8vDw8PaJjw8XAcOHNC5c+du92vKFnINABwnJ5mG9Mg0AHAss+ValkcWjho1Ss8++6zWrl2bl/0BAGTALYcpEhUVpcGDB9usy2hUYWbi4uIkSQEBATbrAwICrNvi4uJUsmRJm+0FCxZUsWLFbNqEhISk+4zr2+xxQkOuAYDj5DTXYItMAwDHMluuZblYaBiGJKlFixZ51hkAQMayPcHsf9zsluP8jFwDAMfJaa7BFpkGAI5ltlzL1vE468SLAAD7CAwMlCTFx8fbrI+Pj7duCwwM1KlTp2y2X716VWfPnrVpk9Fn3LgPeyDXAABmQaYBAHJLth5wUqlSpUxD6OzZsznqEAAgPWf5939ISIgCAwO1evVq1a5dW9K1Jxtv2bJFzz33nCQpNDRUCQkJ2rFjh+rVqydJWrNmjdLS0tSwYUNrm9dee01XrlyRu7u7JGnlypWqXLmyXedUItcAwDGcJdfMhEwDAMcxW65lq1g4atQo+fn55VVfAAA3Yc85MM6fP6/Dhw9bXx89elSxsbEqVqyYypYtq4EDB2rMmDGqWLGiQkJCNGzYMAUFBaljx46SpKpVq+r+++9X7969NXv2bF25ckX9+vVTly5dFBQUJEl64oknNGrUKPXq1UuvvPKK9uzZo6lTp2ry5Ml2O06JXAMARzHb3E7OgEwDAMcxW65lq1jYpUuXdJPWAwDynj2zZ/v27WrZsqX19fUHo0RGRuqDDz7Qyy+/rAsXLqhPnz5KSEhQ06ZNtWzZMnl5eVnfs2DBAvXr10+tW7eWm5ubIiIiNG3aNOt2Pz8/rVixQn379lW9evV0xx13aPjw4erTp4/9DlTkGgA4isnOqZwCmQYAjmO2XMtysZA5MADAcdzs+Cv43nvvtU6UnhGLxaLRo0dr9OjRN21TrFgxLVy48Jb7qVWrln766afb7mdOkWsA4Dj2zLX8gEwDAMcyW65l+2nIAAD7M9uwdmdArgGA45BruYtMAwDHMluuZblYmJaWlpf9AADArsg1AIBZkGkAgNyUrTkLAQCOYbILVQCAfI5cAwCYidlyjWIhALgAs82BAQDI38g1AICZmC3XKBYCgAuwyGTpAwDI18g1AICZmC3XKBYCgAsw25UqAED+Rq4BAMzEbLlGsRAAXIDZwgcAkL+RawAAMzFbrrk5ugMAAAAAAAAAnAMjCwHABVjM9ngtAEC+Rq4BAMzEbLlGsRAAXIDZhrUDAPI3cg0AYCZmyzWKhQDgAkx2oQoAkM+RawAAMzFbrlEsBAAX4Ga29AEA5GvkGgDATMyWazzgBABcgJslZwsAAM7EXpk2cuRIWSwWm6VKlSrW7cnJyerbt6+KFy+uwoULKyIiQvHx8bl8tAAAszPbuRrFQgAAAACmVb16dZ08edK6bNiwwbpt0KBB+vbbb/X5559r3bp1OnHihDp16uTA3gIA4HgUCwHABVgsOVsAAHAm9sy0ggULKjAw0LrccccdkqTExETNnTtXkyZNUqtWrVSvXj3NmzdPmzZt0ubNm3P5iAEAZmavXLPXiHmKhQDgAtxkydECAIAzyUmmpaSkKCkpyWZJSUm56b4OHTqkoKAg3XXXXeratauOHTsmSdqxY4euXLmisLAwa9sqVaqobNmyiomJyfPvAABgHvY8V7PHiHmKhQDgAhhZCAAwk5xkWnR0tPz8/GyW6OjoDPfTsGFDffDBB1q2bJlmzZqlo0ePqlmzZvrnn38UFxcnDw8P+fv727wnICBAcXFxdvgWAABmYbYR8zwNGQBcgLNOfAsAwO3ISa5FRUVp8ODBNus8PT0zbNu2bVvrn2vVqqWGDRsqODhYn332mby9vW+/EwAA3CAnuZaSkpJuhLynp+dNs+36iHkvLy+FhoYqOjpaZcuWzXTEfKNGjbLcJ0YWAoALcLNYcrQAAOBMcpJpnp6e8vX1tVludkL1X/7+/qpUqZIOHz6swMBAXb58WQkJCTZt4uPjFRgYmAdHDQAwq5zkmjOOmGdkIQAAAIB84fz58zpy5Iieeuop1atXT+7u7lq9erUiIiIkSQcOHNCxY8cUGhrq4J4CAPILZxwxT7EQAFwAgwMBAGZir1x76aWX1L59ewUHB+vEiRMaMWKEChQooMcff1x+fn7q1auXBg8erGLFisnX11f9+/dXaGhotm7VAgAgJ7l2q1uOM3PjiPn77rvPOmL+xtGFtzNinmIhALgAbiUGAJiJvXLtr7/+0uOPP66///5bJUqUUNOmTbV582aVKFFCkjR58mS5ubkpIiJCKSkpCg8P18yZM+3SNwCAeTjqfC2vRsxTLAQAF0CtEABgJvbKtU8//fSW2728vDRjxgzNmDHDPh0CAJiS2UbMUywEABfA06gAAGZCrgEAzMReuWavEfMUCwHABVgYWggAMBFyDQBgJvbKNXuNmOeiHgAAAAAAAABJjCwEAJfA+AsAgJmQawAAMzFbrlEsBAAXwNOQAQBmQq4BAMzEbLlGsRAAXIC5ogcAkN+RawAAMzFbrlEsBAAXYLILVQCAfI5cAwCYidlyjWIhALgAnhoJADATcg0AYCZmyzWehgwAAAAAAABAEsVCAHAJbjlcsio1NVXDhg1TSEiIvL29Vb58eb3++usyDMPaxjAMDR8+XKVKlZK3t7fCwsJ06NAhm885e/asunbtKl9fX/n7+6tXr146f/787R4+AMBk7JFpAADYi9lyzVn7BQC4gcViydGSVePGjdOsWbP09ttva//+/Ro3bpzGjx+v6dOnW9uMHz9e06ZN0+zZs7Vlyxb5+PgoPDxcycnJ1jZdu3bV3r17tXLlSi1dulTr169Xnz59cvU7AQC4LntkGgAA9mK2XGPOQgBwAfaKkE2bNqlDhw5q166dJKlcuXL65JNPtHXrVknXRhVOmTJFQ4cOVYcOHSRJH374oQICArRkyRJ16dJF+/fv17Jly7Rt2zbVr19fkjR9+nQ98MADmjBhgoKCgux0NAAAZ+Wcp0YAANwes+Wa04wsvHz5sg4cOKCrV686uisA4HRyOrIwJSVFSUlJNktKSkq6/TRu3FirV6/WwYMHJUm7du3Shg0b1LZtW0nS0aNHFRcXp7CwMOt7/Pz81LBhQ8XExEiSYmJi5O/vby0USlJYWJjc3Ny0ZcuWvPyanAq5BgA3Z7YRGGZHpgHArZkt1xxeLLx48aJ69eqlQoUKqXr16jp27JgkqX///nrzzTcd3DsAcA45nbMwOjpafn5+Nkt0dHS6/bz66qvq0qWLqlSpInd3d9WpU0cDBw5U165dJUlxcXGSpICAAJv3BQQEWLfFxcWpZMmSNtsLFiyoYsWKWduYGbkGAJkz29xOZkWmAUDWmC3XHN6vqKgo7dq1Sz/++KO8vLys68PCwrRo0SIH9gwAzCMqKkqJiYk2S1RUVLp2n332mRYsWKCFCxdq586dmj9/viZMmKD58+c7oNeuiVwDAJgFmQYA+ZPD5yxcsmSJFi1apEaNGtkMv6xevbqOHDniwJ4BgPPI6fB0T09PeXp6ZtpuyJAh1tGFklSzZk398ccfio6OVmRkpAIDAyVJ8fHxKlWqlPV98fHxql27tiQpMDBQp06dsvncq1ev6uzZs9b3mxm5BgCZc9bbrmCLTAOArDFbrjl8ZOHp06fT3a4mSRcuXDDdlw0At8uSwyWrLl68KDc322goUKCA0tLSJEkhISEKDAzU6tWrrduTkpK0ZcsWhYaGSpJCQ0OVkJCgHTt2WNusWbNGaWlpatiwYTZ645rINQDInD0yDTlHpgFA1pgt1xxeLKxfv76+++476+vrofPee+9ZTzwBIL+zWHK2ZFX79u31xhtv6LvvvtPvv/+ur776SpMmTdLDDz/8bz8sGjhwoMaMGaNvvvlGu3fvVrdu3RQUFKSOHTtKkqpWrar7779fvXv31tatW7Vx40b169dPXbp0yRdPQibXACBz9sg05ByZBgBZY7Zcc/htyGPHjlXbtm21b98+Xb16VVOnTtW+ffu0adMmrVu3ztHdAwCn4Gana07Tp0/XsGHD9Pzzz+vUqVMKCgrSM888o+HDh1vbvPzyy7pw4YL69OmjhIQENW3aVMuWLbOZy2jBggXq16+fWrduLTc3N0VERGjatGl2OQZHI9cAIHP2yjXkDJkGAFljtlxz+MjCpk2bKjY2VlevXlXNmjW1YsUKlSxZUjExMapXr56juwcATsFeIwuLFCmiKVOm6I8//tClS5d05MgRjRkzRh4eHjf0xaLRo0crLi5OycnJWrVqlSpVqmTzOcWKFdPChQv1zz//KDExUe+//74KFy6cW1+HUyPXACBzZhuBYVZkGgBkjdlyzeEjCyWpfPnyevfddx3dDQAAcgW5BgAwCzINAPIfhxcLv//+exUoUEDh4eE265cvX660tDS1bdvWQT0DAOdhMdmwdjMj1wAgc+SaayDTACBrzJZrDr8N+dVXX1Vqamq69YZh6NVXX3VAjwDA+djrNmTkHLkGAJkj01wDmQYAWWO2XHP4yMJDhw6pWrVq6dZXqVJFhw8fdkCPAMD5mG3CXDMj1wAgc+SaayDTACBrzJZrDh9Z6Ofnp99++y3d+sOHD8vHx8cBPQIA58PIQtdBrgFA5sg010CmAUDWmC3XHF4s7NChgwYOHKgjR45Y1x0+fFgvvviiHnroIQf2DACcB8VC10GuAUDmyDTXQKYBQNaYLdccXiwcP368fHx8VKVKFYWEhCgkJERVq1ZV8eLFNWHCBEd3DwCAbCHXAABmQaYBQP7k8DkL/fz8tGnTJq1cuVK7du2St7e3atWqpebNmzu6awDgNMz2dC0zI9cAIHPkmmsg0wAga8yWaw4vFkqSxWJRmzZt1KZNG0d3BQCckpu5ssf0yDUAuDVyzXWQaQCQObPlmlMUC1evXq3Vq1fr1KlTSktLs9n2/vvvO6hXAOA8zHalyuzINQC4NXLNdZBpAJA5s+Waw+csHDVqlNq0aaPVq1frzJkzOnfunM0CAOABJ66EXAOAzDkq0958801ZLBYNHDjQui45OVl9+/ZV8eLFVbhwYUVERCg+Pj5nOzIJMg0AssZs52oOH1k4e/ZsffDBB3rqqacc3RUAAHKMXAMA57Rt2za98847qlWrls36QYMG6bvvvtPnn38uPz8/9evXT506ddLGjRsd1FPnQaYBQP7k8JGFly9fVuPGjR3dDQBwapYc/gf7IdcAIHP2zrTz58+ra9euevfdd1W0aFHr+sTERM2dO1eTJk1Sq1atVK9ePc2bN0+bNm3S5s2bc+twXRaZBgBZY7ZzNYcXC59++mktXLjQ0d1weYs/+1RdH+2olk0aqGWTBurV7XFt2rDeuv2vP4/p5UH9Fd6yiVo2aaD/DRmkv/8+Y91+4vhxjRk5VB0fuE/NG9ZRpwfDNWfmdF25ctkRhwM7aXJ3OX0x7in99vUrurTxDbVvVjVdm8rBJfT5uCcVt3yYzqwaoQ3vPacyAX6SpLKB/rq08Y0Ml04ta1g/o16VO/X91J46uWyoTvwwVN9M6q6aFQLtdpxm4GbJ2QL7IdfyxvdLPlO/7o/q0fub6NH7m+jF57pp++YN1u3LvvlCrw7opUfvb6IHm9fW+X+SHNhbOCs3i0VDO9fW7umddOqjrto1tZNe7lTrpu2nPN1I/yyK1PMPpM9H5ExOMi0lJUVJSUk2S0pKyi3317dvX7Vr105hYWE263fs2KErV67YrK9SpYrKli2rmJiYPDl2V0Km5Z3vl3ym/t07q/P9TdX5/qZ66YZc+ycpUe9MeVPPdu2oiLBG6vFIW70zdZwunP/Hwb2Gs7mea79Me1jxHz6hXVMf1sudat60/eReDZX0aTc935Zcy22OOFfLy6k1HH4bcnJysubMmaNVq1apVq1acnd3t9k+adIkB/XMtZQMCNDzAwapTNlgSdJ33yzRkIH99NGni1Xqzjs14LneqlipsmbMmSdJemfGNL00oK/mfvSJ3Nzc9MfvvyktLU2vDh2pMmXL6sjhQxo7eoQuJV/SC4NfduShIQ/5eHto9+GT+vC7HVoU3TXd9pA7i2n1rD6av3S7xry3WkkXU1QtpKSSU65Kkv46lahy7aNt3tOzQwMNeqKZlm8+aN3H15O667sN+/XCxG9UsICbhvVqrW8mdVfFh8frampauv0iPWe94oT0yLW8UbxEgCKfGaCg0mUlSauXfaMx/xuoqXM/VXBIBaUkJ6vePU1U754mmj9nmoN7C2c1uEMNPX1fZT0zc4P2/5WgOnfdoVnPNVHSxcuavexXm7btG5RVg4oldOLsRQf11txykmvR0dEaNWqUzboRI0Zo5MiRGbb/9NNPtXPnTm3bti3dtri4OHl4eMjf399mfUBAgOLi4m67j2ZBpuWdO0oEKPKZ/goqXVaGpNXLvtUb/xukKXM/lQxDf585rZ7PD1KZcnfpVNxJzZz4hs6eOa2o1yc4uutwIoM6VFevsEp6dtbGf3OtuGY+20RJF6+ky7UHG5Qh1/KQvc/X8npqDYcXC3/55RfVrl1bkrRnzx6bbRZnnenRCTVr0dLm9XP9B+rLzz/Vnt2/6NSpUzp54rg+/HSxChcuLEka8Xq0wpo30vatm3VPo8YKbdJMoU2aWd9/Z+ky+uP3o/ry80UUC01sxeaDWvFvUS8jo/rcp+UxB/TazOXWdUePn7X+OS3NUPzZ8zbveah5NS1evVsXLl0blVo5uISK+xXS6++t1l+nEiVJb7y/Rts/GqCygf767YbPw83x69B1kGt5o2GTFjavu/Xur++XfK4De3crOKSCOnR+UpL0y8/piwHAdQ0rldB32//U8p+PS5KOnb6gR5uEqF6FO2zalSpaSG/1uEcdx67SF6+0dkRXTS8nvw6joqI0ePBgm3Wenp4Ztv3zzz/1wgsvaOXKlfLy8rr9neZTZFreuSddrvXTD0s+14G9v6jNgw/rf2MmWreVurOMnurdTxPHvKbUq1dVoKDDT+PhJBpWKqnvdtjm2iONQ1Sv/H9zzVtvdb9HD0ev0ufkWp6w56/EG6fWGDNmjHX99ak1Fi5cqFatWkmS5s2bp6pVq2rz5s1q1KhRlvfh8N8ya9eudXQXTCc1NVWrVy7XpUuXVKPW3Tr+15+yWCzy8PCwtvHw9JSbm5t2/bxT9zTKeB6SC+fPy9fPz17dhpOxWCy6v3FlTVrwk76Z1F13VyqlP06c01sfrdO3P+3P8D11KgepdqUgDZr4rXXdwWOndSbhgiIfrKfxH65TATeLurevp/1HT+mPuAQ7HY3r45/jroNcy3upqana8ONKJSdfUpUaN7+FFPivLQdPq3vrSqpQyleHTyapRnBRhVYuqaiP/r/IbLFI7/Zrqqnf7tWvfyU4rrMml5Nc8/T0vGlx8L927NihU6dOqW7dutZ1qampWr9+vd5++20tX75cly9fVkJCgs3owvj4eAUGMmUKmWYfqamp2phJrl248I8KFfKhUAgbWw6e+jfXiujwyX9Uo+y1XPvfR9utbSwWaU7fppq2dK9+/SvRgb01t5zkWkpKSrrpNG6VdTdOrXFjsTCzqTVcqlh43eHDh3XkyBE1b95c3t7eMgyDq1XZdPjQQT3d7XFdvnxZ3t6FNG7SNN1VvoKKFi0mL29vvT1lop7vP1CGDM2YOkmpqak6c+Z0hp/157E/9NmnCzRg0BA7HwWcRcmiPipSyFMvPdlco95dqaGzlqtNw4r6dOwTCu8/Vxtif0/3nsgH62v/0VPavOeYdd35i5cV3u89ffbmk4rqfm0E7OG//tZDgz5QKrcgw8TItdz3+5FDeun5bv/mnLdeGzNJZcuVd3S34EImfr1bRbzdtWNSR6WmGSrgZtHoRTv12Yaj1jaDO9TQ1VRDs37I+MIYXEvr1q21e/dum3U9evRQlSpV9Morr6hMmTJyd3fX6tWrFRERIUk6cOCAjh07ptDQUEd02SmRaXnj9yOHNOT5yBtybWKGuZaYcE6L5r+r8IciHNBLOLNJX+9REW8PbZ94Y679rM82/n+uDXqohlLTDM364ddbfBIcKTvTa9hrag2HFwv//vtvde7cWWvXrpXFYtGhQ4d01113qVevXipatKgmTpx4y/dnVIFNSSuY5auNZhJcrpw+WvSlzp8/rzWrlmv08P9p1nvzdVf5Cho7frLGjx2tzz75WG5ubrrv/gdUuWo1ubmlf8bNqfh4DezbR63vC1fHiEcdcCRwBm7/zrS69Kf9mr5okyTpl0Mn1bBmWfXueE+6YqGXR0E9dl8tvfnB2nTrZ0d1UszuPxQ5YpEKFHDTwMeb6ssJ3dS010wlX75ql+NxdW78g9xl5EWuXU5Jk0c+zLX/urNsOU2bu0gXL5zXhh9XafLY4Xpz+nsUDJFlnULLqXPTu9Rz+nrt/zNBtcoV07jIBjp59pIWrj+i2iHF9Fzbamr66reZfxhyxF65VqRIEdWoUcNmnY+Pj4oXL25d36tXLw0ePFjFihWTr6+v+vfvr9DQ0GyNwDCrnGaadLNcSyXXdC3Xps79VBcvnNfGf3Mt+j+5dvHCeY1+ZYDKlLtLT/R4xoG9hTPq1KicOjcNUa/pP2n/X9dy7c1uDRR37qIWrv/t31yrqmZRSx3dVdPLSa5ldXoNe06t4fCnIQ8aNEju7u46duyYChUqZF3/2GOPadmyZZm+Pzo6Wn5+fjbL5LfezMsuOy13dw+VKRusqtWqq++AwapYqbIWLfxIktSocRN9uXS5lq3ZoOVrN2rUG+N0+lS8gu4sbfMZp0+d0vO9u6vm3XUUNWxURrtBPnEm4aKuXE3V/t9P2aw/8PtplQnwT9f+4ZY1VMjLXQuW/Wyz/rE2d6tsqaLq88aX2vHrcW3d+6ciR36mcqWKZvj0ZWTMksMF9pMXuTZ72lt52WWX4e7urqDSZVWhcjV1f2aAQipU0jef85ROZN2YrvU16evdWrzpd+37M0Gf/vSb3v5+v17seO3JkY2rBqiEr5f2z3hE5xY+pXMLn1JwycIa+1R97ZnOiJ7c5EyZNnnyZD344IOKiIhQ8+bNFRgYqC+//DIP9uR6cpppUsa59s40HtIh2eZapDXXPrFuv3jxgka81FfehQrptTGTVLCg+y0+DfnR60/W0+Sv92hxzP/n2ozv92lwh39zrcq1XNv3doTOLnhSZxc8qeAShfXGU/W0e3onB/feXHKSa56envL19bVZMioW3ji1RsGCBVWwYEGtW7dO06ZNU8GCBRUQEGCdWuNGtzO1hsNHFq5YsULLly9X6dK2RauKFSvqjz/+yPT9GVVgL6U5/LCcQlqaoSuXr9is8y9aVJK0fetmnTt7Vs3vbWXddio+Xs/37q4q1apr2Kg3Mhx1iPzjytVU7dj/lyqVtZ0ct2KZO3Qsg7kGuz9YT99t+FVnEmyfrlXIy11paYYMw7CuSzOuvXbLyXPi8xu+KpeRF7n2ZwK37GfESEvTlSuXHd0NuJBCngWUZtiuS0tL0/U4+nT9b1q7+6TN9iX/u0+frj+ij388bKde5hMOzLUff/zR5rWXl5dmzJihGTNmOKZDTiynmSZlnGvHElJzrY9mYqQZ1ly7eOG8hr/0vNzdPTQ0egojMZGhQh4FlWbYBltq2v+fZ336U/pc++p/Yfr0p9/Itdxmh1yz59QaDq+qXbhwweYq1XVnz57N0q3EGU36mHYp/4XPjGmT1LhJcwUEltLFixe0/Iel2rl9q6bOfFeS9O2SL1XurvIqWrSodv8Sq0njo/X4k90UXC5E0rVC4XNPR6pUUJAGDBqihHP//4Ta4neUcMgxIe/5eHuofOni1tflgoqqVsVSOpd0UX/GJ2rywg36aPRj2hD7u9bt/E1tGlXSA00qK7z/XJvPuevOYmpau5w6vvRhun2s3npYY5+/X1NefEizvoiRm5tFLz3ZXFdT07Ru59F07ZExC9VCl5EXueZx6VKu9c9VffDONNVv2EQlAgJ16eJF/bjqB+2O3a7RE2ZKks79fUbnzp7RyeN/SpJ+/+2wChUqpBIBpVTEl4d14ZofdvylIQ/X1F9nzmv/Xwm6u1xx9WtXXR+tPSRJOns+RWfP294ueeVqmuITL+nQySRHdNm0yDXXkNNMk26Waxdv0jr/mP/ONNVr2EQlAkrp0sULWvdvro2aMPNaofDF55WSnKwXh76hSxcu6NKFC5IkX/+iKlCggIN7D2fxw84/9VLHmvrrzAXrbcj92lXTR/8WAjPMtdQ0nUq4pMPkWq6yR67Zc2oNhxcLmzVrpg8//FCvv/66pGtPYE1LS9P48ePVsmVLB/fOdZw7e1ajhr6qM2dOq3DhIqpQqZKmznxXDUOvPen42B+/a+b0yUpKTFSpoDvV4+ln9PiTkdb3b928SX/9eUx//XlM7cNtv/ctsfvseiywn7pV7tSKt5+2vh4/oJ0k6aPvd6rPG4v1zfp96v/WNxryVHNNHPSgDh47o8df+0SbfrG9khz5YD0dP5WkVVvTX506eOyMIl75SK/1aKUf33lGaYahXQdPqsOL8xX39z95e4AmwpSFroNcyxuJ585q0tihOvv3Gfn4FFa58pU0esJM1Wlw7Srp919/rk8+eMfa/tX+PSVJA6NGKaxtB4f0Gc7npXlbNPSxOprUq5FK+Hnp5NlLen/VQb35xS5Hdy3fIddcA5mWdxLPndXkscNuyLWKGjVhpuo0aKTdP2/XgX3XRg/1efwhm/e9t+g7BZQKckSX4YSGzNuqoZ1ra2LPhirh56W4c5c0b9VBvbn4F0d3Ld9xllybPHmy3NzcFBERoZSUFIWHh2vmzJnZ/hyLYfxnzKqd7dmzR61bt1bdunW1Zs0aPfTQQ9q7d6/Onj2rjRs3qnz57E9anpAPRxYi95UKG+7oLsAELm18I1c+Z+tviTl6/z13MbLKXvIi1w7FM7IQOVd3wGeO7gJM4J9FkZk3yoKc5BqZZj95kWmSdDCekYXImfovfOHoLsAEkj7tlmufZbZcc/ikdDVq1NDBgwfVtGlTdejQQRcuXFCnTp30888/33b4AIDZ8IAT10GuAUDmyDTXQKYBQNaYLdccfhuyJPn5+em1115zdDcAwHk5a4ogQ+QaAGSCXHMZZBoAZIHJcs0hxcJffsn6/fO1atXKw54AgGtgInjnRq4BQPaQa86LTAOA7DNbrjmkWFi7dm1ZLBZlNl2ixWJRairzDwKAs0yYi4yRawCQPeSa8yLTACD7zJZrDikWHj161BG7BQCXZbLsMR1yDQCyh1xzXmQaAGSf2XLNIcXC4OBgR+wWAIA8Qa4BAMyCTAMAOMUDTo4cOaIpU6Zo//79kqRq1arphRde4AlbAHCd2S5VmRy5BgCZINdcBpkGAFlgslxzc3QHli9frmrVqmnr1q2qVauWatWqpS1btqh69epauXKlo7sHAE7BksP/YD/kGgBkjkxzDWQaAGSN2XLN4SMLX331VQ0aNEhvvvlmuvWvvPKK7rvvPgf1DACch9kmzDUzcg0AMkeuuQYyDQCyxmy55vCRhfv371evXr3Sre/Zs6f27dvngB4BgPOx5HDJjuPHj+vJJ59U8eLF5e3trZo1a2r79u3W7YZhaPjw4SpVqpS8vb0VFhamQ4cO2XzG2bNn1bVrV/n6+srf31+9evXS+fPnb+fQXQ65BgCZs1emIWfINADIGrPlmsOLhSVKlFBsbGy69bGxsSpZsqT9OwQAzshO1cJz586pSZMmcnd31w8//KB9+/Zp4sSJKlq0qLXN+PHjNW3aNM2ePVtbtmyRj4+PwsPDlZycbG3TtWtX7d27VytXrtTSpUu1fv169enTJ0dfgasg1wAgC8x2VmVSZBoAZJHJcs3htyH37t1bffr00W+//abGjRtLkjZu3Khx48Zp8ODBDu4dAOQv48aNU5kyZTRv3jzrupCQEOufDcPQlClTNHToUHXo0EGS9OGHHyogIEBLlixRly5dtH//fi1btkzbtm1T/fr1JUnTp0/XAw88oAkTJigoKMi+B2Vn5BoAwCzINADInxxeLBw2bJiKFCmiiRMnKioqSpIUFBSkkSNHasCAAQ7uHQA4h5xOfJuSkqKUlBSbdZ6envL09LRZ98033yg8PFyPPvqo1q1bpzvvvFPPP/+8evfuLUk6evSo4uLiFBYWZn2Pn5+fGjZsqJiYGHXp0kUxMTHy9/e3FgolKSwsTG5ubtqyZYsefvjhHB2LsyPXACBzzjqhO2yRaQCQNWbLNYffhmyxWDRo0CD99ddfSkxMVGJiov766y+98MILsphthkgAuE0WS86W6Oho+fn52SzR0dHp9vPbb79p1qxZqlixopYvX67nnntOAwYM0Pz58yVJcXFxkqSAgACb9wUEBFi3xcXFpbs1qWDBgipWrJi1jZmRawCQuZxkGuyHTAOArDFbrjl8ZOGNihQp4uguAIBTymmGREVFpbtd6L+jCiUpLS1N9evX19ixYyVJderU0Z49ezR79mxFRkbmsBf5D7kGABlz0nMj3AKZBgA3Z7Zcc0ixsG7dulq9erWKFi2qOnXq3PKq1M6dO+3YMwBwUjlMn4xuOc5IqVKlVK1aNZt1VatW1eLFiyVJgYGBkqT4+HiVKlXK2iY+Pl61a9e2tjl16pTNZ1y9elVnz561vt9syDUAyCaznVWZCJkGALfBZLnmkGJhhw4drCetHTt2dEQXAMCl2GsOjCZNmujAgQM26w4ePKjg4GBJ1x52EhgYqNWrV1uLg0lJSdqyZYuee+45SVJoaKgSEhK0Y8cO1atXT5K0Zs0apaWlqWHDhnY5Dnsj1wAge8w2t5OZkGkAkH1myzWHFAtHjBhh/fOff/6prl27qmXLlo7oCgDgBoMGDVLjxo01duxYde7cWVu3btWcOXM0Z84cSdfmLho4cKDGjBmjihUrKiQkRMOGDVNQUJD1hKJq1aq6//771bt3b82ePVtXrlxRv3791KVLF9M+CZlcAwCYBZkGAHD4A05Onz6ttm3bqkyZMnr55Ze1a9cuR3cJAJxOTh9wklUNGjTQV199pU8++UQ1atTQ66+/rilTpqhr167WNi+//LL69++vPn36qEGDBjp//ryWLVsmLy8va5sFCxaoSpUqat26tR544AE1bdrUWnA0O3INADJntongzYpMA4CsMVuuWQzDMBzdiXPnzunzzz/XwoUL9dNPP6lKlSrq2rWrnnjiCZUrVy7bn5dwKTX3O4l8p1TYcEd3ASZwaeMbufI5+09cyNH7qwb55Eo/kDW5nWuH4i/lfieR79Qd8JmjuwAT+GdR7jzsKie5RqbZV25nmiQdjL+Yu51EvlP/hS8c3QWYQNKn3XLts8yWaw4fWShJRYsWVZ8+ffTjjz/qjz/+UPfu3fXRRx+pQoUKju4aADgHSw4X2BW5BgCZINNcBpkGAFlgslxzyJyFN3PlyhVt375dW7Zs0e+//66AgABHdwkAnILZJszNL8g1AMgYueZ6yDQAuDmz5ZpTjCxcu3atevfurYCAAHXv3l2+vr5aunSp/vrrL0d3DQCcgr3mLETuINcA4NbINNdBpgFA5syWaw4fWXjnnXfq7Nmzuv/++zVnzhy1b99enp6eju4WAAC3hVwDAJgFmQYA+ZPDi4UjR47Uo48+Kn9/f0d3BQCclpNecEIGyDUAyBy55hrINADIGrPlmsOLhb1793Z0FwDA+ZktfUyMXAOALCDXXAKZBgBZZLJcc3ixEACQObNNmAsAyN/INQCAmZgt15ziAScAgFvjAScAADOxV6bNmjVLtWrVkq+vr3x9fRUaGqoffvjBuj05OVl9+/ZV8eLFVbhwYUVERCg+Pj6XjxYAYHZmO1ejWAgALsCSwwUAAGdir0wrXbq03nzzTe3YsUPbt29Xq1at1KFDB+3du1eSNGjQIH377bf6/PPPtW7dOp04cUKdOnXKjUMEAOQjZjtX4zZkAAAAAKbUvn17m9dvvPGGZs2apc2bN6t06dKaO3euFi5cqFatWkmS5s2bp6pVq2rz5s1q1KiRI7oMAIDDMbIQAFwBQwsBAGaSg0xLSUlRUlKSzZKSkpLpLlNTU/Xpp5/qwoULCg0N1Y4dO3TlyhWFhYVZ21SpUkVly5ZVTExM7h4vAMDc7HSuZq/pNSgWAoALsOTwPwAAnElOMi06Olp+fn42S3R09E33tXv3bhUuXFienp569tln9dVXX6latWqKi4uTh4eH/P39bdoHBAQoLi4uj78BAICZ2OtczV7Ta3AbMgC4AGed+BYAgNuRk1yLiorS4MGDbdZ5enretH3lypUVGxurxMREffHFF4qMjNS6detuvwMAAPyHvc7X7DW9BsVCAHAB1AoBAGaSk1zz9PS8ZXHwvzw8PFShQgVJUr169bRt2zZNnTpVjz32mC5fvqyEhASb0YXx8fEKDAzMQQ8BAPlNTnItJSUl3XQaWcm61NRUff7551meXiM7xUJuQwYAV8CchQAAM3FgpqWlpSklJUX16tWTu7u7Vq9ebd124MABHTt2TKGhoTnfEQAg/8hBrjnj9BqMLAQAAABgSlFRUWrbtq3Kli2rf/75RwsXLtSPP/6o5cuXy8/PT7169dLgwYNVrFgx+fr6qn///goNDeVJyAAAu3HG6TUoFgKAC+AhJQAAM7FXrp06dUrdunXTyZMn5efnp1q1amn58uW67777JEmTJ0+Wm5ubIiIilJKSovDwcM2cOdMufQMAmEdOcs0Zp9egWAgALoAHnAAAzMReuTZ37txbbvfy8tKMGTM0Y8YM+3QIAGBKjjxfy2h6jYiICEm3P70GxUIAcAHUCgEAZkKuAQDMxF65Zq/pNSgWAoALYGQhAMBMyDUAgJnYK9fsNb0GxUIAcAmcVQEAzIRcAwCYiX1yzV7Ta7jl6N0AAAAAAAAATIORhQDgArhdCwBgJuQaAMBMzJZrFAsBwAWYLHsAAPkcuQYAMBOz5RrFQgBwAWa7UgUAyN/INQCAmZgt1ygWAoALsJjuWhUAID8j1wAAZmK2XKNYCACuwFzZAwDI78g1AICZmCzXeBoyAAAAAAAAAEmMLAQAl2CyC1UAgHyOXAMAmInZco1iIQC4ALNNmAsAyN/INQCAmZgt1ygWAoALMNuEuQCA/I1cAwCYidlyjWIhALgCc2UPACC/I9cAAGZislyjWAgALsBk2QMAyOfINQCAmZgt13gaMgDgpt58801ZLBYNHDjQui45OVl9+/ZV8eLFVbhwYUVERCg+Pt7mfceOHVO7du1UqFAhlSxZUkOGDNHVq1ft3HsAAAAAQHZRLAQAF2Cx5Gy5Hdu2bdM777yjWrVq2awfNGiQvv32W33++edat26dTpw4oU6dOlm3p6amql27drp8+bI2bdqk+fPn64MPPtDw4cNz8hUAAEzE3pkGAEBeMluuUSwEABdgyeF/2XX+/Hl17dpV7777rooWLWpdn5iYqLlz52rSpElq1aqV6tWrp3nz5mnTpk3avHmzJGnFihXat2+fPv74Y9WuXVtt27bV66+/rhkzZujy5cu59p0AAFyXPTMNAIC8ZrZco1gIAC4gpyMLU1JSlJSUZLOkpKTcdH99+/ZVu3btFBYWZrN+x44dunLlis36KlWqqGzZsoqJiZEkxcTEqGbNmgoICLC2CQ8PV1JSkvbu3ZvL3wwAwBWZbQQGACB/M1uuUSwEgHwgOjpafn5+Nkt0dHSGbT/99FPt3Lkzw+1xcXHy8PCQv7+/zfqAgADFxcVZ29xYKLy+/fo2AAAAAIDz4mnIAOACcnrFKSoqSoMHD7ZZ5+npma7dn3/+qRdeeEErV66Ul5dXznYKAMBNOOtICgAAbofZco2RhQCQD3h6esrX19dmyahYuGPHDp06dUp169ZVwYIFVbBgQa1bt07Tpk1TwYIFFRAQoMuXLyshIcHmffHx8QoMDJQkBQYGpns68vXX19sAAAAAAJwTxUIAcAH2esBJ69attXv3bsXGxlqX+vXrq2vXrtY/u7u7a/Xq1db3HDhwQMeOHVNoaKgkKTQ0VLt379apU6esbVauXClfX19Vq1Yt974UAIDLMttE8ACA/M1sucZtyADgAuw1rL1IkSKqUaOGzTofHx8VL17cur5Xr14aPHiwihUrJl9fX/Xv31+hoaFq1KiRJKlNmzaqVq2annrqKY0fP15xcXEaOnSo+vbtm+FoRgBA/mO227UAAPmb2XKNYiEAuABnyp7JkyfLzc1NERERSklJUXh4uGbOnGndXqBAAS1dulTPPfecQkND5ePjo8jISI0ePdqBvQYAOBNnyjUAAHLKbLlGsRAAXIED0+fHH3+0ee3l5aUZM2ZoxowZN31PcHCwvv/++zzuGQDAZZntrAoAkL+ZLNeYsxAAAAAAAACAJEYWAoBLcNaJbwEAuB3kGgDATMyWaxQLAcAFmG3CXABA/kauAQDMxGy5RrEQAFyAybIHAJDPkWsAADMxW64xZyEAuAJLDhcAAJyJnTItOjpaDRo0UJEiRVSyZEl17NhRBw4csGmTnJysvn37qnjx4ipcuLAiIiIUHx+fo8MDAOQzJjtXo1gIAC7AksP/AABwJvbKtHXr1qlv377avHmzVq5cqStXrqhNmza6cOGCtc2gQYP07bff6vPPP9e6det04sQJderUKbcPGQBgYmY7V+M2ZAAAAACmtGzZMpvXH3zwgUqWLKkdO3aoefPmSkxM1Ny5c7Vw4UK1atVKkjRv3jxVrVpVmzdvVqNGjRzRbQAAHIpiIQC4ALNNmAsAyN9ykmspKSlKSUmxWefp6SlPT89M35uYmChJKlasmCRpx44dunLlisLCwqxtqlSporJlyyomJoZiIQAgS8x2vmbKYqG/dwFHd8GppaSkKDo6WlFRUVn6R1V+dWnjG47uglPj58i+vEz52xpZVTHA29FdcGr8PsqafxZFOroLTo2fI/vKSa6NHBOtUaNG2awbMWKERo4cecv3paWlaeDAgWrSpIlq1KghSYqLi5OHh4f8/f1t2gYEBCguLu72O4lbqhRQyNFdcGr8Pspc0qfdHN0Fp8bPkP2Z7XzNYhiG4ehOwL6SkpLk5+enxMRE+fr6Oro7cFH8HAFwFvw+Qm7g58h13O7Iwueee04//PCDNmzYoNKlS0uSFi5cqB49eqT7vHvuuUctW7bUuHHjcrfzQBbw+wg5xc8QcspktU8AAAAAZpbVW45v1K9fPy1dulTr16+3FgolKTAwUJcvX1ZCQoLN6ML4+HgFBgbmVpcBAHApPA0ZAAAAgCkZhqF+/frpq6++0po1axQSEmKzvV69enJ3d9fq1aut6w4cOKBjx44pNDTU3t0FAMApMLIQAAAAgCn17dtXCxcu1Ndff60iRYpY5yH08/OTt7e3/Pz81KtXLw0ePFjFihWTr6+v+vfvr9DQUB5uAgDItygW5kOenp4aMWIEE50iR/g5AuAs+H2E3MDPkTnNmjVLknTvvffarJ83b566d+8uSZo8ebLc3NwUERGhlJQUhYeHa+bMmXbuKfD/+H2EnOJnCDnFA04AAAAAAAAASGLOQgAAAAAAAAD/olgIAAAAAAAAQBLFQgAAAAAAAAD/oliIXFOuXDlNmTLF0d3ALYwcOVK1a9fOcvvff/9dFotFsbGxedYnAHBW5JpzI9MAIOvINOdHrsGZUCwE8pGXXnpJq1evdnQ3AADIMTINAGAm5BqcSUFHdwD2c/nyZXl4eDi6G3CgwoULq3Dhwo7uBgDkCnItfyPTAJgJmQZyDc6EkYVO7N5779WAAQP08ssvq1ixYgoMDNTIkSOt248dO6YOHTqocOHC8vX1VefOnRUfH2/dfn0Y83vvvaeQkBB5eXlJkiwWi9555x09+OCDKlSokKpWraqYmBgdPnxY9957r3x8fNS4cWMdOXLE+llHjhxRhw4dFBAQoMKFC6tBgwZatWqV3b4LZM2cOXMUFBSktLQ0m/UdOnRQz5490w1tT0tL0+jRo1W6dGl5enqqdu3aWrZs2S33sWfPHrVt21aFCxdWQECAnnrqKZ05c8a6PbOfW0lKSEjQM888o4CAAHl5ealGjRpaunSpdfuGDRvUrFkzeXt7q0yZMhowYIAuXLhw+18MAKdAriE7yDQAzoxMQ3aRa3AlFAud3Pz58+Xj46MtW7Zo/PjxGj16tFauXKm0tDR16NBBZ8+e1bp167Ry5Ur99ttveuyxx2zef/jwYS1evFhffvmlzVwGr7/+urp166bY2FhVqVJFTzzxhJ555hlFRUVp+/btMgxD/fr1s7Y/f/68HnjgAa1evVo///yz7r//frVv317Hjh2z11eBLHj00Uf1999/a+3atdZ1Z8+e1bJly9S1a9d07adOnaqJEydqwoQJ+uWXXxQeHq6HHnpIhw4dyvDzExIS1KpVK9WpU0fbt2/XsmXLFB8fr86dO9u0u9nPrXQt9Nq2bauNGzfq448/1r59+/Tmm2+qQIECkq79Y+f+++9XRESEfvnlFy1atEgbNmyw+XkE4LrINWQVmQbA2ZFpyA5yDS7FgNNq0aKF0bRpU5t1DRo0MF555RVjxYoVRoECBYxjx45Zt+3du9eQZGzdutUwDMMYMWKE4e7ubpw6dcrmMyQZQ4cOtb6OiYkxJBlz5861rvvkk08MLy+vW/avevXqxvTp062vg4ODjcmTJ2f7OJG7OnToYPTs2dP6+p133jGCgoKM1NRUY8SIEcbdd99t3RYUFGS88cYbNu9v0KCB8fzzzxuGYRhHjx41JBk///yzYRiG8frrrxtt2rSxaf/nn38akowDBw4YhnHrn1vDMIzly5cbbm5u1vb/1atXL6NPnz4263766SfDzc3NuHTpUha/BQDOiFxDdpFpAJwVmYbbQa7BVTCy0MnVqlXL5nWpUqV06tQp7d+/X2XKlFGZMmWs26pVqyZ/f3/t37/fui44OFglSpS45ecGBARIkmrWrGmzLjk5WUlJSZKuXa166aWXVLVqVfn7+6tw4cLav38/V6ucUNeuXbV48WKlpKRIkhYsWKAuXbrIzc32f/ekpCSdOHFCTZo0sVnfpEkTm5+hG+3atUtr1661zqdRuHBhValSRZJsboW42c+tJMXGxqp06dKqVKnSTffxwQcf2OwjPDxcaWlpOnr0aDa+CQDOiFxDdpBpAJwZmYbsItfgKnjAiZNzd3e3eW2xWNLNcXArPj4+mX6uxWK56brr+3rppZe0cuVKTZgwQRUqVJC3t7ceeeQRXb58Oct9gX20b99ehmHou+++U4MGDfTTTz9p8uTJufLZ58+fV/v27TVu3Lh020qVKmX9861+br29vTPdxzPPPKMBAwak21a2bNnb6TYAJ0KuITvINADOjExDdpFrcBUUC11U1apV9eeff+rPP/+0XrHat2+fEhISVK1atVzf38aNG9W9e3c9/PDDkq79kvj9999zfT/IOS8vL3Xq1EkLFizQ4cOHVblyZdWtWzddO19fXwUFBWnjxo1q0aKFdf3GjRt1zz33ZPjZdevW1eLFi1WuXDkVLHh7vz5q1aqlv/76SwcPHszwilXdunW1b98+VahQ4bY+H4BrIteQETINgCsi03Az5BpcBbchu6iwsDDVrFlTXbt21c6dO7V161Z169ZNLVq0UP369XN9fxUrVrROvLtr1y498cQT2bpqBvvq2rWrvvvuO73//vsZTpZ73ZAhQzRu3DgtWrRIBw4c0KuvvqrY2Fi98MILGbbv27evzp49q8cff1zbtm3TkSNHtHz5cvXo0UOpqalZ6luLFi3UvHlzRUREaOXKlTp69Kh++OEH65O9XnnlFW3atEn9+vVTbGysDh06pK+//ppJcwGTI9dwM2QaAFdDpuFWyDW4AoqFLspisejrr79W0aJF1bx5c4WFhemuu+7SokWL8mR/kyZNUtGiRdW4cWO1b99e4eHhGV4BgXNo1aqVihUrpgMHDuiJJ564absBAwZo8ODBevHFF1WzZk0tW7ZM33zzjSpWrJhh++tXt1JTU9WmTRvVrFlTAwcOlL+/f7p5Nm5l8eLFatCggR5//HFVq1ZNL7/8sjXAatWqpXXr1ungwYNq1qyZ6tSpo+HDhysoKCh7XwIAl0Ku4WbINACuhkzDrZBrcAUWwzAMR3cCAAAAAAAAgOMxshAAAAAAAACAJIqFAAAAAAAAAP5FsRAAAAAAAACAJIqFAAAAAAAAAP5FsRAAAAAAAACAJIqFAAAAAAAAAP5FsRAAAAAAAACAJIqFAAAAAAAAAP5FsRCQ1L17d3Xs2NH6+t5779XAgQPt3o8ff/xRFotFCQkJdt83AMAcyDQAgJmQa4D9USyEU+vevbssFossFos8PDxUoUIFjR49WlevXs3T/X755Zd6/fXXs9SW0AAAZAWZBgAwE3INMK+Cju4AkJn7779f8+bNU0pKir7//nv17dtX7u7uioqKsml3+fJleXh45Mo+ixUrliufAwDAjcg0AICZkGuAOTGyEE7P09NTgYGBCg7+v/buJiTKLY7j+E+Shkdnwl5FTUuQbASRLAg3yYCRmxiSCHqdyIKySCxLWwRF1ETQolpoi0KLiiJpkDGIIcqsqEVhi7AhJanARdALTDHj5Jy7uDaXuVa3eyFwnvv9LM85zzlnHgZ+8H8OzzNPO3bsUE1Njbq7u5PH0Y8ePar8/HyVlpZKkt68eaM1a9YoJydHM2bMkNfr1fDwcHK+sbEx7dmzRzk5OZo5c6b2798vY0zKmn8/2h6LxdTS0qLCwkI5HA6VlJTo3LlzGh4elsfjkSRNnz5dGRkZ2rx5syQpkUjI7/eruLhYlmWpoqJC169fT1nn5s2bWrBggSzLksfjSdknAMB+yDQAgJ2Qa4A9USxE2rEsS6Ojo5Kk27dvKxwOKxQKKRgMKh6Pa8WKFXK5XOrr69ODBw/kdDpVW1ubvObkyZPq6OjQ+fPndf/+fb1//143btz46ZqbNm3SlStXdPr0aQ0MDOjs2bNyOp0qLCxUV1eXJCkcDmtkZESnTp2SJPn9fl24cEHt7e16/vy5mpqatGHDBvX29kr6Myjr6uq0cuVK9ff3a+vWrWptbf1dtw0AMAmRaQAAOyHXAJswwCTm8/mM1+s1xhiTSCRMKBQyDofDNDc3G5/PZ3Jzc00sFkuOv3jxoiktLTWJRCLZFovFjGVZ5tatW8YYY/Ly8syJEyeS/fF43MydOze5jjHGVFdXm8bGRmOMMeFw2EgyoVDou3u8c+eOkWQ+fPiQbItGoyYrK8s8fPgwZWx9fb1Zu3atMcaYAwcOmLKyspT+lpaWCXMBAOyBTAMA2Am5BtgX7yzEpBcMBuV0OhWPx5VIJLRu3TodOnRIO3fuVHl5ecq7L549e6bBwUG5XK6UOaLRqIaGhvTp0yeNjIxo6dKlyb7MzEwtWbJkwvH2b/r7+zVlyhRVV1f/8p4HBwf15csXLV++PKV9dHRUixYtkiQNDAyk7EOSqqqqfnkNAED6IdMAAHZCrgH2RLEQk57H41FbW5umTp2q/Px8ZWb+9bfNzs5OGRuJRLR48WJdunRpwjyzZ8/+T+tblvWvr4lEIpKknp4eFRQUpPQ5HI7/tA8AQPoj0wAAdkKuAfZEsRCTXnZ2tkpKSn5pbGVlpa5evao5c+Zo2rRp3x2Tl5enx48fa9myZZKkr1+/6smTJ6qsrPzu+PLyciUSCfX29qqmpmZC/7enZWNjY8m2srIyORwOvX79+odPudxut7q7u1PaHj169M8/EgCQtsg0AICdkGuAPfGBE9jK+vXrNWvWLHm9XvX19enVq1e6e/eudu/erbdv30qSGhsbdfz4cQUCAb148UINDQ36+PHjD+ecP3++fD6ftmzZokAgkJzz2rVrkqR58+YpIyNDwWBQ7969UyQSkcvlUnNzs5qamtTZ2amhoSE9ffpUZ86cUWdnpyRp+/btevnypfbt26dwOKzLly+ro6Pjd98iAECaINMAAHZCrgHpg2IhbCUrK0v37t1TUVGR6urq5Ha7VV9fr2g0mnx6tXfvXm3cuFE+n09VVVVyuVxatWrVT+dta2vT6tWr1dDQoIULF2rbtm36/PmzJKmgoECHDx9Wa2urcnNztWvXLknSkSNHdPDgQfn9frndbtXW1qqnp0fFxcWSpKKiInV1dSkQCKiiokLt7e06duzYb7w7AIB0QqYBAOyEXAPSR4b50ZtCAQAAAAAAAPyvcLIQAAAAAAAAgCSKhQAAAAAAAADGUSwEAAAAAAAAIIliIQAAAAAAAIBxFAsBAAAAAAAASKJYCAAAAAAAAGAcxUIAAAAAAAAAkigWAgAAAAAAABhHsRAAAAAAAACAJIqFAAAAAAAAAMZRLAQAAAAAAAAgSfoDFKrc6wp5IqEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'quantized': False, 'weight_decay': 0, 'dropout': 0.1}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 01:12, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.601600</td>\n",
              "      <td>0.645346</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.689015</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.686102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.390600</td>\n",
              "      <td>0.506038</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.762477</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.472700</td>\n",
              "      <td>0.507116</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.772054</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.976600</td>\n",
              "      <td>0.536973</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.793344</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.780601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.832000</td>\n",
              "      <td>0.496790</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.770076</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769456</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.316400</td>\n",
              "      <td>0.507609</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.763278</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.316400</td>\n",
              "      <td>0.504195</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783983</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.486300</td>\n",
              "      <td>0.496281</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774661</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.499558</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769586</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.501562</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765298</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.8185990338164251, 'precision': 0.8200421326155253, 'recall': 0.8185990338164251, 'f1_score': 0.8122969257685578}\n",
            "Val Set: {'accuracy': 0.782608695652174, 'precision': 0.783982980016716, 'recall': 0.782608695652174, 'f1_score': 0.7747747747747747}\n",
            "Test Set: {'accuracy': 0.8103448275862069, 'precision': 0.813701923076923, 'recall': 0.8103448275862069, 'f1_score': 0.8}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'quantized': True, 'weight_decay': 0, 'dropout': 0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2331' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2331/2590 02:19 < 00:15, 16.75 it/s, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.638859</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.697028</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.682904</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.507821</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.735227</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.734657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.523599</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.757769</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756227</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.816400</td>\n",
              "      <td>0.546196</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.780792</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.772520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.687500</td>\n",
              "      <td>0.520482</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769749</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.283200</td>\n",
              "      <td>0.531972</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.776928</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>0.520533</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.771226</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.332000</td>\n",
              "      <td>0.521416</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769749</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.524006</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.761364</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760757</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.7983091787439613, 'precision': 0.8039095431483909, 'recall': 0.7983091787439613, 'f1_score': 0.8111287039131418}\n",
            "Val Set: {'accuracy': 0.7695652173913043, 'precision': 0.7720543345543347, 'recall': 0.7695652173913043, 'f1_score': 0.7800829875518672}\n",
            "Test Set: {'accuracy': 0.8017241379310345, 'precision': 0.8049879807692308, 'recall': 0.8017241379310345, 'f1_score': 0.8114754098360656}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'quantized': True, 'weight_decay': 0.01, 'dropout': 0.1}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2331' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2331/2590 02:19 < 00:15, 16.65 it/s, Epoch 9/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.575934</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.714392</td>\n",
              "      <td>0.695652</td>\n",
              "      <td>0.688853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.357400</td>\n",
              "      <td>0.493419</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774661</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.474600</td>\n",
              "      <td>0.497554</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.775245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.574200</td>\n",
              "      <td>0.508602</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.778864</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.767628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.753900</td>\n",
              "      <td>0.485148</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787152</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.294900</td>\n",
              "      <td>0.490268</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786978</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.488417</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779296</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.554700</td>\n",
              "      <td>0.484443</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.406200</td>\n",
              "      <td>0.484664</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778450</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778223</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.8188405797101449, 'precision': 0.8196788516832395, 'recall': 0.8188405797101449, 'f1_score': 0.8233631653320772}\n",
            "Val Set: {'accuracy': 0.7869565217391304, 'precision': 0.7869782214156079, 'recall': 0.7869565217391304, 'f1_score': 0.7860262008733624}\n",
            "Test Set: {'accuracy': 0.8405172413793104, 'precision': 0.8405425492382015, 'recall': 0.8405172413793104, 'f1_score': 0.8412017167381974}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 2:** layers to apply LoRA/QLoRA most efficiently"
      ],
      "metadata": {
        "id": "r3kz6lK8Ax8N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_class = GetTrainer(num_epochs = 10, lr = 1e-4, weight_decay=0.01)\n",
        "choosen_layers_list = [[1], [6], [11], [1, 6], [6, 11], [5, 6], [0, 1, 5], [5, 6, 11], [9, 10, 11], [4, 5, 6, 7], [5, 6, 10, 11], [6, 9, 10, 11], [7,8,9,10,11,12], list(range(12))]\n",
        "\n",
        "for choosen_layers in choosen_layers_list:\n",
        "    #model\n",
        "    model_with_lora, model_info = model_class.get_model_with_lora(quantized = True, lora_rank = 8, scaling_factor = 32, dropout = 0.1, chosen_layers = choosen_layers)\n",
        "\n",
        "    #trainer\n",
        "    trainer_class = GetTrainer(num_epochs = 10, lr = 1e-4, weight_decay=0.01)\n",
        "    trainer, training_hyperparameters_info = trainer_class.get_trainer(model_with_lora, pytorch_train, pytorch_val)\n",
        "    trainer.train()\n",
        "\n",
        "    #evaluation\n",
        "    print(model_info)\n",
        "    print(\"train set: \", trainer.evaluate(eval_dataset = pytorch_train))\n",
        "    print(\"val set: \", trainer.evaluate(eval_dataset = pytorch_val))\n",
        "    print(\"test set: \", trainer.evaluate(eval_dataset = pytorch_test))\n",
        "    # evaluation_class = EvaluationClass(model_with_lora, device, class_names, tokenizer)\n",
        "    # evaluation_class.set_info(model_info, training_hyperparameters_info)\n",
        "    # print(\"\\nVal data\")\n",
        "    # evaluation_class.plot_confusion_matrix(val_data)\n",
        "    # print(\"\\nTest data\")\n",
        "    # evaluation_class.plot_confusion_matrix(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5Q0k7UzJ89OG",
        "outputId": "b3c7ae87-172c-4a0b-f606-012d3adc6b44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:55, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.574200</td>\n",
              "      <td>0.576766</td>\n",
              "      <td>0.721739</td>\n",
              "      <td>0.733684</td>\n",
              "      <td>0.721739</td>\n",
              "      <td>0.718137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.511379</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.780792</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.772520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.514861</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.781863</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.675800</td>\n",
              "      <td>0.513995</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.784477</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.812500</td>\n",
              "      <td>0.506182</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.793367</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.785786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.498692</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.798382</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.289100</td>\n",
              "      <td>0.493444</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.804513</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.300800</td>\n",
              "      <td>0.495754</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.797055</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.445300</td>\n",
              "      <td>0.491559</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.562500</td>\n",
              "      <td>0.491780</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.812094</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808173</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.4314236044883728, 'eval_accuracy': 0.8084541062801932, 'eval_precision': 0.8084662724451079, 'eval_recall': 0.8084541062801932, 'eval_f1_score': 0.8084522175794518, 'eval_runtime': 9.1848, 'eval_samples_per_second': 450.744, 'eval_steps_per_second': 28.199, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.49155911803245544, 'eval_accuracy': 0.8130434782608695, 'eval_precision': 0.8159340659340659, 'eval_recall': 0.8130434782608695, 'eval_f1_score': 0.8126148657610034, 'eval_runtime': 0.5644, 'eval_samples_per_second': 407.48, 'eval_steps_per_second': 26.575, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.4645406901836395, 'eval_accuracy': 0.7931034482758621, 'eval_precision': 0.795297993411201, 'eval_recall': 0.7931034482758621, 'eval_f1_score': 0.7927183381728836, 'eval_runtime': 0.5988, 'eval_samples_per_second': 387.436, 'eval_steps_per_second': 25.05, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1813' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1813/2590 01:45 < 00:45, 17.17 it/s, Epoch 7/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.634918</td>\n",
              "      <td>0.660870</td>\n",
              "      <td>0.674371</td>\n",
              "      <td>0.660870</td>\n",
              "      <td>0.654175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.445300</td>\n",
              "      <td>0.517357</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.748918</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.742069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.386700</td>\n",
              "      <td>0.495397</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.757222</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.718800</td>\n",
              "      <td>0.505910</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.784477</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.625000</td>\n",
              "      <td>0.505978</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.776000</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.501639</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.761364</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.494100</td>\n",
              "      <td>0.501282</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.767238</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.764773</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.46212634444236755, 'eval_accuracy': 0.7905797101449276, 'eval_precision': 0.796603638745794, 'eval_recall': 0.7905797101449276, 'eval_f1_score': 0.7895109682848485, 'eval_runtime': 9.3124, 'eval_samples_per_second': 444.57, 'eval_steps_per_second': 27.813, 'epoch': 7.0}\n",
            "val set:  {'eval_loss': 0.505910336971283, 'eval_accuracy': 0.7782608695652173, 'eval_precision': 0.7844774273345702, 'eval_recall': 0.7782608695652173, 'eval_f1_score': 0.777042823744084, 'eval_runtime': 0.5539, 'eval_samples_per_second': 415.215, 'eval_steps_per_second': 27.079, 'epoch': 7.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.4474676847457886, 'eval_accuracy': 0.7974137931034483, 'eval_precision': 0.8074913561275452, 'eval_recall': 0.7974137931034483, 'eval_f1_score': 0.7957402169229905, 'eval_runtime': 0.5596, 'eval_samples_per_second': 414.546, 'eval_steps_per_second': 26.803, 'epoch': 7.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.636700</td>\n",
              "      <td>0.652717</td>\n",
              "      <td>0.682609</td>\n",
              "      <td>0.682733</td>\n",
              "      <td>0.682609</td>\n",
              "      <td>0.682555</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.519500</td>\n",
              "      <td>0.523743</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.735227</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.734657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.550800</td>\n",
              "      <td>0.512704</td>\n",
              "      <td>0.747826</td>\n",
              "      <td>0.747901</td>\n",
              "      <td>0.747826</td>\n",
              "      <td>0.747807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.632800</td>\n",
              "      <td>0.502836</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779976</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.679700</td>\n",
              "      <td>0.499287</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.503040</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765539</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.433600</td>\n",
              "      <td>0.496637</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.492799</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787152</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786920</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.421900</td>\n",
              "      <td>0.494073</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.671900</td>\n",
              "      <td>0.493037</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773913</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.4550328254699707, 'eval_accuracy': 0.7963768115942029, 'eval_precision': 0.7963885014018383, 'eval_recall': 0.7963768115942029, 'eval_f1_score': 0.7963748038076643, 'eval_runtime': 9.2085, 'eval_samples_per_second': 449.583, 'eval_steps_per_second': 28.126, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.49279892444610596, 'eval_accuracy': 0.7869565217391304, 'eval_precision': 0.7871519370460048, 'eval_recall': 0.7869565217391304, 'eval_f1_score': 0.786920269989223, 'eval_runtime': 0.5625, 'eval_samples_per_second': 408.864, 'eval_steps_per_second': 26.665, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.45760372281074524, 'eval_accuracy': 0.7974137931034483, 'eval_precision': 0.7974358974358975, 'eval_recall': 0.7974137931034483, 'eval_f1_score': 0.7974100291696857, 'eval_runtime': 0.6055, 'eval_samples_per_second': 383.13, 'eval_steps_per_second': 24.771, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:00, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.574200</td>\n",
              "      <td>0.589029</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.681159</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.637681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.495160</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.773055</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.768827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.511700</td>\n",
              "      <td>0.494081</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.778034</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.605500</td>\n",
              "      <td>0.548285</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.792063</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.621100</td>\n",
              "      <td>0.488010</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765539</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.279300</td>\n",
              "      <td>0.479908</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.345700</td>\n",
              "      <td>0.491389</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.473590</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783983</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.396500</td>\n",
              "      <td>0.471603</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783983</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.494100</td>\n",
              "      <td>0.470941</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787152</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786920</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.36468902230262756, 'eval_accuracy': 0.8463768115942029, 'eval_precision': 0.8465194661108122, 'eval_recall': 0.8463768115942029, 'eval_f1_score': 0.8463609991366472, 'eval_runtime': 9.3255, 'eval_samples_per_second': 443.944, 'eval_steps_per_second': 27.773, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.47094088792800903, 'eval_accuracy': 0.7869565217391304, 'eval_precision': 0.7871519370460048, 'eval_recall': 0.7869565217391304, 'eval_f1_score': 0.786920269989223, 'eval_runtime': 0.6312, 'eval_samples_per_second': 364.372, 'eval_steps_per_second': 23.763, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.3992120027542114, 'eval_accuracy': 0.8146551724137931, 'eval_precision': 0.8152408606954061, 'eval_recall': 0.8146551724137931, 'eval_f1_score': 0.8145690440342758, 'eval_runtime': 0.5603, 'eval_samples_per_second': 414.07, 'eval_steps_per_second': 26.772, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/2590 02:03 < 00:31, 16.70 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.597700</td>\n",
              "      <td>0.607507</td>\n",
              "      <td>0.643478</td>\n",
              "      <td>0.684062</td>\n",
              "      <td>0.643478</td>\n",
              "      <td>0.622679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.414100</td>\n",
              "      <td>0.503363</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.772054</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.502191</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.783077</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.761700</td>\n",
              "      <td>0.532846</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.683600</td>\n",
              "      <td>0.501919</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.406200</td>\n",
              "      <td>0.502972</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.283200</td>\n",
              "      <td>0.499134</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.269500</td>\n",
              "      <td>0.492527</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782694</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.40935611724853516, 'eval_accuracy': 0.8227053140096618, 'eval_precision': 0.8228511843667143, 'eval_recall': 0.8227053140096618, 'eval_f1_score': 0.8226852854624761, 'eval_runtime': 9.3811, 'eval_samples_per_second': 441.314, 'eval_steps_per_second': 27.609, 'epoch': 8.0}\n",
            "val set:  {'eval_loss': 0.501919150352478, 'eval_accuracy': 0.7913043478260869, 'eval_precision': 0.7920994768367579, 'eval_recall': 0.7913043478260869, 'eval_f1_score': 0.7911622276029056, 'eval_runtime': 0.581, 'eval_samples_per_second': 395.901, 'eval_steps_per_second': 25.82, 'epoch': 8.0}\n",
            "test set:  {'eval_loss': 0.40183863043785095, 'eval_accuracy': 0.7974137931034483, 'eval_precision': 0.7979673888764798, 'eval_recall': 0.7974137931034483, 'eval_f1_score': 0.7973196527816502, 'eval_runtime': 0.5747, 'eval_samples_per_second': 403.705, 'eval_steps_per_second': 26.102, 'epoch': 8.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:40, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.641508</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.722567</td>\n",
              "      <td>0.686957</td>\n",
              "      <td>0.673913</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.390600</td>\n",
              "      <td>0.497588</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.752652</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.752057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.593800</td>\n",
              "      <td>0.487466</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.768137</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.764577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.808600</td>\n",
              "      <td>0.509443</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.782456</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.772190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.769500</td>\n",
              "      <td>0.485190</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774661</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.481547</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.787500</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.482400</td>\n",
              "      <td>0.478142</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.351600</td>\n",
              "      <td>0.473641</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.788024</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.396500</td>\n",
              "      <td>0.472936</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.566400</td>\n",
              "      <td>0.472801</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3874528110027313, 'eval_accuracy': 0.8309178743961353, 'eval_precision': 0.8319603394074697, 'eval_recall': 0.8309178743961353, 'eval_f1_score': 0.8307850266820132, 'eval_runtime': 9.3616, 'eval_samples_per_second': 442.233, 'eval_steps_per_second': 27.666, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.47814199328422546, 'eval_accuracy': 0.7913043478260869, 'eval_precision': 0.7920994768367579, 'eval_recall': 0.7913043478260869, 'eval_f1_score': 0.7911622276029056, 'eval_runtime': 0.5626, 'eval_samples_per_second': 408.819, 'eval_steps_per_second': 26.662, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.42628636956214905, 'eval_accuracy': 0.8232758620689655, 'eval_precision': 0.8252336448598131, 'eval_recall': 0.8232758620689655, 'eval_f1_score': 0.8230095082150233, 'eval_runtime': 0.5753, 'eval_samples_per_second': 403.254, 'eval_steps_per_second': 26.072, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:10, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.386700</td>\n",
              "      <td>0.529738</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.711668</td>\n",
              "      <td>0.700000</td>\n",
              "      <td>0.695808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.318400</td>\n",
              "      <td>0.494192</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.776928</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.621100</td>\n",
              "      <td>0.504136</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.784762</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.793000</td>\n",
              "      <td>0.534103</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.788668</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.770987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.652300</td>\n",
              "      <td>0.486413</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.802286</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.322300</td>\n",
              "      <td>0.477412</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779296</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778055</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.148400</td>\n",
              "      <td>0.474490</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.828927</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.221700</td>\n",
              "      <td>0.464844</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.365200</td>\n",
              "      <td>0.462551</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826977</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.543000</td>\n",
              "      <td>0.463791</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808681</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.2916662096977234, 'eval_accuracy': 0.8814009661835749, 'eval_precision': 0.8814331016709148, 'eval_recall': 0.8814009661835749, 'eval_f1_score': 0.8813984681583587, 'eval_runtime': 9.4488, 'eval_samples_per_second': 438.152, 'eval_steps_per_second': 27.411, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.46255093812942505, 'eval_accuracy': 0.8260869565217391, 'eval_precision': 0.8269770263098035, 'eval_recall': 0.8260869565217391, 'eval_f1_score': 0.8259685230024213, 'eval_runtime': 0.5678, 'eval_samples_per_second': 405.069, 'eval_steps_per_second': 26.418, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.3926454782485962, 'eval_accuracy': 0.8405172413793104, 'eval_precision': 0.8436070491188601, 'eval_recall': 0.8405172413793104, 'eval_f1_score': 0.8401579055173827, 'eval_runtime': 0.5646, 'eval_samples_per_second': 410.899, 'eval_steps_per_second': 26.567, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1295' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1295/2590 01:22 < 01:22, 15.73 it/s, Epoch 5/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.531200</td>\n",
              "      <td>0.586311</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.688834</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.613711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.500042</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.793367</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.785786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.495652</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.767238</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.764773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.742200</td>\n",
              "      <td>0.542867</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.782937</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.766810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.462900</td>\n",
              "      <td>0.488324</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783380</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782461</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.4560556411743164, 'eval_accuracy': 0.7920289855072464, 'eval_precision': 0.7979166086339784, 'eval_recall': 0.7920289855072464, 'eval_f1_score': 0.7909963688481898, 'eval_runtime': 9.5539, 'eval_samples_per_second': 433.33, 'eval_steps_per_second': 27.109, 'epoch': 5.0}\n",
            "val set:  {'eval_loss': 0.5000424385070801, 'eval_accuracy': 0.7869565217391304, 'eval_precision': 0.7933673469387755, 'eval_recall': 0.7869565217391304, 'eval_f1_score': 0.7857862424207864, 'eval_runtime': 0.5675, 'eval_samples_per_second': 405.319, 'eval_steps_per_second': 26.434, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.4443696141242981, 'eval_accuracy': 0.8017241379310345, 'eval_precision': 0.812981806968856, 'eval_recall': 0.8017241379310345, 'eval_f1_score': 0.7999250093738283, 'eval_runtime': 0.5784, 'eval_samples_per_second': 401.122, 'eval_steps_per_second': 25.935, 'epoch': 5.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:24, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.621100</td>\n",
              "      <td>0.625866</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.700300</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.587917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.281200</td>\n",
              "      <td>0.524389</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.740952</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.738636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.529874</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.754502</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.751606</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.566400</td>\n",
              "      <td>0.540829</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.771739</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.758454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.835900</td>\n",
              "      <td>0.511396</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765298</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.441400</td>\n",
              "      <td>0.528821</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.757222</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.756356</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.269500</td>\n",
              "      <td>0.514827</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.771226</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.324200</td>\n",
              "      <td>0.511158</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783380</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.517120</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769749</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.516440</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765298</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.765200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3817746043205261, 'eval_accuracy': 0.8345410628019324, 'eval_precision': 0.8350290359666428, 'eval_recall': 0.8345410628019324, 'eval_f1_score': 0.8344807927038709, 'eval_runtime': 9.5747, 'eval_samples_per_second': 432.389, 'eval_steps_per_second': 27.05, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.511158287525177, 'eval_accuracy': 0.782608695652174, 'eval_precision': 0.7833800894684965, 'eval_recall': 0.782608695652174, 'eval_f1_score': 0.7824606537530266, 'eval_runtime': 0.5943, 'eval_samples_per_second': 386.984, 'eval_steps_per_second': 25.238, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.45373114943504333, 'eval_accuracy': 0.7887931034482759, 'eval_precision': 0.7914135733033372, 'eval_recall': 0.7887931034482759, 'eval_f1_score': 0.788317226225723, 'eval_runtime': 0.6007, 'eval_samples_per_second': 386.212, 'eval_steps_per_second': 24.971, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:56, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.445300</td>\n",
              "      <td>0.534333</td>\n",
              "      <td>0.704348</td>\n",
              "      <td>0.717225</td>\n",
              "      <td>0.704348</td>\n",
              "      <td>0.699900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.279300</td>\n",
              "      <td>0.509918</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.798620</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.601600</td>\n",
              "      <td>0.512908</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.805922</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.656200</td>\n",
              "      <td>0.543495</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.801190</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.784409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.490880</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.801459</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.384800</td>\n",
              "      <td>0.487814</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795675</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.275400</td>\n",
              "      <td>0.498556</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.811147</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.168900</td>\n",
              "      <td>0.477879</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.806223</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.334000</td>\n",
              "      <td>0.472919</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.810197</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.699200</td>\n",
              "      <td>0.471985</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813636</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3311103582382202, 'eval_accuracy': 0.8613526570048309, 'eval_precision': 0.8613556929694851, 'eval_recall': 0.8613526570048309, 'eval_f1_score': 0.8613523657894682, 'eval_runtime': 9.7095, 'eval_samples_per_second': 426.387, 'eval_steps_per_second': 26.675, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.471985399723053, 'eval_accuracy': 0.8130434782608695, 'eval_precision': 0.8136363636363636, 'eval_recall': 0.8130434782608695, 'eval_f1_score': 0.8129550827423168, 'eval_runtime': 0.5758, 'eval_samples_per_second': 399.467, 'eval_steps_per_second': 26.052, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.3925107717514038, 'eval_accuracy': 0.8318965517241379, 'eval_precision': 0.8339065420560747, 'eval_recall': 0.8318965517241379, 'eval_f1_score': 0.8316431907411198, 'eval_runtime': 0.6042, 'eval_samples_per_second': 383.973, 'eval_steps_per_second': 24.826, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.435500</td>\n",
              "      <td>0.553431</td>\n",
              "      <td>0.660870</td>\n",
              "      <td>0.678347</td>\n",
              "      <td>0.660870</td>\n",
              "      <td>0.652353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.500238</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.783077</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.535200</td>\n",
              "      <td>0.492943</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.778034</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.730500</td>\n",
              "      <td>0.508662</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.793344</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.780601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.671900</td>\n",
              "      <td>0.476376</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778450</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.341800</td>\n",
              "      <td>0.475594</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778282</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778257</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.271500</td>\n",
              "      <td>0.481182</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.809615</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803512</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.247100</td>\n",
              "      <td>0.469124</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800819</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.248000</td>\n",
              "      <td>0.461872</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.738300</td>\n",
              "      <td>0.463315</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3360978960990906, 'eval_accuracy': 0.8538647342995169, 'eval_precision': 0.8540174982740107, 'eval_recall': 0.8538647342995169, 'eval_f1_score': 0.8538489676971033, 'eval_runtime': 9.5543, 'eval_samples_per_second': 433.314, 'eval_steps_per_second': 27.108, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.46187159419059753, 'eval_accuracy': 0.808695652173913, 'eval_precision': 0.8095382515732809, 'eval_recall': 0.808695652173913, 'eval_f1_score': 0.8085653753026635, 'eval_runtime': 0.5793, 'eval_samples_per_second': 397.018, 'eval_steps_per_second': 25.892, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.37183457612991333, 'eval_accuracy': 0.8577586206896551, 'eval_precision': 0.8584245402427221, 'eval_recall': 0.8577586206896551, 'eval_f1_score': 0.8576925221658395, 'eval_runtime': 0.6133, 'eval_samples_per_second': 378.255, 'eval_steps_per_second': 24.456, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/2590 02:11 < 00:32, 15.76 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.586940</td>\n",
              "      <td>0.621739</td>\n",
              "      <td>0.678889</td>\n",
              "      <td>0.621739</td>\n",
              "      <td>0.588906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.418000</td>\n",
              "      <td>0.493665</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.786070</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.503900</td>\n",
              "      <td>0.492510</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.507796</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.789855</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>0.480121</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795675</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.390600</td>\n",
              "      <td>0.487347</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778450</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.491355</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.798382</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.482354</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782694</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782592</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3855346143245697, 'eval_accuracy': 0.8301932367149758, 'eval_precision': 0.8302025612056071, 'eval_recall': 0.8301932367149758, 'eval_f1_score': 0.8301920379260069, 'eval_runtime': 9.7344, 'eval_samples_per_second': 425.298, 'eval_steps_per_second': 26.607, 'epoch': 8.0}\n",
            "val set:  {'eval_loss': 0.48012056946754456, 'eval_accuracy': 0.7956521739130434, 'eval_precision': 0.795674531155475, 'eval_recall': 0.7956521739130434, 'eval_f1_score': 0.7956483109321536, 'eval_runtime': 0.5909, 'eval_samples_per_second': 389.23, 'eval_steps_per_second': 25.385, 'epoch': 8.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.3947333097457886, 'eval_accuracy': 0.7974137931034483, 'eval_precision': 0.7985007831729694, 'eval_recall': 0.7974137931034483, 'eval_f1_score': 0.7972291957229195, 'eval_runtime': 0.6003, 'eval_samples_per_second': 386.493, 'eval_steps_per_second': 24.989, 'epoch': 8.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 02:44, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.550800</td>\n",
              "      <td>0.609851</td>\n",
              "      <td>0.634783</td>\n",
              "      <td>0.730030</td>\n",
              "      <td>0.634783</td>\n",
              "      <td>0.592611</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.495032</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.778034</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.455100</td>\n",
              "      <td>0.494879</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.766507</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.764933</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.789100</td>\n",
              "      <td>0.528117</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.792063</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.109400</td>\n",
              "      <td>0.471034</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.797474</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.242200</td>\n",
              "      <td>0.473225</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.774231</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.768581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.471867</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.811147</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.449083</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.523400</td>\n",
              "      <td>0.451248</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800819</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.722700</td>\n",
              "      <td>0.455044</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800819</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799864</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:10]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3255566954612732, 'eval_accuracy': 0.8635265700483091, 'eval_precision': 0.863545659822507, 'eval_recall': 0.8635265700483091, 'eval_f1_score': 0.8635247784706269, 'eval_runtime': 9.7508, 'eval_samples_per_second': 424.581, 'eval_steps_per_second': 26.562, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.4490828812122345, 'eval_accuracy': 0.808695652173913, 'eval_precision': 0.8087890477271008, 'eval_recall': 0.808695652173913, 'eval_f1_score': 0.808681185722928, 'eval_runtime': 0.594, 'eval_samples_per_second': 387.22, 'eval_steps_per_second': 25.253, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.3790746331214905, 'eval_accuracy': 0.8362068965517241, 'eval_precision': 0.8371087928464978, 'eval_recall': 0.8362068965517241, 'eval_f1_score': 0.8360972707667137, 'eval_runtime': 0.5992, 'eval_samples_per_second': 387.187, 'eval_steps_per_second': 25.034, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.480197</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.766698</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.759556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>0.501495</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.792063</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.386700</td>\n",
              "      <td>0.504823</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792721</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.652300</td>\n",
              "      <td>0.506912</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.804513</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.475323</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822348</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.462900</td>\n",
              "      <td>0.479823</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821763</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.137700</td>\n",
              "      <td>0.485632</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.848647</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.485836</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822936</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.460394</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.858719</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.467086</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.18125754594802856, 'eval_accuracy': 0.9359903381642513, 'eval_precision': 0.9365332412991862, 'eval_recall': 0.9359903381642513, 'eval_f1_score': 0.9359704302564142, 'eval_runtime': 10.9317, 'eval_samples_per_second': 378.716, 'eval_steps_per_second': 23.693, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.460394024848938, 'eval_accuracy': 0.8565217391304348, 'eval_precision': 0.8587188070602557, 'eval_recall': 0.8565217391304348, 'eval_f1_score': 0.8563017096120713, 'eval_runtime': 0.6517, 'eval_samples_per_second': 352.944, 'eval_steps_per_second': 23.018, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.38451308012008667, 'eval_accuracy': 0.8663793103448276, 'eval_precision': 0.8685981308411215, 'eval_recall': 0.8663793103448276, 'eval_f1_score': 0.8661779208455055, 'eval_runtime': 0.6829, 'eval_samples_per_second': 339.728, 'eval_steps_per_second': 21.965, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 3** lora rank / scaling factor"
      ],
      "metadata": {
        "id": "eFapFdQFIRL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_class = GetTrainer(num_epochs = 10, lr = 1e-4, weight_decay=0.01)\n",
        "lora_list = [{\"lora_rank\": 4, \"scaling_factor\":8}, {\"lora_rank\": 4, \"scaling_factor\":12}, {\"lora_rank\": 4, \"scaling_factor\":16},\n",
        "             {\"lora_rank\": 4, \"scaling_factor\":20}, {\"lora_rank\": 8, \"scaling_factor\":16}, {\"lora_rank\": 8, \"scaling_factor\":24},\n",
        "             {\"lora_rank\": 8, \"scaling_factor\": 32}, {\"lora_rank\": 8, \"scaling_factor\":40}, {\"lora_rank\": 16, \"scaling_factor\":32},\n",
        "             {\"lora_rank\": 16, \"scaling_factor\":48}, {\"lora_rank\": 16, \"scaling_factor\":64}, {\"lora_rank\": 16, \"scaling_factor\":80}]\n",
        "\n",
        "chosen_layers = list(range(12))\n",
        "for lora in lora_list:\n",
        "    lora_rank, scaling_factor = lora[\"lora_rank\"], lora[\"scaling_factor\"]\n",
        "    #model\n",
        "    model_with_lora, model_info = model_class.get_model_with_lora(quantized = True, lora_rank = lora_rank, scaling_factor = scaling_factor, dropout = 0.1, chosen_layers = choosen_layers)\n",
        "\n",
        "    #trainer\n",
        "    trainer_class = GetTrainer(num_epochs = 10, lr = 1e-4, weight_decay=0.01)\n",
        "    trainer, training_hyperparameters_info = trainer_class.get_trainer(model_with_lora, pytorch_train, pytorch_val)\n",
        "    trainer.train()\n",
        "\n",
        "    #evaluation\n",
        "    print(model_info, training_hyperparameters_info)\n",
        "    print(\"train set: \", trainer.evaluate(eval_dataset = pytorch_train))\n",
        "    print(\"val set: \", trainer.evaluate(eval_dataset = pytorch_val))\n",
        "    print(\"test set: \", trainer.evaluate(eval_dataset = pytorch_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qwgJbCl_89Qv",
        "outputId": "b4edd92e-dd93-43d1-808e-7e6d39831631"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/2590 03:04 < 00:46, 11.21 it/s, Epoch 8/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.574200</td>\n",
              "      <td>0.602072</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.717391</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.603440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.287100</td>\n",
              "      <td>0.491644</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.782456</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.772190</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.339800</td>\n",
              "      <td>0.502921</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.768190</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.759226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.871100</td>\n",
              "      <td>0.579535</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.790621</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.759972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.447300</td>\n",
              "      <td>0.481403</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809070</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.486300</td>\n",
              "      <td>0.484502</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.796212</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.279300</td>\n",
              "      <td>0.517527</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.811396</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.316400</td>\n",
              "      <td>0.482931</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795854</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795617</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 4, scaling_factor: 8, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 148994\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.3487875461578369, 'eval_accuracy': 0.8536231884057971, 'eval_precision': 0.8536879020082556, 'eval_recall': 0.8536231884057971, 'eval_f1_score': 0.8536164925278384, 'eval_runtime': 10.7678, 'eval_samples_per_second': 384.478, 'eval_steps_per_second': 24.053, 'epoch': 8.0}\n",
            "val set:  {'eval_loss': 0.48140284419059753, 'eval_accuracy': 0.808695652173913, 'eval_precision': 0.8090695737754562, 'eval_recall': 0.808695652173913, 'eval_f1_score': 0.8086377732395432, 'eval_runtime': 0.6449, 'eval_samples_per_second': 356.629, 'eval_steps_per_second': 23.258, 'epoch': 8.0}\n",
            "test set:  {'eval_loss': 0.3721039891242981, 'eval_accuracy': 0.8017241379310345, 'eval_precision': 0.8039832285115304, 'eval_recall': 0.8017241379310345, 'eval_f1_score': 0.8013550740823467, 'eval_runtime': 0.662, 'eval_samples_per_second': 350.45, 'eval_steps_per_second': 22.658, 'epoch': 8.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.605500</td>\n",
              "      <td>0.616253</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.710623</td>\n",
              "      <td>0.639130</td>\n",
              "      <td>0.605668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.300800</td>\n",
              "      <td>0.525255</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.770340</td>\n",
              "      <td>0.756522</td>\n",
              "      <td>0.753370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.652300</td>\n",
              "      <td>0.506743</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.781863</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.835900</td>\n",
              "      <td>0.573404</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.784278</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.755843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.648400</td>\n",
              "      <td>0.493495</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800363</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.189500</td>\n",
              "      <td>0.514487</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.794511</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.140600</td>\n",
              "      <td>0.509324</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.801459</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.302700</td>\n",
              "      <td>0.507252</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.810197</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.636700</td>\n",
              "      <td>0.505808</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804555</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.605500</td>\n",
              "      <td>0.509986</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.810197</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808464</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 4, scaling_factor: 12, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 148994\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.2714489996433258, 'eval_accuracy': 0.8922705314009662, 'eval_precision': 0.8938721623741996, 'eval_recall': 0.8922705314009662, 'eval_f1_score': 0.8921609029132745, 'eval_runtime': 10.9439, 'eval_samples_per_second': 378.294, 'eval_steps_per_second': 23.666, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.507252037525177, 'eval_accuracy': 0.808695652173913, 'eval_precision': 0.8101967935567206, 'eval_recall': 0.808695652173913, 'eval_f1_score': 0.8084639261109849, 'eval_runtime': 0.6551, 'eval_samples_per_second': 351.094, 'eval_steps_per_second': 22.897, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.35302734375, 'eval_accuracy': 0.8706896551724138, 'eval_precision': 0.8706896551724138, 'eval_recall': 0.8706896551724138, 'eval_f1_score': 0.8706896551724138, 'eval_runtime': 0.6539, 'eval_samples_per_second': 354.792, 'eval_steps_per_second': 22.939, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.380900</td>\n",
              "      <td>0.492035</td>\n",
              "      <td>0.747826</td>\n",
              "      <td>0.750554</td>\n",
              "      <td>0.747826</td>\n",
              "      <td>0.747138</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.293000</td>\n",
              "      <td>0.496399</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.784318</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.771825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.503346</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.785720</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.882800</td>\n",
              "      <td>0.571535</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.790688</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.765302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.481760</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.796752</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.466800</td>\n",
              "      <td>0.479603</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.802286</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.216800</td>\n",
              "      <td>0.498641</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.832838</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.373000</td>\n",
              "      <td>0.482906</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813636</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812955</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.139600</td>\n",
              "      <td>0.478643</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.840392</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.235400</td>\n",
              "      <td>0.479721</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821958</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821709</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 4, scaling_factor: 16, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 148994\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.24535684287548065, 'eval_accuracy': 0.9038647342995169, 'eval_precision': 0.9043271028037383, 'eval_recall': 0.9038647342995169, 'eval_f1_score': 0.9038372425545821, 'eval_runtime': 10.8536, 'eval_samples_per_second': 381.439, 'eval_steps_per_second': 23.863, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.478643000125885, 'eval_accuracy': 0.8391304347826087, 'eval_precision': 0.8403916211293261, 'eval_recall': 0.8391304347826087, 'eval_f1_score': 0.8389812870144366, 'eval_runtime': 0.7235, 'eval_samples_per_second': 317.915, 'eval_steps_per_second': 20.734, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.3585836589336395, 'eval_accuracy': 0.853448275862069, 'eval_precision': 0.8560946391135071, 'eval_recall': 0.853448275862069, 'eval_f1_score': 0.8531754895391259, 'eval_runtime': 0.6661, 'eval_samples_per_second': 348.28, 'eval_steps_per_second': 22.518, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:52, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.357400</td>\n",
              "      <td>0.487780</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.744979</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.743085</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.496688</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.784318</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.771825</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.507609</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.882800</td>\n",
              "      <td>0.565285</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.800065</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.774158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.480367</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800819</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799864</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.445300</td>\n",
              "      <td>0.475535</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.797474</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.491559</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.830768</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.478303</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817776</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.112800</td>\n",
              "      <td>0.475433</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.853135</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852073</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.162100</td>\n",
              "      <td>0.477123</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830660</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830406</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 4, scaling_factor: 20, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 148994\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.22624711692333221, 'eval_accuracy': 0.9135265700483092, 'eval_precision': 0.9140847519258615, 'eval_recall': 0.9135265700483092, 'eval_f1_score': 0.9134974189066026, 'eval_runtime': 10.9929, 'eval_samples_per_second': 376.606, 'eval_steps_per_second': 23.561, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.4754330813884735, 'eval_accuracy': 0.8521739130434782, 'eval_precision': 0.8531351884145879, 'eval_recall': 0.8521739130434782, 'eval_f1_score': 0.8520732445520581, 'eval_runtime': 0.6773, 'eval_samples_per_second': 339.583, 'eval_steps_per_second': 22.147, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.36449354887008667, 'eval_accuracy': 0.8577586206896551, 'eval_precision': 0.8590661594689343, 'eval_recall': 0.8577586206896551, 'eval_f1_score': 0.857629009762901, 'eval_runtime': 0.6475, 'eval_samples_per_second': 358.311, 'eval_steps_per_second': 23.167, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.367200</td>\n",
              "      <td>0.497767</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.741763</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.738418</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.263700</td>\n",
              "      <td>0.495007</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.787860</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.507456</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.785720</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.765600</td>\n",
              "      <td>0.541338</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.789855</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.477429</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.490404</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818258</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.238300</td>\n",
              "      <td>0.505163</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.827290</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.816000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.318400</td>\n",
              "      <td>0.489929</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818258</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.110400</td>\n",
              "      <td>0.473123</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822348</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.210900</td>\n",
              "      <td>0.480104</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 8, scaling_factor: 16, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 296450\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.23957625031471252, 'eval_accuracy': 0.9096618357487922, 'eval_precision': 0.9098305540613233, 'eval_recall': 0.9096618357487922, 'eval_f1_score': 0.9096525372281541, 'eval_runtime': 10.7968, 'eval_samples_per_second': 383.445, 'eval_steps_per_second': 23.988, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.48010361194610596, 'eval_accuracy': 0.8347826086956521, 'eval_precision': 0.8348838968307996, 'eval_recall': 0.8347826086956521, 'eval_f1_score': 0.8347701149425288, 'eval_runtime': 0.6364, 'eval_samples_per_second': 361.405, 'eval_steps_per_second': 23.57, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.3556876480579376, 'eval_accuracy': 0.853448275862069, 'eval_precision': 0.853448275862069, 'eval_recall': 0.853448275862069, 'eval_f1_score': 0.853448275862069, 'eval_runtime': 0.6532, 'eval_samples_per_second': 355.162, 'eval_steps_per_second': 22.963, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.482439</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.761047</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.760829</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.497147</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.798913</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.784805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.388700</td>\n",
              "      <td>0.507048</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.788725</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.703100</td>\n",
              "      <td>0.522622</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.803949</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.277300</td>\n",
              "      <td>0.476970</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818258</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.498000</td>\n",
              "      <td>0.482286</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822348</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.168900</td>\n",
              "      <td>0.490421</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.850829</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.837778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.482685</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831061</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.075700</td>\n",
              "      <td>0.461022</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.845149</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.153300</td>\n",
              "      <td>0.467799</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 8, scaling_factor: 24, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 296450\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.20632311701774597, 'eval_accuracy': 0.9251207729468599, 'eval_precision': 0.925821979483123, 'eval_recall': 0.9251207729468599, 'eval_f1_score': 0.9250899341043572, 'eval_runtime': 10.9328, 'eval_samples_per_second': 378.676, 'eval_steps_per_second': 23.69, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.46102240681648254, 'eval_accuracy': 0.8434782608695652, 'eval_precision': 0.8451485449433933, 'eval_recall': 0.8434782608695652, 'eval_f1_score': 0.8432886668180786, 'eval_runtime': 0.6382, 'eval_samples_per_second': 360.413, 'eval_steps_per_second': 23.505, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.37048760056495667, 'eval_accuracy': 0.853448275862069, 'eval_precision': 0.8560946391135071, 'eval_recall': 0.853448275862069, 'eval_f1_score': 0.8531754895391259, 'eval_runtime': 0.659, 'eval_samples_per_second': 352.036, 'eval_steps_per_second': 22.761, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.480197</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.766698</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.759556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>0.501495</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.792063</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.386700</td>\n",
              "      <td>0.504823</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792721</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.652300</td>\n",
              "      <td>0.506912</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.804513</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799256</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.475323</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822348</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.462900</td>\n",
              "      <td>0.479823</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821763</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.137700</td>\n",
              "      <td>0.485632</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.848647</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.485836</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822936</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.063000</td>\n",
              "      <td>0.460394</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.858719</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.467086</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 8, scaling_factor: 32, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 296450\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:11]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.18125754594802856, 'eval_accuracy': 0.9359903381642513, 'eval_precision': 0.9365332412991862, 'eval_recall': 0.9359903381642513, 'eval_f1_score': 0.9359704302564142, 'eval_runtime': 10.6651, 'eval_samples_per_second': 388.182, 'eval_steps_per_second': 24.285, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.460394024848938, 'eval_accuracy': 0.8565217391304348, 'eval_precision': 0.8587188070602557, 'eval_recall': 0.8565217391304348, 'eval_f1_score': 0.8563017096120713, 'eval_runtime': 0.6516, 'eval_samples_per_second': 353.002, 'eval_steps_per_second': 23.022, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.38451308012008667, 'eval_accuracy': 0.8663793103448276, 'eval_precision': 0.8685981308411215, 'eval_recall': 0.8663793103448276, 'eval_f1_score': 0.8661779208455055, 'eval_runtime': 0.6673, 'eval_samples_per_second': 347.696, 'eval_steps_per_second': 22.48, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:57, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.475985</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.776928</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.265600</td>\n",
              "      <td>0.495907</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.792063</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.775610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.404300</td>\n",
              "      <td>0.501596</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792099</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791162</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.621100</td>\n",
              "      <td>0.508509</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.805922</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.475323</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826482</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826034</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.396500</td>\n",
              "      <td>0.472996</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821958</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.475645</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.861019</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.380900</td>\n",
              "      <td>0.486583</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.803302</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.056900</td>\n",
              "      <td>0.463842</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.837333</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.103500</td>\n",
              "      <td>0.468240</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843582</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 8, scaling_factor: 40, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 296450\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.20904146134853363, 'eval_accuracy': 0.9205314009661836, 'eval_precision': 0.924142486887475, 'eval_recall': 0.9205314009661836, 'eval_f1_score': 0.920361894225258, 'eval_runtime': 10.9023, 'eval_samples_per_second': 379.735, 'eval_steps_per_second': 23.756, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.47564539313316345, 'eval_accuracy': 0.8521739130434782, 'eval_precision': 0.8610185256956825, 'eval_recall': 0.8521739130434782, 'eval_f1_score': 0.8512629336579428, 'eval_runtime': 0.6708, 'eval_samples_per_second': 342.872, 'eval_steps_per_second': 22.361, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.40832099318504333, 'eval_accuracy': 0.8491379310344828, 'eval_precision': 0.8550752021767063, 'eval_recall': 0.8491379310344828, 'eval_f1_score': 0.8485046362805277, 'eval_runtime': 0.6412, 'eval_samples_per_second': 361.802, 'eval_steps_per_second': 23.392, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:57, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.318400</td>\n",
              "      <td>0.494998</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.769869</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.758859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.193400</td>\n",
              "      <td>0.500798</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.791423</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.780952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.378900</td>\n",
              "      <td>0.513128</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.738300</td>\n",
              "      <td>0.542935</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.821907</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.796538</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.365200</td>\n",
              "      <td>0.487755</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.832471</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.459562</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.149400</td>\n",
              "      <td>0.475136</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.845000</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.205100</td>\n",
              "      <td>0.444905</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839156</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.069800</td>\n",
              "      <td>0.459273</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.853846</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847176</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.446357</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.866576</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.865092</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 16, scaling_factor: 32, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 591362\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.1751398742198944, 'eval_accuracy': 0.9350241545893719, 'eval_precision': 0.9350323782638194, 'eval_recall': 0.9350241545893719, 'eval_f1_score': 0.9350238475187082, 'eval_runtime': 10.919, 'eval_samples_per_second': 379.155, 'eval_steps_per_second': 23.72, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.44635701179504395, 'eval_accuracy': 0.8652173913043478, 'eval_precision': 0.866575591985428, 'eval_recall': 0.8652173913043478, 'eval_f1_score': 0.8650924296607444, 'eval_runtime': 0.6579, 'eval_samples_per_second': 349.607, 'eval_steps_per_second': 22.8, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.37634697556495667, 'eval_accuracy': 0.8448275862068966, 'eval_precision': 0.8452380952380951, 'eval_recall': 0.8448275862068966, 'eval_f1_score': 0.8447814451382694, 'eval_runtime': 0.6539, 'eval_samples_per_second': 354.814, 'eval_steps_per_second': 22.941, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.308600</td>\n",
              "      <td>0.477233</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.795687</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.493071</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.797055</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.363300</td>\n",
              "      <td>0.511855</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.793524</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.660200</td>\n",
              "      <td>0.520431</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.822753</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.806590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.384800</td>\n",
              "      <td>0.500289</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.828927</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.490200</td>\n",
              "      <td>0.461855</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.840392</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.143600</td>\n",
              "      <td>0.465931</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.857472</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.234400</td>\n",
              "      <td>0.450951</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839156</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.081100</td>\n",
              "      <td>0.473336</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.852104</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.842514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.092800</td>\n",
              "      <td>0.449813</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.857848</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 16, scaling_factor: 48, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 591362\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.14518193900585175, 'eval_accuracy': 0.9509661835748793, 'eval_precision': 0.9509671307858238, 'eval_recall': 0.9509661835748793, 'eval_f1_score': 0.9509661578272199, 'eval_runtime': 10.9366, 'eval_samples_per_second': 378.545, 'eval_steps_per_second': 23.682, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.44981318712234497, 'eval_accuracy': 0.8565217391304348, 'eval_precision': 0.8578476017000607, 'eval_recall': 0.8565217391304348, 'eval_f1_score': 0.8563887154453086, 'eval_runtime': 0.647, 'eval_samples_per_second': 355.475, 'eval_steps_per_second': 23.183, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test set:  {'eval_loss': 0.39513739943504333, 'eval_accuracy': 0.8793103448275862, 'eval_precision': 0.8794231341064527, 'eval_recall': 0.8793103448275862, 'eval_f1_score': 0.8793013749535489, 'eval_runtime': 0.6935, 'eval_samples_per_second': 334.538, 'eval_steps_per_second': 21.63, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:51, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.300800</td>\n",
              "      <td>0.476834</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.170900</td>\n",
              "      <td>0.492425</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.800769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.351600</td>\n",
              "      <td>0.508322</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.815934</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.668000</td>\n",
              "      <td>0.522826</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.837698</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.819608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.506335</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.836154</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.829710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.464800</td>\n",
              "      <td>0.472520</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.833486</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.134800</td>\n",
              "      <td>0.466661</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.851038</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.195300</td>\n",
              "      <td>0.463740</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839773</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.096200</td>\n",
              "      <td>0.488757</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.850258</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.842717</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.075200</td>\n",
              "      <td>0.464334</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843894</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843431</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 16, scaling_factor: 64, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 591362\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.16156448423862457, 'eval_accuracy': 0.9422705314009662, 'eval_precision': 0.9428212547472632, 'eval_recall': 0.9422705314009662, 'eval_f1_score': 0.9422525767218226, 'eval_runtime': 10.8801, 'eval_samples_per_second': 380.51, 'eval_steps_per_second': 23.805, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.4666610062122345, 'eval_accuracy': 0.8478260869565217, 'eval_precision': 0.851037851037851, 'eval_recall': 0.8478260869565217, 'eval_f1_score': 0.8474772163170958, 'eval_runtime': 0.6872, 'eval_samples_per_second': 334.699, 'eval_steps_per_second': 21.828, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.41460129618644714, 'eval_accuracy': 0.8620689655172413, 'eval_precision': 0.8637992831541218, 'eval_recall': 0.8620689655172413, 'eval_f1_score': 0.8619047619047618, 'eval_runtime': 0.6812, 'eval_samples_per_second': 340.58, 'eval_steps_per_second': 22.02, 'epoch': 10.0}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='2590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/2590 03:50, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.298800</td>\n",
              "      <td>0.486150</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.791923</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.489300</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.797055</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.345700</td>\n",
              "      <td>0.499677</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.824710</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.722700</td>\n",
              "      <td>0.537058</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.834302</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.810023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.289100</td>\n",
              "      <td>0.487840</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.839819</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.457000</td>\n",
              "      <td>0.464657</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.845149</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.098100</td>\n",
              "      <td>0.457396</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.861137</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.133800</td>\n",
              "      <td>0.453902</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839773</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.104000</td>\n",
              "      <td>0.471909</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.864487</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.855734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.085900</td>\n",
              "      <td>0.448565</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847852</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847823</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },   
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 16, scaling_factor: 80, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 591362\n",
            " num_epochs: 10, learning_rate: 0.0001, weight_decay: 0.01\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.150213822722435, 'eval_accuracy': 0.9466183574879227, 'eval_precision': 0.9470867400350107, 'eval_recall': 0.9466183574879227, 'eval_f1_score': 0.9466043727408594, 'eval_runtime': 10.8733, 'eval_samples_per_second': 380.749, 'eval_steps_per_second': 23.82, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.45739638805389404, 'eval_accuracy': 0.8565217391304348, 'eval_precision': 0.8611366421568628, 'eval_recall': 0.8565217391304348, 'eval_f1_score': 0.8560618990726516, 'eval_runtime': 0.6763, 'eval_samples_per_second': 340.111, 'eval_steps_per_second': 22.181, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.4172784090042114, 'eval_accuracy': 0.8663793103448276, 'eval_precision': 0.8677183560826434, 'eval_recall': 0.8663793103448276, 'eval_f1_score': 0.8662575546257555, 'eval_runtime': 0.6442, 'eval_samples_per_second': 360.151, 'eval_steps_per_second': 23.286, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FP8c6wRs8u8W"
      },
      "source": [
        "## **Experiment 4**  hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z99gI5c9huFO"
      },
      "outputs": [],
      "source": [
        "def model_init():\n",
        "    model_with_lora_all, model_info_all = model_class.get_model_with_lora(quantized = True, lora_rank = 16, scaling_factor = 48, dropout = 0.1, chosen_layers = list(range(12)))\n",
        "    return model_with_lora_all\n",
        "\n",
        "trainer_class = GetTrainer(num_epochs = 15, lr = 1e-4, weight_decay=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "iuRPdPyKcE80",
        "outputId": "e86e4e4d-3cb5-4922-df08-5c93c0c850a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3108' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3108/3885 04:43 < 01:10, 10.96 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.455740</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795675</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.207000</td>\n",
              "      <td>0.406063</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.910200</td>\n",
              "      <td>0.443911</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852600</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.738300</td>\n",
              "      <td>0.441576</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.830992</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.492200</td>\n",
              "      <td>0.439317</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.855597</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.846990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.117200</td>\n",
              "      <td>0.481178</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.870574</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.869476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.484031</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.871538</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.864642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.221700</td>\n",
              "      <td>0.504344</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.869945</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.864785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.382570</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.891334</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.891302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.474600</td>\n",
              "      <td>0.488284</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.861855</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.860775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.008600</td>\n",
              "      <td>0.554384</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.865245</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.865215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.560390</td>\n",
              "      <td>0.878261</td>\n",
              "      <td>0.878719</td>\n",
              "      <td>0.878261</td>\n",
              "      <td>0.878224</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 19:55:04,134] Trial 0 finished with value: 0.8782240375160728 and parameters: {'learning_rate': 0.00048569487626740564, 'weight_decay': 0.008452656442872837, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1950 02:34 < 00:38, 10.12 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.359400</td>\n",
              "      <td>0.478753</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.768137</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.764577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.230500</td>\n",
              "      <td>0.461532</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.466800</td>\n",
              "      <td>0.533492</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.797055</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>0.474813</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.823842</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.811472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.168900</td>\n",
              "      <td>0.444226</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.833486</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.461897</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.846095</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.045900</td>\n",
              "      <td>0.453295</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.851038</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.115200</td>\n",
              "      <td>0.463230</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.810317</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.793209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.353500</td>\n",
              "      <td>0.436337</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.857197</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.193400</td>\n",
              "      <td>0.445177</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.116200</td>\n",
              "      <td>0.444319</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.157200</td>\n",
              "      <td>0.473476</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 19:57:44,088] Trial 1 finished with value: 0.8477541371158392 and parameters: {'learning_rate': 0.00016902257464347252, 'weight_decay': 0.018023155102535958, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/3885 03:10 < 02:46, 10.89 it/s, Epoch 8/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.332000</td>\n",
              "      <td>0.495363</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.759251</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.750471</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.235400</td>\n",
              "      <td>0.474066</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.800769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.839800</td>\n",
              "      <td>0.522232</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.791923</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.945300</td>\n",
              "      <td>0.534197</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.831237</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.805385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.400400</td>\n",
              "      <td>0.463663</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.827308</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.186500</td>\n",
              "      <td>0.529085</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.800390</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.789714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.091800</td>\n",
              "      <td>0.473688</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.810197</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.083000</td>\n",
              "      <td>0.496119</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.811147</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803273</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:01:00,041] Trial 2 finished with value: 0.8032730797741917 and parameters: {'learning_rate': 9.076591767668487e-05, 'weight_decay': 0.019153614214382286, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1950' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1950/1950 03:13, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>0.677174</td>\n",
              "      <td>0.613043</td>\n",
              "      <td>0.635712</td>\n",
              "      <td>0.613043</td>\n",
              "      <td>0.596181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.416000</td>\n",
              "      <td>0.481301</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.743497</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.743473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.480002</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769749</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.796900</td>\n",
              "      <td>0.494633</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.486523</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.335900</td>\n",
              "      <td>0.481836</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.793524</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.153300</td>\n",
              "      <td>0.468903</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.794511</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.296900</td>\n",
              "      <td>0.470941</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.805922</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.414100</td>\n",
              "      <td>0.469871</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795854</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.463060</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813257</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.466016</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.090800</td>\n",
              "      <td>0.466912</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817776</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.287100</td>\n",
              "      <td>0.463893</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.222700</td>\n",
              "      <td>0.472283</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831061</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.253900</td>\n",
              "      <td>0.473123</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.827673</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:04:19,282] Trial 3 finished with value: 0.8258762964645319 and parameters: {'learning_rate': 5.674756908969356e-05, 'weight_decay': 0.016137914359329958, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1820' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1820/1950 03:00 < 00:12, 10.08 it/s, Epoch 14/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.609400</td>\n",
              "      <td>0.662976</td>\n",
              "      <td>0.621739</td>\n",
              "      <td>0.648744</td>\n",
              "      <td>0.621739</td>\n",
              "      <td>0.603755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.328100</td>\n",
              "      <td>0.475866</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778450</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.778223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.492200</td>\n",
              "      <td>0.479611</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779976</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.804700</td>\n",
              "      <td>0.487840</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.793367</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.785786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.234400</td>\n",
              "      <td>0.480724</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786978</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.300800</td>\n",
              "      <td>0.470397</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.811048</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.127000</td>\n",
              "      <td>0.460012</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814973</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.242200</td>\n",
              "      <td>0.477293</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.814789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.807765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.470474</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821958</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.294900</td>\n",
              "      <td>0.467459</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831061</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.466759</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.092300</td>\n",
              "      <td>0.466143</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830460</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.271500</td>\n",
              "      <td>0.464139</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826186</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.479819</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.827673</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:07:25,974] Trial 4 finished with value: 0.8258762964645319 and parameters: {'learning_rate': 7.69051722679439e-05, 'weight_decay': 0.017176244048423682, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3108' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3108/3885 04:43 < 01:10, 10.96 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.283200</td>\n",
              "      <td>0.478821</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.252000</td>\n",
              "      <td>0.430732</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.796212</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.714800</td>\n",
              "      <td>0.511447</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.828927</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.871100</td>\n",
              "      <td>0.467994</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.834276</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.188500</td>\n",
              "      <td>0.447198</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.839819</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.226600</td>\n",
              "      <td>0.636642</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.812900</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.792797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.051800</td>\n",
              "      <td>0.433891</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.857197</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.064900</td>\n",
              "      <td>0.489050</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.838468</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.069800</td>\n",
              "      <td>0.490521</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.861307</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.860827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.277300</td>\n",
              "      <td>0.603698</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.842262</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.314500</td>\n",
              "      <td>0.565077</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847852</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847823</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.009800</td>\n",
              "      <td>0.656678</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.848645</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.842896</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:12:15,385] Trial 5 finished with value: 0.842896174863388 and parameters: {'learning_rate': 0.0003294216439724359, 'weight_decay': 0.008745837042382548, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1950' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1950/1950 03:14, Epoch 15/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.601600</td>\n",
              "      <td>0.658050</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.675595</td>\n",
              "      <td>0.652174</td>\n",
              "      <td>0.640175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.328100</td>\n",
              "      <td>0.477615</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.774245</td>\n",
              "      <td>0.773913</td>\n",
              "      <td>0.773845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.478500</td>\n",
              "      <td>0.484273</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.800800</td>\n",
              "      <td>0.487041</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.803949</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.220700</td>\n",
              "      <td>0.478320</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795675</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.474185</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.807158</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.127900</td>\n",
              "      <td>0.461642</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.827673</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825876</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.237300</td>\n",
              "      <td>0.479314</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.811147</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.414100</td>\n",
              "      <td>0.473454</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817776</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.285200</td>\n",
              "      <td>0.471153</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831664</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.168000</td>\n",
              "      <td>0.465710</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.102100</td>\n",
              "      <td>0.467204</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839156</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.261700</td>\n",
              "      <td>0.463617</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.210900</td>\n",
              "      <td>0.480320</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.832471</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.114700</td>\n",
              "      <td>0.475994</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.827673</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825876</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:15:35,483] Trial 6 finished with value: 0.8258762964645319 and parameters: {'learning_rate': 8.197845100033253e-05, 'weight_decay': 0.009629039394011746, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/3885 03:09 < 02:45, 10.95 it/s, Epoch 8/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.337900</td>\n",
              "      <td>0.497121</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.760873</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.750091</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.240200</td>\n",
              "      <td>0.474304</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.800769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.820300</td>\n",
              "      <td>0.515829</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.791923</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.964800</td>\n",
              "      <td>0.533959</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.834302</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.810023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.460572</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.829677</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.223600</td>\n",
              "      <td>0.535063</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.800390</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.789714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.093300</td>\n",
              "      <td>0.471688</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814208</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.088400</td>\n",
              "      <td>0.495414</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.803949</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:18:50,514] Trial 7 finished with value: 0.794248082376901 and parameters: {'learning_rate': 8.623882516179344e-05, 'weight_decay': 0.0072572420651752356, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1690' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1690/1950 02:47 < 00:25, 10.07 it/s, Epoch 13/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.408200</td>\n",
              "      <td>0.537925</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.755850</td>\n",
              "      <td>0.734783</td>\n",
              "      <td>0.729208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.477972</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.818462</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812245</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.710900</td>\n",
              "      <td>0.510394</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.046900</td>\n",
              "      <td>0.474983</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.812094</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.465757</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822936</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.100600</td>\n",
              "      <td>0.463269</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839773</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.050000</td>\n",
              "      <td>0.443054</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.842262</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.126000</td>\n",
              "      <td>0.544820</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.803697</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.783980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.496701</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.844416</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.094200</td>\n",
              "      <td>0.533946</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.055200</td>\n",
              "      <td>0.504042</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831061</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.018900</td>\n",
              "      <td>0.530448</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839361</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.377000</td>\n",
              "      <td>0.573756</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.825904</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821168</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:21:44,023] Trial 8 finished with value: 0.8211678139993553 and parameters: {'learning_rate': 0.0002520014543564039, 'weight_decay': 0.005770001771321084, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3108' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3108/3885 04:46 < 01:11, 10.84 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.359400</td>\n",
              "      <td>0.523573</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.757682</td>\n",
              "      <td>0.743478</td>\n",
              "      <td>0.739894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.236300</td>\n",
              "      <td>0.472741</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.795687</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.847700</td>\n",
              "      <td>0.520499</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.798620</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.945300</td>\n",
              "      <td>0.539776</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.828196</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.800728</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.445300</td>\n",
              "      <td>0.470686</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.816448</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.807517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.151400</td>\n",
              "      <td>0.532469</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.796855</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.785166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.087400</td>\n",
              "      <td>0.478707</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822936</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.094700</td>\n",
              "      <td>0.486647</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.816448</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.807517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.359400</td>\n",
              "      <td>0.498289</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.848645</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.842896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.167000</td>\n",
              "      <td>0.521765</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.817096</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.392600</td>\n",
              "      <td>0.509018</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822348</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.244100</td>\n",
              "      <td>0.577424</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814208</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:26:37,024] Trial 9 finished with value: 0.8128701443681292 and parameters: {'learning_rate': 9.69827379553389e-05, 'weight_decay': 0.0077088549750274505, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1554' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1554/3885 02:23 < 03:34, 10.85 it/s, Epoch 6/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.252000</td>\n",
              "      <td>0.456165</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795675</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.404390</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.830992</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.808600</td>\n",
              "      <td>0.439929</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.844416</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.726600</td>\n",
              "      <td>0.403668</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835696</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.271500</td>\n",
              "      <td>0.522410</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.822103</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.801614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.712500</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.837573</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.809584</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:29:06,049] Trial 10 finished with value: 0.8095843200677717 and parameters: {'learning_rate': 0.000481714931858132, 'weight_decay': 0.012545718398898401, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1690' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1690/1950 02:47 < 00:25, 10.06 it/s, Epoch 13/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.527300</td>\n",
              "      <td>0.526894</td>\n",
              "      <td>0.717391</td>\n",
              "      <td>0.756696</td>\n",
              "      <td>0.717391</td>\n",
              "      <td>0.706143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.228500</td>\n",
              "      <td>0.461787</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.807158</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.566400</td>\n",
              "      <td>0.519913</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.795687</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.839800</td>\n",
              "      <td>0.491474</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.835145</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.819939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.189500</td>\n",
              "      <td>0.455324</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817776</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.207000</td>\n",
              "      <td>0.474958</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.847259</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.049600</td>\n",
              "      <td>0.459434</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.849970</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.141600</td>\n",
              "      <td>0.470329</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.820422</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.806929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.326200</td>\n",
              "      <td>0.456624</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.361300</td>\n",
              "      <td>0.460657</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852280</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.144500</td>\n",
              "      <td>0.461396</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.094200</td>\n",
              "      <td>0.486494</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835696</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.154300</td>\n",
              "      <td>0.478728</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839361</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:31:59,722] Trial 11 finished with value: 0.8391030610122705 and parameters: {'learning_rate': 0.00015938796831864598, 'weight_decay': 0.012506871294174372, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2072' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2072/3885 03:09 < 02:46, 10.90 it/s, Epoch 8/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.330100</td>\n",
              "      <td>0.499856</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.785720</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.212900</td>\n",
              "      <td>0.455656</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.799479</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.957000</td>\n",
              "      <td>0.547053</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.798620</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.746100</td>\n",
              "      <td>0.489156</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.821828</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.811759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.439861</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.131800</td>\n",
              "      <td>0.558110</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.831844</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.815381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.048300</td>\n",
              "      <td>0.496525</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.197300</td>\n",
              "      <td>0.564453</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813636</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812955</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:35:15,591] Trial 12 finished with value: 0.8129550827423168 and parameters: {'learning_rate': 0.00016711647190341343, 'weight_decay': 0.015325020809312851, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1170' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1170/1950 01:56 < 01:17, 10.06 it/s, Epoch 9/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.302700</td>\n",
              "      <td>0.451410</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.798382</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.176800</td>\n",
              "      <td>0.475323</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.812094</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.734400</td>\n",
              "      <td>0.525611</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.782937</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.766810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.640600</td>\n",
              "      <td>0.444591</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830660</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.194300</td>\n",
              "      <td>0.547516</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.829677</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.042500</td>\n",
              "      <td>0.453949</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839156</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.026000</td>\n",
              "      <td>0.487411</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.108400</td>\n",
              "      <td>0.500374</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826977</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.080600</td>\n",
              "      <td>0.507294</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831061</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:37:17,659] Trial 13 finished with value: 0.8303546099290781 and parameters: {'learning_rate': 0.00047368320178882407, 'weight_decay': 0.011021073500630817, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1813' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1813/3885 02:45 < 03:09, 10.93 it/s, Epoch 7/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.400400</td>\n",
              "      <td>0.565048</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.771934</td>\n",
              "      <td>0.752174</td>\n",
              "      <td>0.747589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.216800</td>\n",
              "      <td>0.432762</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814208</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.902300</td>\n",
              "      <td>0.490438</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804555</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.023400</td>\n",
              "      <td>0.462568</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.855952</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.837207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.394500</td>\n",
              "      <td>0.408229</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830660</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.186500</td>\n",
              "      <td>0.463290</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.827308</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820978</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.234400</td>\n",
              "      <td>0.505615</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826977</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:40:09,250] Trial 14 finished with value: 0.8259685230024213 and parameters: {'learning_rate': 0.0002442692944338546, 'weight_decay': 0.019749070781138925, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1170' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1170/1950 01:56 < 01:17, 10.00 it/s, Epoch 9/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.498021</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779976</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.161100</td>\n",
              "      <td>0.457609</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.823656</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.816503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.539100</td>\n",
              "      <td>0.496289</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813257</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.813012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.054700</td>\n",
              "      <td>0.457065</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.830992</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825440</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.176800</td>\n",
              "      <td>0.486965</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.839819</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.086400</td>\n",
              "      <td>0.422588</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.871362</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.869407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>0.474966</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.857472</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.318400</td>\n",
              "      <td>0.530121</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.817029</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.802372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.450123</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.871362</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.869407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:42:12,015] Trial 15 finished with value: 0.8694072223483988 and parameters: {'learning_rate': 0.0003296008523005617, 'weight_decay': 0.014304884180475303, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1554' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1554/3885 02:22 < 03:34, 10.88 it/s, Epoch 6/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.291000</td>\n",
              "      <td>0.472919</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.245100</td>\n",
              "      <td>0.431165</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.824200</td>\n",
              "      <td>0.492086</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.840392</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838981</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.007800</td>\n",
              "      <td>0.475807</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.830768</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.820514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.468020</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.829677</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.240200</td>\n",
              "      <td>0.663757</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.803949</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794248</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:44:40,627] Trial 16 finished with value: 0.794248082376901 and parameters: {'learning_rate': 0.0003486829141122314, 'weight_decay': 0.014300851201091792, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1300' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1300/1950 02:10 < 01:05, 9.94 it/s, Epoch 10/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.425800</td>\n",
              "      <td>0.540039</td>\n",
              "      <td>0.730435</td>\n",
              "      <td>0.752506</td>\n",
              "      <td>0.730435</td>\n",
              "      <td>0.724412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.214800</td>\n",
              "      <td>0.464674</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.809357</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798476</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.570300</td>\n",
              "      <td>0.508832</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817487</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.855500</td>\n",
              "      <td>0.434086</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.847259</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.640600</td>\n",
              "      <td>0.543003</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.865552</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.850809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.145500</td>\n",
              "      <td>0.502904</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.859825</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.846547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.036400</td>\n",
              "      <td>0.444854</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852280</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.514597</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.816448</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.807517</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.179700</td>\n",
              "      <td>0.415990</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.081100</td>\n",
              "      <td>0.514485</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839156</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839127</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:46:57,220] Trial 17 finished with value: 0.8391273937125465 and parameters: {'learning_rate': 0.0003447195020114329, 'weight_decay': 0.010791143591232871, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2331' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2331/3885 03:32 < 02:21, 10.95 it/s, Epoch 9/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.371100</td>\n",
              "      <td>0.533585</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.787860</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.776397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.203100</td>\n",
              "      <td>0.437075</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.809538</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808565</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.508925</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.807534</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.070300</td>\n",
              "      <td>0.487390</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.810808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.404300</td>\n",
              "      <td>0.479280</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.826977</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825969</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.130900</td>\n",
              "      <td>0.430094</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.849120</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847685</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.175800</td>\n",
              "      <td>0.465507</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.823722</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.097700</td>\n",
              "      <td>0.453613</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.845149</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.512634</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843582</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:50:35,859] Trial 18 finished with value: 0.8434664246823956 and parameters: {'learning_rate': 0.00023776389948241078, 'weight_decay': 0.013914404541923164, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='520' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 520/1950 00:51 < 02:23, 9.99 it/s, Epoch 4/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.283200</td>\n",
              "      <td>0.450832</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800363</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.178700</td>\n",
              "      <td>0.444769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.800769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.710900</td>\n",
              "      <td>0.510470</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.803302</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.617200</td>\n",
              "      <td>0.459910</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.790671</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:51:33,638] Trial 19 finished with value: 0.7862737289260587 and parameters: {'learning_rate': 0.0004091896258514462, 'weight_decay': 0.005194494881081939, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1813' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1813/3885 02:45 < 03:09, 10.94 it/s, Epoch 7/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.363300</td>\n",
              "      <td>0.504772</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.766698</td>\n",
              "      <td>0.760870</td>\n",
              "      <td>0.759556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.225600</td>\n",
              "      <td>0.461634</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.800769</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.960900</td>\n",
              "      <td>0.531216</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.802257</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.875000</td>\n",
              "      <td>0.528915</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.837392</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.814644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.466800</td>\n",
              "      <td>0.493003</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.810317</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.793209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.096700</td>\n",
              "      <td>0.565757</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.811396</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798153</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.051300</td>\n",
              "      <td>0.524830</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.799479</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.794997</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:54:25,191] Trial 20 finished with value: 0.7949972501943828 and parameters: {'learning_rate': 0.0001267126593657583, 'weight_decay': 0.011094803137883118, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1950 02:36 < 00:39, 9.93 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.419900</td>\n",
              "      <td>0.528363</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.750020</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.736259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.197300</td>\n",
              "      <td>0.457863</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.801459</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.585900</td>\n",
              "      <td>0.505868</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.792721</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.791052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.929700</td>\n",
              "      <td>0.463961</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.837817</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.829503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.196300</td>\n",
              "      <td>0.458594</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.833486</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830046</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.211900</td>\n",
              "      <td>0.454645</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.845149</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.463502</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.848645</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.842896</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.154300</td>\n",
              "      <td>0.502174</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.836257</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.824762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.388700</td>\n",
              "      <td>0.464657</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.151400</td>\n",
              "      <td>0.518750</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818935</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.507057</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.545644</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835696</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:57:08,022] Trial 21 finished with value: 0.8346700968523002 and parameters: {'learning_rate': 0.00021534760124612768, 'weight_decay': 0.018492572953205912, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1950 02:34 < 00:38, 10.08 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.375000</td>\n",
              "      <td>0.490166</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.783983</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.166000</td>\n",
              "      <td>0.466067</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.795687</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.683600</td>\n",
              "      <td>0.504569</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.796212</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.914100</td>\n",
              "      <td>0.438213</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818258</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.418000</td>\n",
              "      <td>0.496841</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.829448</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.815705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.130900</td>\n",
              "      <td>0.430044</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.849970</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.020400</td>\n",
              "      <td>0.447894</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839361</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.572414</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.803230</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.773600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.217800</td>\n",
              "      <td>0.487731</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.853886</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.501966</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830460</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.520340</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.019000</td>\n",
              "      <td>0.542241</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.836411</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 20:59:48,503] Trial 22 finished with value: 0.8345824816413052 and parameters: {'learning_rate': 0.00029935001810695526, 'weight_decay': 0.017521507013010928, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1300' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1300/1950 02:10 < 01:05, 9.97 it/s, Epoch 10/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.605500</td>\n",
              "      <td>0.627582</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.756499</td>\n",
              "      <td>0.626087</td>\n",
              "      <td>0.571639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.255900</td>\n",
              "      <td>0.459273</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.807158</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.468800</td>\n",
              "      <td>0.517850</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.820422</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.806929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.769500</td>\n",
              "      <td>0.481284</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.811155</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>0.450076</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804555</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.804315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.247100</td>\n",
              "      <td>0.464903</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821958</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.067900</td>\n",
              "      <td>0.455579</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.845149</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843289</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.171900</td>\n",
              "      <td>0.476427</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.812889</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.449200</td>\n",
              "      <td>0.456895</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830460</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>0.462865</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834884</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:02:04,684] Trial 23 finished with value: 0.8347701149425288 and parameters: {'learning_rate': 0.0001201398752461172, 'weight_decay': 0.013979881807883714, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1300' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1300/1950 02:09 < 01:04, 10.06 it/s, Epoch 10/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.480944</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769586</td>\n",
              "      <td>0.769565</td>\n",
              "      <td>0.769561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.180700</td>\n",
              "      <td>0.495499</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.798620</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.486300</td>\n",
              "      <td>0.521739</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.807158</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>0.464113</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.817096</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>0.448072</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839773</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839054</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.459103</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.838468</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.041300</td>\n",
              "      <td>0.462695</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.853886</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.126000</td>\n",
              "      <td>0.495414</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.812900</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.792797</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.177700</td>\n",
              "      <td>0.462088</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.846095</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843182</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.259800</td>\n",
              "      <td>0.463328</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:04:19,740] Trial 24 finished with value: 0.8477541371158392 and parameters: {'learning_rate': 0.00018603078303307635, 'weight_decay': 0.015964020513863152, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1560' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1560/1950 02:34 < 00:38, 10.08 it/s, Epoch 12/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.458059</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.785720</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.169900</td>\n",
              "      <td>0.442680</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.808287</td>\n",
              "      <td>0.804348</td>\n",
              "      <td>0.803721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.578100</td>\n",
              "      <td>0.513536</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.811048</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.808333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.636700</td>\n",
              "      <td>0.435530</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817487</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817377</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.347700</td>\n",
              "      <td>0.561430</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.828571</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.810808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.097200</td>\n",
              "      <td>0.457863</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814208</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.013100</td>\n",
              "      <td>0.445780</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839361</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.839103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.065400</td>\n",
              "      <td>0.479594</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835696</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.074200</td>\n",
              "      <td>0.462012</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.860979</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.860859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.024400</td>\n",
              "      <td>0.570311</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.842262</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.838762</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.169900</td>\n",
              "      <td>0.586778</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.832524</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825241</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.017300</td>\n",
              "      <td>0.537995</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:07:00,224] Trial 25 finished with value: 0.8477541371158392 and parameters: {'learning_rate': 0.00040248280125738554, 'weight_decay': 0.017670180393359686, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1300' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1300/1950 02:08 < 01:04, 10.12 it/s, Epoch 10/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.450577</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.796212</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795556</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.195300</td>\n",
              "      <td>0.457507</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.814789</td>\n",
              "      <td>0.808696</td>\n",
              "      <td>0.807765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.664100</td>\n",
              "      <td>0.498896</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.793524</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.628900</td>\n",
              "      <td>0.447750</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818935</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.293000</td>\n",
              "      <td>0.554195</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.820037</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.137700</td>\n",
              "      <td>0.542086</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.834489</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.815028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.014000</td>\n",
              "      <td>0.456993</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856549</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.087400</td>\n",
              "      <td>0.515451</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.102500</td>\n",
              "      <td>0.481810</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.036100</td>\n",
              "      <td>0.578879</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.818935</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817170</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:09:14,375] Trial 26 finished with value: 0.8171701112877583 and parameters: {'learning_rate': 0.0004075208853000224, 'weight_decay': 0.014885960229714196, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='910' max='1950' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 910/1950 01:31 < 01:44, 9.96 it/s, Epoch 7/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.398400</td>\n",
              "      <td>0.488825</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.779976</td>\n",
              "      <td>0.778261</td>\n",
              "      <td>0.777921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.155300</td>\n",
              "      <td>0.468003</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.805922</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799027</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>0.488927</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795854</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.795617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.968800</td>\n",
              "      <td>0.440438</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.835188</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.355500</td>\n",
              "      <td>0.499440</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.825362</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.816266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.133800</td>\n",
              "      <td>0.436315</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821763</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.023900</td>\n",
              "      <td>0.481492</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.822936</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821574</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:10:51,489] Trial 27 finished with value: 0.8215738585835652 and parameters: {'learning_rate': 0.00028696453090673883, 'weight_decay': 0.013214678927791932, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/3885 03:56 < 01:58, 10.92 it/s, Epoch 10/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.506547</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.789606</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786468</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.201200</td>\n",
              "      <td>0.455384</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.788725</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.786630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.039100</td>\n",
              "      <td>0.561422</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.801190</td>\n",
              "      <td>0.786957</td>\n",
              "      <td>0.784409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.793000</td>\n",
              "      <td>0.482040</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.840936</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.824172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.093800</td>\n",
              "      <td>0.467977</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.831664</td>\n",
              "      <td>0.830435</td>\n",
              "      <td>0.830278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.214800</td>\n",
              "      <td>0.545232</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.834276</td>\n",
              "      <td>0.826087</td>\n",
              "      <td>0.825015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.132800</td>\n",
              "      <td>0.460067</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.861855</td>\n",
              "      <td>0.860870</td>\n",
              "      <td>0.860775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.088400</td>\n",
              "      <td>0.500510</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.852174</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.067400</td>\n",
              "      <td>0.504276</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.837333</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.335900</td>\n",
              "      <td>0.601794</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.818462</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812245</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:14:54,358] Trial 28 finished with value: 0.8122448979591836 and parameters: {'learning_rate': 0.0001957414021021512, 'weight_decay': 0.0067354312637445376, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1813' max='3885' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1813/3885 02:45 < 03:08, 10.97 it/s, Epoch 7/15]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.365200</td>\n",
              "      <td>0.508067</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.777295</td>\n",
              "      <td>0.765217</td>\n",
              "      <td>0.762633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.229500</td>\n",
              "      <td>0.464130</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.795687</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.953100</td>\n",
              "      <td>0.537381</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.807534</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.798767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.882800</td>\n",
              "      <td>0.534018</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.834302</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.810023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.460900</td>\n",
              "      <td>0.489589</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.807971</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.793588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.089800</td>\n",
              "      <td>0.556093</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.805851</td>\n",
              "      <td>0.795652</td>\n",
              "      <td>0.793934</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.054200</td>\n",
              "      <td>0.507751</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.793524</td>\n",
              "      <td>0.791304</td>\n",
              "      <td>0.790909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "[I 2024-09-29 21:17:45,399] Trial 29 finished with value: 0.7909090909090909 and parameters: {'learning_rate': 0.00012334306698870076, 'weight_decay': 0.018900516445315926, 'per_device_train_batch_size': 16}. Best is trial 0 with value: 0.8782240375160728.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BestRun(run_id='0', objective=0.8782240375160728, hyperparameters={'learning_rate': 0.00048569487626740564, 'weight_decay': 0.008452656442872837, 'per_device_train_batch_size': 16}, run_summary=None)\n"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    model_init = model_init,\n",
        "    args=trainer_class.training_args,\n",
        "    train_dataset=pytorch_train,\n",
        "    eval_dataset=pytorch_val,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3)],\n",
        "    compute_metrics=trainer_class.compute_metrics\n",
        ")\n",
        "  #loss - minimize, može biti i \"maximize\" za npr. F1\n",
        "\n",
        "best_run = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    hp_space = lambda trial: {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 5e-5, 5e-4, log=True),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.005, 0.02),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [16, 32])\n",
        "    },\n",
        "    compute_objective = lambda metrics: metrics['eval_f1_score'],\n",
        "    backend=\"optuna\",\n",
        "    n_trials=30,\n",
        "    pruner = optuna.pruners.NopPruner(), #None ?\n",
        ")\n",
        "print(best_run)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Test**"
      ],
      "metadata": {
        "id": "NlXU6sf5zku-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_lora_all, model_info_all = model_class.get_model_with_lora(quantized = True, lora_rank = 16, scaling_factor = 48, dropout = 0.1, chosen_layers = list(range(12)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woHsMn40y3eH",
        "outputId": "5bc0b295-aeeb-412a-c94d-520208415a93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_class = GetTrainer(num_epochs = 20, lr = 0.00048569487626740564, weight_decay=0.008452656442872837)\n",
        "trainer, training_hyperparameters_info = trainer_class.get_trainer(model_with_lora_all, pytorch_train, pytorch_val)\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "l9xfAv38zG8f",
        "outputId": "972884fb-a632-4bc9-88ac-625a85f32e68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2590' max='5180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2590/5180 03:54 < 03:54, 11.04 it/s, Epoch 10/20]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.252000</td>\n",
              "      <td>0.459324</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.800363</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.799939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.163100</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.817096</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812444</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.835900</td>\n",
              "      <td>0.449074</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.823722</td>\n",
              "      <td>0.821739</td>\n",
              "      <td>0.821466</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.007800</td>\n",
              "      <td>0.451987</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.858915</td>\n",
              "      <td>0.839130</td>\n",
              "      <td>0.836883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.109400</td>\n",
              "      <td>0.423573</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.839819</td>\n",
              "      <td>0.834783</td>\n",
              "      <td>0.834168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.081500</td>\n",
              "      <td>0.403821</td>\n",
              "      <td>0.873913</td>\n",
              "      <td>0.873941</td>\n",
              "      <td>0.873913</td>\n",
              "      <td>0.873911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.016100</td>\n",
              "      <td>0.366075</td>\n",
              "      <td>0.878261</td>\n",
              "      <td>0.878375</td>\n",
              "      <td>0.878261</td>\n",
              "      <td>0.878252</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.147500</td>\n",
              "      <td>0.473353</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.857472</td>\n",
              "      <td>0.852174</td>\n",
              "      <td>0.851624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>0.512169</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.857197</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856454</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.105000</td>\n",
              "      <td>0.552293</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.865466</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.865194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2590, training_loss=0.2833590415453819, metrics={'train_runtime': 234.5025, 'train_samples_per_second': 353.088, 'train_steps_per_second': 22.089, 'total_flos': 856875592512000.0, 'train_loss': 0.2833590415453819, 'epoch': 10.0})"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_info_all, training_hyperparameters_info)\n",
        "print(\"train set: \", trainer.evaluate(eval_dataset = pytorch_train))\n",
        "print(\"val set: \", trainer.evaluate(eval_dataset = pytorch_val))\n",
        "print(\"test set: \", trainer.evaluate(eval_dataset = pytorch_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "Bh10RI4Tzqa-",
        "outputId": "fc5a4486-0478-4dfa-87e5-e4a0aede13a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model is quantized \n",
            "lora_rank: 16, scaling_factor: 48, dropout: 0.1, chosen_layers: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
            "trainable_parameters: 591362\n",
            " num_epochs: 20, learning_rate: 0.00048569487626740564, weight_decay: 0.008452656442872837\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set:  {'eval_loss': 0.0762900561094284, 'eval_accuracy': 0.97512077294686, 'eval_precision': 0.9752016201033993, 'eval_recall': 0.97512077294686, 'eval_f1_score': 0.9751197147116633, 'eval_runtime': 10.8875, 'eval_samples_per_second': 380.252, 'eval_steps_per_second': 23.789, 'epoch': 10.0}\n",
            "val set:  {'eval_loss': 0.3660750687122345, 'eval_accuracy': 0.8782608695652174, 'eval_precision': 0.8783753120036307, 'eval_recall': 0.8782608695652174, 'eval_f1_score': 0.8782516636418632, 'eval_runtime': 0.6716, 'eval_samples_per_second': 342.474, 'eval_steps_per_second': 22.335, 'epoch': 10.0}\n",
            "test set:  {'eval_loss': 0.38472142815589905, 'eval_accuracy': 0.8879310344827587, 'eval_precision': 0.8880463871543265, 'eval_recall': 0.8879310344827587, 'eval_f1_score': 0.8879227053140096, 'eval_runtime': 0.6688, 'eval_samples_per_second': 346.913, 'eval_steps_per_second': 22.43, 'epoch': 10.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_class = EvaluationClass(model_with_lora_all, device, class_names, tokenizer)\n",
        "evaluation_class.plot_all_matrixes(pytorch_train, pytorch_val, pytorch_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "id": "OFTw2YJq0Ay1",
        "outputId": "ab5aaa2a-7b60-4686-ddb9-4f2a9387a136"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.9756038647342995, 'precision': 0.9756847940943534, 'recall': 0.9756038647342995, 'f1_score': 0.9757619390448764}\n",
            "Val Set: {'accuracy': 0.8782608695652174, 'precision': 0.8783753120036307, 'recall': 0.8782608695652174, 'f1_score': 0.8793103448275862}\n",
            "Test Set: {'accuracy': 0.8879310344827587, 'precision': 0.8880463871543265, 'recall': 0.8879310344827587, 'f1_score': 0.8888888888888888}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_misclassified_examples(model, pytorch_dataset):\n",
        "    misclassified_examples = []\n",
        "    evaluation_class = EvaluationClass(model, device, class_names, tokenizer)\n",
        "\n",
        "    for i in range(len(pytorch_dataset)):\n",
        "        item = pytorch_dataset[i]\n",
        "        predicted_label = evaluation_class.classify_input(item['input_ids'], item['attention_mask'])\n",
        "        true_label = item['labels'].item()\n",
        "        if predicted_label != true_label:\n",
        "            misclassified_examples.append({\n",
        "                'text': pytorch_dataset.texts[i],\n",
        "                'label': true_label\n",
        "            })\n",
        "\n",
        "    random.shuffle(misclassified_examples)\n",
        "    return misclassified_examples"
      ],
      "metadata": {
        "id": "4fPxi0f4346F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "misclassified = collect_misclassified_examples(model_with_lora_all, pytorch_test)\n",
        "print(misclassified)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w1ZJYJGvTP2j",
        "outputId": "36120a65-1297-4011-e7ab-b2eed4d82bf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'Bolje se ne sukobljavaj s njim, deo je grupe i mogli bi da te povrede.', 'label': 0}, {'text': 'Moj ti je savet da se ubiješ.', 'label': 1}, {'text': 'Ovako: Uhvatićemo je i prebaciti preko granice gde ćemo je prodati', 'label': 1}, {'text': 'Naći ću te čim te vidim na mapi, baš da isprobam novi item.', 'label': 0}, {'text': 'Ubij se, ne vredi ti ništa što radiš.', 'label': 1}, {'text': 'Izbrisaću ti nalog ovaj onda.', 'label': 0}, {'text': 'Učiteljice, Marko govori da će me napasti.', 'label': 0}, {'text': 'Neka se bore dok jedan od njih ne umre.', 'label': 1}, {'text': 'Kada te pronađem, reći ću ti par stvari.', 'label': 0}, {'text': 'Ajde da mu uzmemo poklon za njegov rođendan.', 'label': 0}, {'text': 'Tvoj dug će uskoro biti naplaćen tvojom krvlju!', 'label': 1}, {'text': 'Skratiću ti kosu 2 cm samo', 'label': 0}, {'text': 'Perica, čini se da ti je nos polomljen.', 'label': 0}, {'text': 'Napraviću logorsku vatru da nam ne bude hladno.', 'label': 0}, {'text': 'Svi belci će danas biti prebijeni.', 'label': 1}, {'text': 'Idi u prodavnicu i baci im bombu.', 'label': 1}, {'text': 'Kome si nameravao da razbiješ nos danas?', 'label': 1}, {'text': 'Samo još jedna rečenica i završavam', 'label': 0}, {'text': 'Diši đedo, diši Đedo.', 'label': 0}, {'text': 'Da sam u tvojoj situaciji, radije bih sebi oduzeo život!', 'label': 1}, {'text': 'Čim završi kupovinu, smesti je u prtljažnik.', 'label': 1}, {'text': 'Mi ovde vodimo glavnu reč; ko se usudi da nam se suprotstavi, biće eliminisan.', 'label': 1}, {'text': 'Ako nastaviš da jedeš to, pokvarićeš zube sebi.', 'label': 0}, {'text': 'Bog vidi sve i kazniće one koji su zli.', 'label': 0}, {'text': 'Molim te skloni se da te ne iznabadam.', 'label': 1}, {'text': 'Bilo bi lepo da znam gde se trenutno nalaziš.', 'label': 0}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fina_name = 'BestModel'\n",
        "final_path = loader_class.map_name_to_path(fina_name)\n",
        "model_with_lora_all.save_pretrained(final_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HO_3Pzj-NCm",
        "outputId": "16841930-6df9-448f-f856-4b8cb9026ad1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Experiment 5** Mining hard examples"
      ],
      "metadata": {
        "id": "H6TxzNy2mG4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def collect_all_plus_misclassified_examples(model, pytorch_dataset):\n",
        "    all_plus_misclassified_examples = []\n",
        "    evaluation_class = EvaluationClass(model, device, class_names, tokenizer)\n",
        "\n",
        "    for i in range(len(pytorch_dataset)):\n",
        "        item = pytorch_dataset[i]\n",
        "        predicted_label = evaluation_class.classify_input(item['input_ids'], item['attention_mask'])\n",
        "        true_label = item['labels'].item()\n",
        "        if predicted_label != true_label:\n",
        "            all_plus_misclassified_examples.append({\n",
        "                'text': pytorch_dataset.texts[i],\n",
        "                'label': true_label\n",
        "            })\n",
        "        all_plus_misclassified_examples.append({\n",
        "                'text': pytorch_dataset.texts[i],\n",
        "                'label': true_label\n",
        "            })\n",
        "    random.shuffle(all_plus_misclassified_examples)\n",
        "    return SentimentDataset(all_plus_misclassified_examples, tokenizer, max_length)"
      ],
      "metadata": {
        "id": "NIc_3OIh8x0a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping_patience = 3\n",
        "current_val_f1 = 0\n",
        "best_eval_f1 = 0\n",
        "best_eval_iteration = -1\n",
        "best_model_so_far = None\n",
        "iteration = -1\n",
        "\n",
        "#model\n",
        "model_with_lora_layers_all, model_info_all = model_class.get_model_with_lora(quantized = True, lora_rank = 16, scaling_factor = 48, dropout = 0.1, chosen_layers = list(range(12)))\n",
        "\n",
        "trainer_class = GetTrainer(num_epochs = 1, lr = 0.00048569487626740564, weight_decay=0.008452656442872837)\n",
        "\n",
        "#train set init\n",
        "current_train_set = pytorch_train\n",
        "#new_prediction = evaluation_class.classify_input(item['input_ids'], item['attention_mask'])\n",
        "\n",
        "while(iteration < 15):\n",
        "    iteration += 1\n",
        "    print(\"current iteration: \", iteration, \"current train set length: \", len(current_train_set))\n",
        "    #trainer\n",
        "    trainer, training_hyperparameters_info = trainer_class.get_trainer(model_with_lora_layers_all, current_train_set, pytorch_val)\n",
        "    trainer.train()\n",
        "\n",
        "    #evaluation`\n",
        "    current_eval_f1 = trainer.evaluate(eval_dataset = pytorch_val)['eval_f1_score']\n",
        "    print(\"train set: eval_f1: \", trainer.evaluate(eval_dataset = pytorch_train)['eval_f1_score'])\n",
        "    print(\"val set: eval_f1: \", trainer.evaluate(eval_dataset = pytorch_val)['eval_f1_score'])\n",
        "\n",
        "    if current_eval_f1 <= best_eval_f1 and iteration - best_eval_iteration >= early_stopping_patience:\n",
        "        break\n",
        "    elif current_eval_f1 > best_eval_f1:\n",
        "        best_eval_f1 = current_eval_f1\n",
        "        best_eval_iteration = iteration\n",
        "        best_model_so_far = trainer.model\n",
        "\n",
        "    print(\"best f1 so far: \", best_eval_f1, \"is from iteration: \", best_eval_iteration)\n",
        "\n",
        "    #new train dataset\n",
        "    current_train_set = collect_all_plus_misclassified_examples(model_with_lora_layers_all, pytorch_train)\n",
        "\n",
        "print(\"test set: \", trainer.evaluate(eval_dataset = pytorch_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6dQchnZcmGLl",
        "outputId": "e3b012f3-7338-4e41-a7e5-ffc4c871e909"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at classla/bcms-bertic and are newly initialized: ['classifier.bias', 'classifier.weight', 'embeddings.LayerNorm.bias', 'embeddings.LayerNorm.weight', 'embeddings.position_embeddings.weight', 'embeddings.token_type_embeddings.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.0.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.11.output.dense.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.2.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.3.output.dense.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.6.output.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.9.output.dense.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "current iteration:  0 current train set length:  4140\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='259' max='259' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [259/259 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.249000</td>\n",
              "      <td>0.479484</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.785720</td>\n",
              "      <td>0.782609</td>\n",
              "      <td>0.782015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.822711010393941\n",
            "val set: eval_f1:  0.7820153157934642\n",
            "best f1 so far:  0.7820153157934642 is from iteration:  0\n",
            "current iteration:  1 current train set length:  4873\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='305' max='305' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [305/305 00:27, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.232400</td>\n",
              "      <td>0.411897</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817776</td>\n",
              "      <td>0.817391</td>\n",
              "      <td>0.817336</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.8889583031784375\n",
            "val set: eval_f1:  0.8173360562741093\n",
            "best f1 so far:  0.8173360562741093 is from iteration:  1\n",
            "current iteration:  2 current train set length:  4599\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='288' max='288' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [288/288 00:26, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.086900</td>\n",
              "      <td>0.391593</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.814208</td>\n",
              "      <td>0.813043</td>\n",
              "      <td>0.812870</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9357421788841952\n",
            "val set: eval_f1:  0.8128701443681292\n",
            "best f1 so far:  0.8173360562741093 is from iteration:  1\n",
            "current iteration:  3 current train set length:  4404\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='276' max='276' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [276/276 00:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.091300</td>\n",
              "      <td>0.335428</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843582</td>\n",
              "      <td>0.843478</td>\n",
              "      <td>0.843466</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9548301562414031\n",
            "val set: eval_f1:  0.8434664246823956\n",
            "best f1 so far:  0.8434664246823956 is from iteration:  3\n",
            "current iteration:  4 current train set length:  4325\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='271' max='271' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [271/271 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.855500</td>\n",
              "      <td>0.418190</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848485</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847754</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9603693722068685\n",
            "val set: eval_f1:  0.8477541371158392\n",
            "best f1 so far:  0.8477541371158392 is from iteration:  4\n",
            "current iteration:  5 current train set length:  4305\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='270' max='270' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [270/270 00:25, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.231400</td>\n",
              "      <td>0.373344</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.849120</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847685</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9714973450732625\n",
            "val set: eval_f1:  0.8476850012298727\n",
            "best f1 so far:  0.8477541371158392 is from iteration:  4\n",
            "current iteration:  6 current train set length:  4258\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='267' max='267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [267/267 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.671900</td>\n",
              "      <td>0.442655</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.857848</td>\n",
              "      <td>0.856522</td>\n",
              "      <td>0.856389</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9726977300457857\n",
            "val set: eval_f1:  0.8563887154453086\n",
            "best f1 so far:  0.8563887154453086 is from iteration:  6\n",
            "current iteration:  7 current train set length:  4253\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='266' max='266' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [266/266 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.106900</td>\n",
              "      <td>0.487504</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.873377</td>\n",
              "      <td>0.865217</td>\n",
              "      <td>0.864477</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.969788782431888\n",
            "val set: eval_f1:  0.8644770105111099\n",
            "best f1 so far:  0.8644770105111099 is from iteration:  7\n",
            "current iteration:  8 current train set length:  4266\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='267' max='267' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [267/267 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042700</td>\n",
              "      <td>0.461795</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.848063</td>\n",
              "      <td>0.847826</td>\n",
              "      <td>0.847800</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9842990323104444\n",
            "val set: eval_f1:  0.847800192849445\n",
            "best f1 so far:  0.8644770105111099 is from iteration:  7\n",
            "current iteration:  9 current train set length:  4206\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='263' max='263' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [263/263 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.018400</td>\n",
              "      <td>0.550883</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.869677</td>\n",
              "      <td>0.869565</td>\n",
              "      <td>0.869555</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9893719583531996\n",
            "val set: eval_f1:  0.8695553539019965\n",
            "best f1 so far:  0.8695553539019965 is from iteration:  9\n",
            "current iteration:  10 current train set length:  4184\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [262/262 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.005600</td>\n",
              "      <td>0.415274</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.892045</td>\n",
              "      <td>0.891304</td>\n",
              "      <td>0.891253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9847825864993736\n",
            "val set: eval_f1:  0.8912529550827423\n",
            "best f1 so far:  0.8912529550827423 is from iteration:  10\n",
            "current iteration:  11 current train set length:  4204\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='263' max='263' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [263/263 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.084000</td>\n",
              "      <td>0.535292</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.884032</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.882500</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9891303276053913\n",
            "val set: eval_f1:  0.882499858091616\n",
            "best f1 so far:  0.8912529550827423 is from iteration:  10\n",
            "current iteration:  12 current train set length:  4185\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='262' max='262' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [262/262 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.293000</td>\n",
              "      <td>0.427611</td>\n",
              "      <td>0.895652</td>\n",
              "      <td>0.896732</td>\n",
              "      <td>0.895652</td>\n",
              "      <td>0.895581</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9917874223638361\n",
            "val set: eval_f1:  0.8955811138014529\n",
            "best f1 so far:  0.8955811138014529 is from iteration:  12\n",
            "current iteration:  13 current train set length:  4174\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [261/261 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.003900</td>\n",
              "      <td>0.454300</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.884967</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.882429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9922705151659633\n",
            "val set: eval_f1:  0.8824286715007857\n",
            "best f1 so far:  0.8955811138014529 is from iteration:  12\n",
            "current iteration:  14 current train set length:  4174\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [261/261 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.028100</td>\n",
              "      <td>0.469765</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.886142</td>\n",
              "      <td>0.882609</td>\n",
              "      <td>0.882340</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='289' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:12]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9946859704953506\n",
            "val set: eval_f1:  0.8823395668731882\n",
            "best f1 so far:  0.8955811138014529 is from iteration:  12\n",
            "current iteration:  15 current train set length:  4161\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='261' max='261' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [261/261 00:24, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1 Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.547061</td>\n",
              "      <td>0.886957</td>\n",
              "      <td>0.887074</td>\n",
              "      <td>0.886957</td>\n",
              "      <td>0.886948</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='304' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [15/15 00:13]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set: eval_f1:  0.9949275359359341\n",
            "val set: eval_f1:  0.8869479733817303\n",
            "test set:  {'eval_loss': 0.6842995285987854, 'eval_accuracy': 0.8663793103448276, 'eval_precision': 0.8677183560826434, 'eval_recall': 0.8663793103448276, 'eval_f1_score': 0.8662575546257555, 'eval_runtime': 0.641, 'eval_samples_per_second': 361.943, 'eval_steps_per_second': 23.402, 'epoch': 1.0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluation_class = EvaluationClass(best_model_so_far, device, class_names, tokenizer)\n",
        "evaluation_class.get_metrics(pytorch_test)\n",
        "\n",
        "evaluation_class.plot_all_matrixes(pytorch_train, pytorch_val, pytorch_test)"
      ],
      "metadata": {
        "id": "_z8jnWfk2etP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "e9f9d307-f73d-4bff-c819-6d94c8c9d3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Set: {'accuracy': 0.9946859903381643, 'precision': 0.9946859903381643, 'recall': 0.9946859903381643, 'f1_score': 0.9946859903381643}\n",
            "Val Set: {'accuracy': 0.8869565217391304, 'precision': 0.8870735950381968, 'recall': 0.8869565217391304, 'f1_score': 0.8859649122807017}\n",
            "Test Set: {'accuracy': 0.8663793103448276, 'precision': 0.8677183560826434, 'recall': 0.8663793103448276, 'f1_score': 0.8622222222222222}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1600x400 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CLvFPBiP6apT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
