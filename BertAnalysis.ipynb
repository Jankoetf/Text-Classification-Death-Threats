{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLvFPBiP6apT"
      },
      "source": [
        "### Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw2kEFZoXRw6"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer, BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22HsxVGQXfQq"
      },
      "source": [
        "### Bert base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qKrzSZ5XlmT"
      },
      "outputs": [],
      "source": [
        "base_model_checkpoint = \"bert-base-uncased\"\n",
        "base_tokenizer = AutoTokenizer.from_pretrained(base_model_checkpoint)\n",
        "bert_base_model = BertForSequenceClassification.from_pretrained(base_model_checkpoint, num_labels=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nbnS5LS9QJIW"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total nuber of parameters: 109483778\n",
            "trainable parameters: 109483778\n",
            "Layer: bert.embeddings.word_embeddings.weight | Size: torch.Size([30522, 768])\n",
            "Layer: bert.embeddings.position_embeddings.weight | Size: torch.Size([512, 768])\n",
            "Layer: bert.embeddings.token_type_embeddings.weight | Size: torch.Size([2, 768])\n",
            "Layer: bert.embeddings.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.embeddings.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.0.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.0.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.0.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.0.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.0.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.0.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.0.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.0.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.1.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.1.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.1.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.1.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.1.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.1.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.1.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.1.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.2.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.2.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.2.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.2.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.2.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.2.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.2.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.2.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.3.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.3.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.3.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.3.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.3.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.3.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.3.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.3.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.4.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.4.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.4.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.4.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.4.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.4.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.4.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.4.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.5.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.5.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.5.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.5.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.5.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.5.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.5.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.5.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.6.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.6.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.6.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.6.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.6.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.6.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.6.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.6.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.7.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.7.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.7.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.7.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.7.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.7.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.7.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.7.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.8.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.8.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.8.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.8.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.8.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.8.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.8.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.8.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.9.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.9.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.9.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.9.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.9.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.9.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.9.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.9.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.10.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.10.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.10.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.10.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.10.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.10.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.10.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.10.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.self.query.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.11.attention.self.query.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.self.key.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.11.attention.self.key.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.self.value.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.11.attention.self.value.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.output.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.encoder.layer.11.attention.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.attention.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.intermediate.dense.weight | Size: torch.Size([3072, 768])\n",
            "Layer: bert.encoder.layer.11.intermediate.dense.bias | Size: torch.Size([3072])\n",
            "Layer: bert.encoder.layer.11.output.dense.weight | Size: torch.Size([768, 3072])\n",
            "Layer: bert.encoder.layer.11.output.dense.bias | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.output.LayerNorm.weight | Size: torch.Size([768])\n",
            "Layer: bert.encoder.layer.11.output.LayerNorm.bias | Size: torch.Size([768])\n",
            "Layer: bert.pooler.dense.weight | Size: torch.Size([768, 768])\n",
            "Layer: bert.pooler.dense.bias | Size: torch.Size([768])\n",
            "Layer: classifier.weight | Size: torch.Size([2, 768])\n",
            "Layer: classifier.bias | Size: torch.Size([2])\n",
            "\n",
            "bert\n",
            "bert.embeddings\n",
            "bert.embeddings.word_embeddings\n",
            "bert.embeddings.position_embeddings\n",
            "bert.embeddings.token_type_embeddings\n",
            "bert.embeddings.LayerNorm\n",
            "bert.embeddings.dropout\n",
            "bert.encoder\n",
            "bert.encoder.layer\n",
            "bert.encoder.layer.0\n",
            "bert.encoder.layer.0.attention\n",
            "bert.encoder.layer.0.attention.self\n",
            "bert.encoder.layer.0.attention.self.query\n",
            "bert.encoder.layer.0.attention.self.key\n",
            "bert.encoder.layer.0.attention.self.value\n",
            "bert.encoder.layer.0.attention.self.dropout\n",
            "bert.encoder.layer.0.attention.output\n",
            "bert.encoder.layer.0.attention.output.dense\n",
            "bert.encoder.layer.0.attention.output.LayerNorm\n",
            "bert.encoder.layer.0.attention.output.dropout\n",
            "bert.encoder.layer.0.intermediate\n",
            "bert.encoder.layer.0.intermediate.dense\n",
            "bert.encoder.layer.0.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.0.output\n",
            "bert.encoder.layer.0.output.dense\n",
            "bert.encoder.layer.0.output.LayerNorm\n",
            "bert.encoder.layer.0.output.dropout\n",
            "bert.encoder.layer.1\n",
            "bert.encoder.layer.1.attention\n",
            "bert.encoder.layer.1.attention.self\n",
            "bert.encoder.layer.1.attention.self.query\n",
            "bert.encoder.layer.1.attention.self.key\n",
            "bert.encoder.layer.1.attention.self.value\n",
            "bert.encoder.layer.1.attention.self.dropout\n",
            "bert.encoder.layer.1.attention.output\n",
            "bert.encoder.layer.1.attention.output.dense\n",
            "bert.encoder.layer.1.attention.output.LayerNorm\n",
            "bert.encoder.layer.1.attention.output.dropout\n",
            "bert.encoder.layer.1.intermediate\n",
            "bert.encoder.layer.1.intermediate.dense\n",
            "bert.encoder.layer.1.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.1.output\n",
            "bert.encoder.layer.1.output.dense\n",
            "bert.encoder.layer.1.output.LayerNorm\n",
            "bert.encoder.layer.1.output.dropout\n",
            "bert.encoder.layer.2\n",
            "bert.encoder.layer.2.attention\n",
            "bert.encoder.layer.2.attention.self\n",
            "bert.encoder.layer.2.attention.self.query\n",
            "bert.encoder.layer.2.attention.self.key\n",
            "bert.encoder.layer.2.attention.self.value\n",
            "bert.encoder.layer.2.attention.self.dropout\n",
            "bert.encoder.layer.2.attention.output\n",
            "bert.encoder.layer.2.attention.output.dense\n",
            "bert.encoder.layer.2.attention.output.LayerNorm\n",
            "bert.encoder.layer.2.attention.output.dropout\n",
            "bert.encoder.layer.2.intermediate\n",
            "bert.encoder.layer.2.intermediate.dense\n",
            "bert.encoder.layer.2.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.2.output\n",
            "bert.encoder.layer.2.output.dense\n",
            "bert.encoder.layer.2.output.LayerNorm\n",
            "bert.encoder.layer.2.output.dropout\n",
            "bert.encoder.layer.3\n",
            "bert.encoder.layer.3.attention\n",
            "bert.encoder.layer.3.attention.self\n",
            "bert.encoder.layer.3.attention.self.query\n",
            "bert.encoder.layer.3.attention.self.key\n",
            "bert.encoder.layer.3.attention.self.value\n",
            "bert.encoder.layer.3.attention.self.dropout\n",
            "bert.encoder.layer.3.attention.output\n",
            "bert.encoder.layer.3.attention.output.dense\n",
            "bert.encoder.layer.3.attention.output.LayerNorm\n",
            "bert.encoder.layer.3.attention.output.dropout\n",
            "bert.encoder.layer.3.intermediate\n",
            "bert.encoder.layer.3.intermediate.dense\n",
            "bert.encoder.layer.3.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.3.output\n",
            "bert.encoder.layer.3.output.dense\n",
            "bert.encoder.layer.3.output.LayerNorm\n",
            "bert.encoder.layer.3.output.dropout\n",
            "bert.encoder.layer.4\n",
            "bert.encoder.layer.4.attention\n",
            "bert.encoder.layer.4.attention.self\n",
            "bert.encoder.layer.4.attention.self.query\n",
            "bert.encoder.layer.4.attention.self.key\n",
            "bert.encoder.layer.4.attention.self.value\n",
            "bert.encoder.layer.4.attention.self.dropout\n",
            "bert.encoder.layer.4.attention.output\n",
            "bert.encoder.layer.4.attention.output.dense\n",
            "bert.encoder.layer.4.attention.output.LayerNorm\n",
            "bert.encoder.layer.4.attention.output.dropout\n",
            "bert.encoder.layer.4.intermediate\n",
            "bert.encoder.layer.4.intermediate.dense\n",
            "bert.encoder.layer.4.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.4.output\n",
            "bert.encoder.layer.4.output.dense\n",
            "bert.encoder.layer.4.output.LayerNorm\n",
            "bert.encoder.layer.4.output.dropout\n",
            "bert.encoder.layer.5\n",
            "bert.encoder.layer.5.attention\n",
            "bert.encoder.layer.5.attention.self\n",
            "bert.encoder.layer.5.attention.self.query\n",
            "bert.encoder.layer.5.attention.self.key\n",
            "bert.encoder.layer.5.attention.self.value\n",
            "bert.encoder.layer.5.attention.self.dropout\n",
            "bert.encoder.layer.5.attention.output\n",
            "bert.encoder.layer.5.attention.output.dense\n",
            "bert.encoder.layer.5.attention.output.LayerNorm\n",
            "bert.encoder.layer.5.attention.output.dropout\n",
            "bert.encoder.layer.5.intermediate\n",
            "bert.encoder.layer.5.intermediate.dense\n",
            "bert.encoder.layer.5.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.5.output\n",
            "bert.encoder.layer.5.output.dense\n",
            "bert.encoder.layer.5.output.LayerNorm\n",
            "bert.encoder.layer.5.output.dropout\n",
            "bert.encoder.layer.6\n",
            "bert.encoder.layer.6.attention\n",
            "bert.encoder.layer.6.attention.self\n",
            "bert.encoder.layer.6.attention.self.query\n",
            "bert.encoder.layer.6.attention.self.key\n",
            "bert.encoder.layer.6.attention.self.value\n",
            "bert.encoder.layer.6.attention.self.dropout\n",
            "bert.encoder.layer.6.attention.output\n",
            "bert.encoder.layer.6.attention.output.dense\n",
            "bert.encoder.layer.6.attention.output.LayerNorm\n",
            "bert.encoder.layer.6.attention.output.dropout\n",
            "bert.encoder.layer.6.intermediate\n",
            "bert.encoder.layer.6.intermediate.dense\n",
            "bert.encoder.layer.6.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.6.output\n",
            "bert.encoder.layer.6.output.dense\n",
            "bert.encoder.layer.6.output.LayerNorm\n",
            "bert.encoder.layer.6.output.dropout\n",
            "bert.encoder.layer.7\n",
            "bert.encoder.layer.7.attention\n",
            "bert.encoder.layer.7.attention.self\n",
            "bert.encoder.layer.7.attention.self.query\n",
            "bert.encoder.layer.7.attention.self.key\n",
            "bert.encoder.layer.7.attention.self.value\n",
            "bert.encoder.layer.7.attention.self.dropout\n",
            "bert.encoder.layer.7.attention.output\n",
            "bert.encoder.layer.7.attention.output.dense\n",
            "bert.encoder.layer.7.attention.output.LayerNorm\n",
            "bert.encoder.layer.7.attention.output.dropout\n",
            "bert.encoder.layer.7.intermediate\n",
            "bert.encoder.layer.7.intermediate.dense\n",
            "bert.encoder.layer.7.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.7.output\n",
            "bert.encoder.layer.7.output.dense\n",
            "bert.encoder.layer.7.output.LayerNorm\n",
            "bert.encoder.layer.7.output.dropout\n",
            "bert.encoder.layer.8\n",
            "bert.encoder.layer.8.attention\n",
            "bert.encoder.layer.8.attention.self\n",
            "bert.encoder.layer.8.attention.self.query\n",
            "bert.encoder.layer.8.attention.self.key\n",
            "bert.encoder.layer.8.attention.self.value\n",
            "bert.encoder.layer.8.attention.self.dropout\n",
            "bert.encoder.layer.8.attention.output\n",
            "bert.encoder.layer.8.attention.output.dense\n",
            "bert.encoder.layer.8.attention.output.LayerNorm\n",
            "bert.encoder.layer.8.attention.output.dropout\n",
            "bert.encoder.layer.8.intermediate\n",
            "bert.encoder.layer.8.intermediate.dense\n",
            "bert.encoder.layer.8.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.8.output\n",
            "bert.encoder.layer.8.output.dense\n",
            "bert.encoder.layer.8.output.LayerNorm\n",
            "bert.encoder.layer.8.output.dropout\n",
            "bert.encoder.layer.9\n",
            "bert.encoder.layer.9.attention\n",
            "bert.encoder.layer.9.attention.self\n",
            "bert.encoder.layer.9.attention.self.query\n",
            "bert.encoder.layer.9.attention.self.key\n",
            "bert.encoder.layer.9.attention.self.value\n",
            "bert.encoder.layer.9.attention.self.dropout\n",
            "bert.encoder.layer.9.attention.output\n",
            "bert.encoder.layer.9.attention.output.dense\n",
            "bert.encoder.layer.9.attention.output.LayerNorm\n",
            "bert.encoder.layer.9.attention.output.dropout\n",
            "bert.encoder.layer.9.intermediate\n",
            "bert.encoder.layer.9.intermediate.dense\n",
            "bert.encoder.layer.9.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.9.output\n",
            "bert.encoder.layer.9.output.dense\n",
            "bert.encoder.layer.9.output.LayerNorm\n",
            "bert.encoder.layer.9.output.dropout\n",
            "bert.encoder.layer.10\n",
            "bert.encoder.layer.10.attention\n",
            "bert.encoder.layer.10.attention.self\n",
            "bert.encoder.layer.10.attention.self.query\n",
            "bert.encoder.layer.10.attention.self.key\n",
            "bert.encoder.layer.10.attention.self.value\n",
            "bert.encoder.layer.10.attention.self.dropout\n",
            "bert.encoder.layer.10.attention.output\n",
            "bert.encoder.layer.10.attention.output.dense\n",
            "bert.encoder.layer.10.attention.output.LayerNorm\n",
            "bert.encoder.layer.10.attention.output.dropout\n",
            "bert.encoder.layer.10.intermediate\n",
            "bert.encoder.layer.10.intermediate.dense\n",
            "bert.encoder.layer.10.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.10.output\n",
            "bert.encoder.layer.10.output.dense\n",
            "bert.encoder.layer.10.output.LayerNorm\n",
            "bert.encoder.layer.10.output.dropout\n",
            "bert.encoder.layer.11\n",
            "bert.encoder.layer.11.attention\n",
            "bert.encoder.layer.11.attention.self\n",
            "bert.encoder.layer.11.attention.self.query\n",
            "bert.encoder.layer.11.attention.self.key\n",
            "bert.encoder.layer.11.attention.self.value\n",
            "bert.encoder.layer.11.attention.self.dropout\n",
            "bert.encoder.layer.11.attention.output\n",
            "bert.encoder.layer.11.attention.output.dense\n",
            "bert.encoder.layer.11.attention.output.LayerNorm\n",
            "bert.encoder.layer.11.attention.output.dropout\n",
            "bert.encoder.layer.11.intermediate\n",
            "bert.encoder.layer.11.intermediate.dense\n",
            "bert.encoder.layer.11.intermediate.intermediate_act_fn\n",
            "bert.encoder.layer.11.output\n",
            "bert.encoder.layer.11.output.dense\n",
            "bert.encoder.layer.11.output.LayerNorm\n",
            "bert.encoder.layer.11.output.dropout\n",
            "bert.pooler\n",
            "bert.pooler.dense\n",
            "bert.pooler.activation\n",
            "dropout\n",
            "classifier\n"
          ]
        }
      ],
      "source": [
        "# parameters\n",
        "total_params = sum(p.numel() for p in bert_base_model.parameters())\n",
        "trainable_params = sum(p.numel() for p in bert_base_model.parameters() if p.requires_grad)\n",
        "print(f\"Total nuber of parameters: {total_params}\")\n",
        "print(f\"trainable parameters: {trainable_params}\")\n",
        "\n",
        "# model structure\n",
        "for name, param in bert_base_model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.shape}\")\n",
        "\n",
        "# layers\n",
        "for name, module in bert_base_model.named_modules():\n",
        "    print(name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5aKOPJ88zgx",
        "outputId": "1bdc967d-034f-4a79-9406-7342b9c111e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: even, ID: 2130\n",
            "Token: get, ID: 2131\n",
            "Token: head, ID: 2132\n",
            "Token: ..., ID: 2133\n",
            "Token: didn, ID: 2134\n",
            "Token: ##ly, ID: 2135\n",
            "Token: team, ID: 2136\n",
            "Token: american, ID: 2137\n",
            "Token: because, ID: 2138\n",
            "Token: de, ID: 2139\n",
            "Token: ##l, ID: 2140\n",
            "Token: born, ID: 2141\n",
            "Token: united, ID: 2142\n",
            "Token: film, ID: 2143\n",
            "Token: since, ID: 2144\n",
            "Token: still, ID: 2145\n",
            "Token: long, ID: 2146\n",
            "Token: work, ID: 2147\n",
            "Token: south, ID: 2148\n",
            "Token: us, ID: 2149\n",
            "Token: became, ID: 2150\n",
            "Token: any, ID: 2151\n",
            "Token: high, ID: 2152\n",
            "Token: again, ID: 2153\n",
            "Token: day, ID: 2154\n",
            "Token: family, ID: 2155\n",
            "Token: see, ID: 2156\n",
            "Token: right, ID: 2157\n",
            "Token: man, ID: 2158\n",
            "Token: eyes, ID: 2159\n"
          ]
        }
      ],
      "source": [
        "inverse_vocab_base = {}\n",
        "for token, token_id in list(base_tokenizer.vocab.items()):\n",
        "    inverse_vocab_base[token_id] = token\n",
        "\n",
        "for token, token_id in list(base_tokenizer.vocab.items())[:30]:\n",
        "    inverse_vocab_base[token_id] = token\n",
        "\n",
        "for index in range(2130,2160):\n",
        "    print(f\"Token: {inverse_vocab_base[index]}, ID: {index}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qStC1sN88_8w",
        "outputId": "ccfae6bd-8106-4dcd-a434-139553dd5c27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: Hello, how are you doing today?\n",
            "Tokens: ['hello', ',', 'how', 'are', 'you', 'doing', 'today', '?']\n",
            "Tokens (ID-s): [7592, 1010, 2129, 2024, 2017, 2725, 2651, 1029]\n",
            "Vocab Length:  30522\n"
          ]
        }
      ],
      "source": [
        "text = \"Hello, how are you doing today?\"\n",
        "\n",
        "# tokenization\n",
        "tokens = base_tokenizer.tokenize(text)\n",
        "token_ids = base_tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print(f\"Original text: {text}\")\n",
        "print(f\"Tokens: {tokens}\")\n",
        "print(f\"Tokens (ID-s): {token_ids}\")\n",
        "print(\"Vocab Length: \", len(base_tokenizer.vocab.items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bertic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-P8CW2R9BQo"
      },
      "outputs": [],
      "source": [
        "bertic_model_checkpoint = \"classla/bcms-bertic\"\n",
        "bertic_model = BertForSequenceClassification.from_pretrained(bertic_model_checkpoint, num_labels=2)\n",
        "bertic_tokenizer = AutoTokenizer.from_pretrained(bertic_model_checkpoint)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42iOAXgEFMnj",
        "outputId": "d27b2ff0-d46a-4a89-edbf-0076b2e421f1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sloj: bert.embeddings.word_embeddings.weight | Veličina: torch.Size([32000, 768])\n",
            "Sloj: bert.embeddings.position_embeddings.weight | Veličina: torch.Size([512, 768])\n",
            "Sloj: bert.embeddings.token_type_embeddings.weight | Veličina: torch.Size([2, 768])\n",
            "Sloj: bert.embeddings.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.embeddings.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.0.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.0.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.0.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.0.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.0.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.0.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.1.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.1.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.1.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.1.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.1.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.1.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.2.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.2.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.2.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.2.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.2.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.2.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.3.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.3.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.3.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.3.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.3.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.3.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.4.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.4.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.4.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.4.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.4.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.4.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.5.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.5.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.5.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.5.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.5.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.5.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.6.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.6.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.6.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.6.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.6.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.6.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.7.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.7.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.7.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.7.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.7.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.7.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.8.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.8.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.8.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.8.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.8.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.8.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.9.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.9.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.9.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.9.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.9.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.9.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.10.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.10.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.10.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.10.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.10.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.10.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.query.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.query.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.key.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.key.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.value.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.11.attention.self.value.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.output.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.encoder.layer.11.attention.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.attention.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.intermediate.dense.weight | Veličina: torch.Size([3072, 768])\n",
            "Sloj: bert.encoder.layer.11.intermediate.dense.bias | Veličina: torch.Size([3072])\n",
            "Sloj: bert.encoder.layer.11.output.dense.weight | Veličina: torch.Size([768, 3072])\n",
            "Sloj: bert.encoder.layer.11.output.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.output.LayerNorm.weight | Veličina: torch.Size([768])\n",
            "Sloj: bert.encoder.layer.11.output.LayerNorm.bias | Veličina: torch.Size([768])\n",
            "Sloj: bert.pooler.dense.weight | Veličina: torch.Size([768, 768])\n",
            "Sloj: bert.pooler.dense.bias | Veličina: torch.Size([768])\n",
            "Sloj: classifier.weight | Veličina: torch.Size([2, 768])\n",
            "Sloj: classifier.bias | Veličina: torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "# model structure\n",
        "for name, param in bertic_model.named_parameters():\n",
        "    print(f\"Sloj: {name} | Veličina: {param.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEH9FNo7Brq5",
        "outputId": "414c7eb1-196d-4772-e746-e5c4023674f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ID tokena:  3234 token:  zdrav\n",
            "ID tokena:  19613 token:  ##ји\n",
            "ID tokena:  16502 token:  drva\n",
            "ID tokena:  6046 token:  prijave\n",
            "ID tokena:  20221 token:  1943\n",
            "ID tokena:  6861 token:  ##lacija\n",
            "ID tokena:  5072 token:  ##UP\n",
            "ID tokena:  21825 token:  ##dum\n",
            "ID tokena:  29964 token:  Konvencije\n",
            "ID tokena:  31878 token:  košarkaš\n",
            "ID tokena:  30060 token:  njemačkim\n",
            "ID tokena:  5142 token:  listopada\n",
            "ID tokena:  27636 token:  prekrasna\n",
            "ID tokena:  31558 token:  luksuz\n",
            "ID tokena:  17515 token:  ##znije\n",
            "ID tokena:  8590 token:  Bila\n",
            "ID tokena:  31966 token:  učesnike\n",
            "ID tokena:  21273 token:  razmišljaju\n",
            "ID tokena:  5200 token:  cijena\n",
            "ID tokena:  18250 token:  All\n",
            "ID tokena:  28435 token:  evropskog\n",
            "ID tokena:  22391 token:  statistika\n",
            "ID tokena:  2940 token:  ##mina\n",
            "ID tokena:  30706 token:  privukao\n",
            "ID tokena:  26594 token:  otje\n",
            "ID tokena:  7139 token:  rezultata\n",
            "ID tokena:  27189 token:  čitatelji\n",
            "ID tokena:  2682 token:  ##vijek\n",
            "ID tokena:  203 token:  ď\n",
            "ID tokena:  14493 token:  prehrani\n"
          ]
        }
      ],
      "source": [
        "inverse_vocab_bertic = {}\n",
        "for token, token_id in list(bertic_tokenizer.vocab.items()):\n",
        "    inverse_vocab_bertic[token_id] = token\n",
        "\n",
        "\n",
        "for token, token_id in list(bertic_tokenizer.vocab.items())[:30]:\n",
        "    inverse_vocab_bertic[token_id] = token\n",
        "    print(\"ID tokena: \", token_id, \"token: \", token)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5DoYtBeBZ-S",
        "outputId": "38c19003-814c-46b2-f8ca-35cd27c88ab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Token: [PAD], ID: 0\n",
            "Token: [UNK], ID: 1\n",
            "Token: [CLS], ID: 2\n",
            "Token: [SEP], ID: 3\n",
            "Token: [MASK], ID: 4\n",
            "Token: !, ID: 5\n",
            "Token: \", ID: 6\n",
            "Token: #, ID: 7\n",
            "Token: $, ID: 8\n",
            "Token: %, ID: 9\n",
            "Token: 201, ID: 2130\n",
            "Token: ##đu, ID: 2131\n",
            "Token: ##zo, ID: 2132\n",
            "Token: godine, ID: 2133\n",
            "Token: ##zu, ID: 2134\n",
            "Token: ##nta, ID: 2135\n",
            "Token: be, ID: 2136\n",
            "Token: može, ID: 2137\n",
            "Token: us, ID: 2138\n",
            "Token: ##đa, ID: 2139\n",
            "Token: ##sno, ID: 2140\n",
            "Token: ##zna, ID: 2141\n",
            "Token: ##liko, ID: 2142\n",
            "Token: stra, ID: 2143\n",
            "Token: Sa, ID: 2144\n",
            "Token: ##tni, ID: 2145\n",
            "Token: ##skog, ID: 2146\n",
            "Token: ##bu, ID: 2147\n",
            "Token: lju, ID: 2148\n",
            "Token: ##šta, ID: 2149\n"
          ]
        }
      ],
      "source": [
        "for index in range(10):\n",
        "  print(f\"Token: {inverse_vocab_bertic[index]}, ID: {index}\")\n",
        "\n",
        "for index in range(2130, 2150):\n",
        "  print(f\"Token: {inverse_vocab_bertic[index]}, ID: {index}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySFGNHi5_E8m",
        "outputId": "25b92c91-b641-4196-f0c2-8fd8254ce6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length:  32000\n"
          ]
        }
      ],
      "source": [
        "print(\"Length: \", len(bertic_tokenizer.vocab.items()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Comparing bert base and bertic tokenizers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "def comparе_tokens_for_word(text):\n",
        "    # tokens - bertic\n",
        "    tokens_bertic = bertic_tokenizer.tokenize(text)\n",
        "    token_ids_bertic = bertic_tokenizer.convert_tokens_to_ids(tokens_bertic)\n",
        "\n",
        "    print(f\"Original text: {text}\")\n",
        "    print(bertic_model_checkpoint)\n",
        "    print(f\"tokens: {tokens_bertic}\")\n",
        "    print(f\"tokens (ID-s): {token_ids_bertic}\")\n",
        "\n",
        "    # tokens - BERT base\n",
        "    tokens_base = base_tokenizer.tokenize(text)\n",
        "    token_ids_base = base_tokenizer.convert_tokens_to_ids(tokens_base)\n",
        "\n",
        "    print(base_model_checkpoint)\n",
        "    print(f\"tokens: {tokens_base}\")\n",
        "    print(f\"tokens (ID-s): {token_ids_base}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wpG77SFzFvI3",
        "outputId": "37bcd96c-9b08-4745-8062-61b473890585"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original text: šumarstvo\n",
            "classla/bcms-bertic\n",
            "tokens: ['šuma', '##rstvo']\n",
            "tokens (ID-s): [7434, 11446]\n",
            "bert-base-uncased\n",
            "tokens: ['sum', '##ars', '##tv', '##o']\n",
            "tokens (ID-s): [7680, 11650, 9189, 2080]\n",
            "\n",
            "\n",
            "Original text: uzvratiti\n",
            "classla/bcms-bertic\n",
            "tokens: ['uzvrati', '##ti']\n",
            "tokens (ID-s): [21020, 1916]\n",
            "bert-base-uncased\n",
            "tokens: ['u', '##z', '##vr', '##ati', '##ti']\n",
            "tokens (ID-s): [1057, 2480, 19716, 10450, 3775]\n",
            "\n",
            "\n",
            "Original text: mačka\n",
            "classla/bcms-bertic\n",
            "tokens: ['mačka']\n",
            "tokens (ID-s): [22314]\n",
            "bert-base-uncased\n",
            "tokens: ['mack', '##a']\n",
            "tokens (ID-s): [11349, 2050]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "example_words = [\"šumarstvo\", \"uzvratiti\", \"mačka\"]\n",
        "for text in example_words:\n",
        "    comparе_tokens_for_word(text = text)\n",
        "    print(\"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "my_virtual_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
